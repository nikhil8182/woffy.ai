{
  "version": 3,
  "sources": ["../../@firebase/ai/src/constants.ts", "../../@firebase/ai/src/errors.ts", "../../@firebase/ai/src/types/enums.ts", "../../@firebase/ai/src/types/responses.ts", "../../@firebase/ai/src/types/error.ts", "../../@firebase/ai/src/types/schema.ts", "../../@firebase/ai/src/types/imagen/requests.ts", "../../@firebase/ai/src/public-types.ts", "../../@firebase/ai/src/backend.ts", "../../@firebase/ai/src/helpers.ts", "../../@firebase/ai/src/logger.ts", "../../@firebase/ai/src/types/language-model.ts", "../../@firebase/ai/src/methods/chrome-adapter.ts", "../../@firebase/ai/src/service.ts", "../../@firebase/ai/src/factory-browser.ts", "../../@firebase/ai/src/models/utils.ts", "../../@firebase/ai/src/models/ai-model.ts", "../../@firebase/ai/src/requests/request.ts", "../../@firebase/ai/src/requests/response-helpers.ts", "../../@firebase/ai/src/googleai-mappers.ts", "../../@firebase/ai/src/requests/stream-reader.ts", "../../@firebase/ai/src/requests/hybrid-helpers.ts", "../../@firebase/ai/src/methods/generate-content.ts", "../../@firebase/ai/src/requests/request-helpers.ts", "../../@firebase/ai/src/methods/chat-session-helpers.ts", "../../@firebase/ai/src/methods/chat-session.ts", "../../@firebase/ai/src/methods/count-tokens.ts", "../../@firebase/ai/src/models/generative-model.ts", "../../@firebase/ai/src/methods/live-session.ts", "../../@firebase/ai/src/models/live-generative-model.ts", "../../@firebase/ai/src/models/imagen-model.ts", "../../@firebase/ai/src/websocket.ts", "../../@firebase/ai/src/models/template-generative-model.ts", "../../@firebase/ai/src/models/template-imagen-model.ts", "../../@firebase/ai/src/requests/schema-builder.ts", "../../@firebase/ai/src/requests/imagen-image-format.ts", "../../@firebase/ai/src/methods/live-session-helpers.ts", "../../@firebase/ai/src/api.ts", "../../@firebase/ai/src/index.ts"],
  "sourcesContent": ["/**\n * @license\n * Copyright 2024 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { version } from '../package.json';\n\nexport const AI_TYPE = 'AI';\n\nexport const DEFAULT_LOCATION = 'us-central1';\n\nexport const DEFAULT_DOMAIN = 'firebasevertexai.googleapis.com';\n\nexport const STAGING_URL =\n  'https://staging-firebasevertexai.sandbox.googleapis.com';\n\nexport const DEFAULT_API_VERSION = 'v1beta';\n\nexport const PACKAGE_VERSION = version;\n\nexport const LANGUAGE_TAG = 'gl-js';\n\nexport const DEFAULT_FETCH_TIMEOUT_MS = 180 * 1000;\n\n/**\n * Defines the name of the default in-cloud model to use for hybrid inference.\n */\nexport const DEFAULT_HYBRID_IN_CLOUD_MODEL = 'gemini-2.0-flash-lite';\n", "/**\n * @license\n * Copyright 2024 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { FirebaseError } from '@firebase/util';\nimport { AIErrorCode, CustomErrorData } from './types';\nimport { AI_TYPE } from './constants';\n\n/**\n * Error class for the Firebase AI SDK.\n *\n * @public\n */\nexport class AIError extends FirebaseError {\n  /**\n   * Constructs a new instance of the `AIError` class.\n   *\n   * @param code - The error code from {@link (AIErrorCode:type)}.\n   * @param message - A human-readable message describing the error.\n   * @param customErrorData - Optional error data.\n   */\n  constructor(\n    readonly code: AIErrorCode,\n    message: string,\n    readonly customErrorData?: CustomErrorData\n  ) {\n    // Match error format used by FirebaseError from ErrorFactory\n    const service = AI_TYPE;\n    const fullCode = `${service}/${code}`;\n    const fullMessage = `${service}: ${message} (${fullCode})`;\n    super(code, fullMessage);\n\n    // FirebaseError initializes a stack trace, but it assumes the error is created from the error\n    // factory. Since we break this assumption, we set the stack trace to be originating from this\n    // constructor.\n    // This is only supported in V8.\n    if (Error.captureStackTrace) {\n      // Allows us to initialize the stack trace without including the constructor itself at the\n      // top level of the stack trace.\n      Error.captureStackTrace(this, AIError);\n    }\n\n    // Allows instanceof AIError in ES5/ES6\n    // https://github.com/Microsoft/TypeScript-wiki/blob/master/Breaking-Changes.md#extending-built-ins-like-error-array-and-map-may-no-longer-work\n    // TODO(dlarocque): Replace this with `new.target`: https://www.typescriptlang.org/docs/handbook/release-notes/typescript-2-2.html#support-for-newtarget\n    //                   which we can now use since we no longer target ES5.\n    Object.setPrototypeOf(this, AIError.prototype);\n\n    // Since Error is an interface, we don't inherit toString and so we define it ourselves.\n    this.toString = () => fullMessage;\n  }\n}\n", "/**\n * @license\n * Copyright 2024 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\n/**\n * Role is the producer of the content.\n * @public\n */\nexport type Role = (typeof POSSIBLE_ROLES)[number];\n\n/**\n * Possible roles.\n * @public\n */\nexport const POSSIBLE_ROLES = ['user', 'model', 'function', 'system'] as const;\n\n/**\n * Harm categories that would cause prompts or candidates to be blocked.\n * @public\n */\nexport const HarmCategory = {\n  HARM_CATEGORY_HATE_SPEECH: 'HARM_CATEGORY_HATE_SPEECH',\n  HARM_CATEGORY_SEXUALLY_EXPLICIT: 'HARM_CATEGORY_SEXUALLY_EXPLICIT',\n  HARM_CATEGORY_HARASSMENT: 'HARM_CATEGORY_HARASSMENT',\n  HARM_CATEGORY_DANGEROUS_CONTENT: 'HARM_CATEGORY_DANGEROUS_CONTENT'\n} as const;\n\n/**\n * Harm categories that would cause prompts or candidates to be blocked.\n * @public\n */\nexport type HarmCategory = (typeof HarmCategory)[keyof typeof HarmCategory];\n\n/**\n * Threshold above which a prompt or candidate will be blocked.\n * @public\n */\nexport const HarmBlockThreshold = {\n  /**\n   * Content with `NEGLIGIBLE` will be allowed.\n   */\n  BLOCK_LOW_AND_ABOVE: 'BLOCK_LOW_AND_ABOVE',\n  /**\n   * Content with `NEGLIGIBLE` and `LOW` will be allowed.\n   */\n  BLOCK_MEDIUM_AND_ABOVE: 'BLOCK_MEDIUM_AND_ABOVE',\n  /**\n   * Content with `NEGLIGIBLE`, `LOW`, and `MEDIUM` will be allowed.\n   */\n  BLOCK_ONLY_HIGH: 'BLOCK_ONLY_HIGH',\n  /**\n   * All content will be allowed.\n   */\n  BLOCK_NONE: 'BLOCK_NONE',\n  /**\n   * All content will be allowed. This is the same as `BLOCK_NONE`, but the metadata corresponding\n   * to the {@link (HarmCategory:type)} will not be present in the response.\n   */\n  OFF: 'OFF'\n} as const;\n\n/**\n * Threshold above which a prompt or candidate will be blocked.\n * @public\n */\nexport type HarmBlockThreshold =\n  (typeof HarmBlockThreshold)[keyof typeof HarmBlockThreshold];\n\n/**\n * This property is not supported in the Gemini Developer API ({@link GoogleAIBackend}).\n *\n * @public\n */\nexport const HarmBlockMethod = {\n  /**\n   * The harm block method uses both probability and severity scores.\n   */\n  SEVERITY: 'SEVERITY',\n  /**\n   * The harm block method uses the probability score.\n   */\n  PROBABILITY: 'PROBABILITY'\n} as const;\n\n/**\n * This property is not supported in the Gemini Developer API ({@link GoogleAIBackend}).\n *\n * @public\n */\nexport type HarmBlockMethod =\n  (typeof HarmBlockMethod)[keyof typeof HarmBlockMethod];\n\n/**\n * Probability that a prompt or candidate matches a harm category.\n * @public\n */\nexport const HarmProbability = {\n  /**\n   * Content has a negligible chance of being unsafe.\n   */\n  NEGLIGIBLE: 'NEGLIGIBLE',\n  /**\n   * Content has a low chance of being unsafe.\n   */\n  LOW: 'LOW',\n  /**\n   * Content has a medium chance of being unsafe.\n   */\n  MEDIUM: 'MEDIUM',\n  /**\n   * Content has a high chance of being unsafe.\n   */\n  HIGH: 'HIGH'\n} as const;\n\n/**\n * Probability that a prompt or candidate matches a harm category.\n * @public\n */\nexport type HarmProbability =\n  (typeof HarmProbability)[keyof typeof HarmProbability];\n\n/**\n * Harm severity levels.\n * @public\n */\nexport const HarmSeverity = {\n  /**\n   * Negligible level of harm severity.\n   */\n  HARM_SEVERITY_NEGLIGIBLE: 'HARM_SEVERITY_NEGLIGIBLE',\n  /**\n   * Low level of harm severity.\n   */\n  HARM_SEVERITY_LOW: 'HARM_SEVERITY_LOW',\n  /**\n   * Medium level of harm severity.\n   */\n  HARM_SEVERITY_MEDIUM: 'HARM_SEVERITY_MEDIUM',\n  /**\n   * High level of harm severity.\n   */\n  HARM_SEVERITY_HIGH: 'HARM_SEVERITY_HIGH',\n  /**\n   * Harm severity is not supported.\n   *\n   * @remarks\n   * The GoogleAI backend does not support `HarmSeverity`, so this value is used as a fallback.\n   */\n  HARM_SEVERITY_UNSUPPORTED: 'HARM_SEVERITY_UNSUPPORTED'\n} as const;\n\n/**\n * Harm severity levels.\n * @public\n */\nexport type HarmSeverity = (typeof HarmSeverity)[keyof typeof HarmSeverity];\n\n/**\n * Reason that a prompt was blocked.\n * @public\n */\nexport const BlockReason = {\n  /**\n   * Content was blocked by safety settings.\n   */\n  SAFETY: 'SAFETY',\n  /**\n   * Content was blocked, but the reason is uncategorized.\n   */\n  OTHER: 'OTHER',\n  /**\n   * Content was blocked because it contained terms from the terminology blocklist.\n   */\n  BLOCKLIST: 'BLOCKLIST',\n  /**\n   * Content was blocked due to prohibited content.\n   */\n  PROHIBITED_CONTENT: 'PROHIBITED_CONTENT'\n} as const;\n\n/**\n * Reason that a prompt was blocked.\n * @public\n */\nexport type BlockReason = (typeof BlockReason)[keyof typeof BlockReason];\n\n/**\n * Reason that a candidate finished.\n * @public\n */\nexport const FinishReason = {\n  /**\n   * Natural stop point of the model or provided stop sequence.\n   */\n  STOP: 'STOP',\n  /**\n   * The maximum number of tokens as specified in the request was reached.\n   */\n  MAX_TOKENS: 'MAX_TOKENS',\n  /**\n   * The candidate content was flagged for safety reasons.\n   */\n  SAFETY: 'SAFETY',\n  /**\n   * The candidate content was flagged for recitation reasons.\n   */\n  RECITATION: 'RECITATION',\n  /**\n   * Unknown reason.\n   */\n  OTHER: 'OTHER',\n  /**\n   * The candidate content contained forbidden terms.\n   */\n  BLOCKLIST: 'BLOCKLIST',\n  /**\n   * The candidate content potentially contained prohibited content.\n   */\n  PROHIBITED_CONTENT: 'PROHIBITED_CONTENT',\n  /**\n   * The candidate content potentially contained Sensitive Personally Identifiable Information (SPII).\n   */\n  SPII: 'SPII',\n  /**\n   * The function call generated by the model was invalid.\n   */\n  MALFORMED_FUNCTION_CALL: 'MALFORMED_FUNCTION_CALL'\n} as const;\n\n/**\n * Reason that a candidate finished.\n * @public\n */\nexport type FinishReason = (typeof FinishReason)[keyof typeof FinishReason];\n\n/**\n * @public\n */\nexport const FunctionCallingMode = {\n  /**\n   * Default model behavior; model decides to predict either a function call\n   * or a natural language response.\n   */\n  AUTO: 'AUTO',\n  /**\n   * Model is constrained to always predicting a function call only.\n   * If `allowed_function_names` is set, the predicted function call will be\n   * limited to any one of `allowed_function_names`, else the predicted\n   * function call will be any one of the provided `function_declarations`.\n   */\n  ANY: 'ANY',\n  /**\n   * Model will not predict any function call. Model behavior is same as when\n   * not passing any function declarations.\n   */\n  NONE: 'NONE'\n} as const;\n\n/**\n * @public\n */\nexport type FunctionCallingMode =\n  (typeof FunctionCallingMode)[keyof typeof FunctionCallingMode];\n\n/**\n * Content part modality.\n * @public\n */\nexport const Modality = {\n  /**\n   * Unspecified modality.\n   */\n  MODALITY_UNSPECIFIED: 'MODALITY_UNSPECIFIED',\n  /**\n   * Plain text.\n   */\n  TEXT: 'TEXT',\n  /**\n   * Image.\n   */\n  IMAGE: 'IMAGE',\n  /**\n   * Video.\n   */\n  VIDEO: 'VIDEO',\n  /**\n   * Audio.\n   */\n  AUDIO: 'AUDIO',\n  /**\n   * Document (for example, PDF).\n   */\n  DOCUMENT: 'DOCUMENT'\n} as const;\n\n/**\n * Content part modality.\n * @public\n */\nexport type Modality = (typeof Modality)[keyof typeof Modality];\n\n/**\n * Generation modalities to be returned in generation responses.\n *\n * @beta\n */\nexport const ResponseModality = {\n  /**\n   * Text.\n   * @beta\n   */\n  TEXT: 'TEXT',\n  /**\n   * Image.\n   * @beta\n   */\n  IMAGE: 'IMAGE',\n  /**\n   * Audio.\n   * @beta\n   */\n  AUDIO: 'AUDIO'\n} as const;\n\n/**\n * Generation modalities to be returned in generation responses.\n *\n * @beta\n */\nexport type ResponseModality =\n  (typeof ResponseModality)[keyof typeof ResponseModality];\n\n/**\n * Determines whether inference happens on-device or in-cloud.\n *\n * @remarks\n * <b>PREFER_ON_DEVICE:</b> Attempt to make inference calls using an\n * on-device model. If on-device inference is not available, the SDK\n * will fall back to using a cloud-hosted model.\n * <br/>\n * <b>ONLY_ON_DEVICE:</b> Only attempt to make inference calls using an\n * on-device model. The SDK will not fall back to a cloud-hosted model.\n * If on-device inference is not available, inference methods will throw.\n * <br/>\n * <b>ONLY_IN_CLOUD:</b> Only attempt to make inference calls using a\n * cloud-hosted model. The SDK will not fall back to an on-device model.\n * <br/>\n * <b>PREFER_IN_CLOUD:</b> Attempt to make inference calls to a\n * cloud-hosted model. If not available, the SDK will fall back to an\n * on-device model.\n *\n * @beta\n */\nexport const InferenceMode = {\n  'PREFER_ON_DEVICE': 'prefer_on_device',\n  'ONLY_ON_DEVICE': 'only_on_device',\n  'ONLY_IN_CLOUD': 'only_in_cloud',\n  'PREFER_IN_CLOUD': 'prefer_in_cloud'\n} as const;\n\n/**\n * Determines whether inference happens on-device or in-cloud.\n *\n * @beta\n */\nexport type InferenceMode = (typeof InferenceMode)[keyof typeof InferenceMode];\n\n/**\n * Indicates whether inference happened on-device or in-cloud.\n *\n * @beta\n */\nexport const InferenceSource = {\n  'ON_DEVICE': 'on_device',\n  'IN_CLOUD': 'in_cloud'\n} as const;\n\n/**\n * Indicates whether inference happened on-device or in-cloud.\n *\n * @beta\n */\nexport type InferenceSource =\n  (typeof InferenceSource)[keyof typeof InferenceSource];\n\n/**\n * Represents the result of the code execution.\n *\n * @beta\n */\nexport const Outcome = {\n  UNSPECIFIED: 'OUTCOME_UNSPECIFIED',\n  OK: 'OUTCOME_OK',\n  FAILED: 'OUTCOME_FAILED',\n  DEADLINE_EXCEEDED: 'OUTCOME_DEADLINE_EXCEEDED'\n};\n\n/**\n * Represents the result of the code execution.\n *\n * @beta\n */\nexport type Outcome = (typeof Outcome)[keyof typeof Outcome];\n\n/**\n * The programming language of the code.\n *\n * @beta\n */\nexport const Language = {\n  UNSPECIFIED: 'LANGUAGE_UNSPECIFIED',\n  PYTHON: 'PYTHON'\n};\n\n/**\n * The programming language of the code.\n *\n * @beta\n */\nexport type Language = (typeof Language)[keyof typeof Language];\n", "/**\n * @license\n * Copyright 2024 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { Content, FunctionCall, InlineDataPart } from './content';\nimport {\n  BlockReason,\n  FinishReason,\n  HarmCategory,\n  HarmProbability,\n  HarmSeverity,\n  InferenceSource,\n  Modality\n} from './enums';\n\n/**\n * Result object returned from {@link GenerativeModel.generateContent} call.\n *\n * @public\n */\nexport interface GenerateContentResult {\n  response: EnhancedGenerateContentResponse;\n}\n\n/**\n * Result object returned from {@link GenerativeModel.generateContentStream} call.\n * Iterate over `stream` to get chunks as they come in and/or\n * use the `response` promise to get the aggregated response when\n * the stream is done.\n *\n * @public\n */\nexport interface GenerateContentStreamResult {\n  stream: AsyncGenerator<EnhancedGenerateContentResponse>;\n  response: Promise<EnhancedGenerateContentResponse>;\n}\n\n/**\n * Response object wrapped with helper methods.\n *\n * @public\n */\nexport interface EnhancedGenerateContentResponse\n  extends GenerateContentResponse {\n  /**\n   * Returns the text string from the response, if available.\n   * Throws if the prompt or candidate was blocked.\n   */\n  text: () => string;\n  /**\n   * Aggregates and returns every {@link InlineDataPart} from the first candidate of\n   * {@link GenerateContentResponse}.\n   *\n   * @throws If the prompt or candidate was blocked.\n   */\n  inlineDataParts: () => InlineDataPart[] | undefined;\n  /**\n   * Aggregates and returns every {@link FunctionCall} from the first candidate of\n   * {@link GenerateContentResponse}.\n   *\n   * @throws If the prompt or candidate was blocked.\n   */\n  functionCalls: () => FunctionCall[] | undefined;\n  /**\n   * Aggregates and returns every {@link TextPart} with their `thought` property set\n   * to `true` from the first candidate of {@link GenerateContentResponse}.\n   *\n   * @throws If the prompt or candidate was blocked.\n   *\n   * @remarks\n   * Thought summaries provide a brief overview of the model's internal thinking process,\n   * offering insight into how it arrived at the final answer. This can be useful for\n   * debugging, understanding the model's reasoning, and verifying its accuracy.\n   *\n   * Thoughts will only be included if {@link ThinkingConfig.includeThoughts} is\n   * set to `true`.\n   */\n  thoughtSummary: () => string | undefined;\n  /**\n   * Indicates whether inference happened on-device or in-cloud.\n   *\n   * @beta\n   */\n  inferenceSource?: InferenceSource;\n}\n\n/**\n * Individual response from {@link GenerativeModel.generateContent} and\n * {@link GenerativeModel.generateContentStream}.\n * `generateContentStream()` will return one in each chunk until\n * the stream is done.\n * @public\n */\nexport interface GenerateContentResponse {\n  candidates?: GenerateContentCandidate[];\n  promptFeedback?: PromptFeedback;\n  usageMetadata?: UsageMetadata;\n}\n\n/**\n * Usage metadata about a {@link GenerateContentResponse}.\n *\n * @public\n */\nexport interface UsageMetadata {\n  promptTokenCount: number;\n  candidatesTokenCount: number;\n  /**\n   * The number of tokens used by the model's internal \"thinking\" process.\n   */\n  thoughtsTokenCount?: number;\n  totalTokenCount: number;\n  /**\n   * The number of tokens used by tools.\n   */\n  toolUsePromptTokenCount?: number;\n  promptTokensDetails?: ModalityTokenCount[];\n  candidatesTokensDetails?: ModalityTokenCount[];\n  /**\n   * A list of tokens used by tools, broken down by modality.\n   */\n  toolUsePromptTokensDetails?: ModalityTokenCount[];\n}\n\n/**\n * Represents token counting info for a single modality.\n *\n * @public\n */\nexport interface ModalityTokenCount {\n  /** The modality associated with this token count. */\n  modality: Modality;\n  /** The number of tokens counted. */\n  tokenCount: number;\n}\n\n/**\n * If the prompt was blocked, this will be populated with `blockReason` and\n * the relevant `safetyRatings`.\n * @public\n */\nexport interface PromptFeedback {\n  blockReason?: BlockReason;\n  safetyRatings: SafetyRating[];\n  /**\n   * A human-readable description of the `blockReason`.\n   *\n   * This property is only supported in the Vertex AI Gemini API ({@link VertexAIBackend}).\n   */\n  blockReasonMessage?: string;\n}\n\n/**\n * A candidate returned as part of a {@link GenerateContentResponse}.\n * @public\n */\nexport interface GenerateContentCandidate {\n  index: number;\n  content: Content;\n  finishReason?: FinishReason;\n  finishMessage?: string;\n  safetyRatings?: SafetyRating[];\n  citationMetadata?: CitationMetadata;\n  groundingMetadata?: GroundingMetadata;\n  urlContextMetadata?: URLContextMetadata;\n}\n\n/**\n * Citation metadata that may be found on a {@link GenerateContentCandidate}.\n * @public\n */\nexport interface CitationMetadata {\n  citations: Citation[];\n}\n\n/**\n * A single citation.\n * @public\n */\nexport interface Citation {\n  startIndex?: number;\n  endIndex?: number;\n  uri?: string;\n  license?: string;\n  /**\n   * The title of the cited source, if available.\n   *\n   * This property is only supported in the Vertex AI Gemini API ({@link VertexAIBackend}).\n   */\n  title?: string;\n  /**\n   * The publication date of the cited source, if available.\n   *\n   * This property is only supported in the Vertex AI Gemini API ({@link VertexAIBackend}).\n   */\n  publicationDate?: Date;\n}\n\n/**\n * Metadata returned when grounding is enabled.\n *\n * Currently, only Grounding with Google Search is supported (see {@link GoogleSearchTool}).\n *\n * Important: If using Grounding with Google Search, you are required to comply with the\n * \"Grounding with Google Search\" usage requirements for your chosen API provider: {@link https://ai.google.dev/gemini-api/terms#grounding-with-google-search | Gemini Developer API}\n * or Vertex AI Gemini API (see {@link https://cloud.google.com/terms/service-terms | Service Terms}\n * section within the Service Specific Terms).\n *\n * @public\n */\nexport interface GroundingMetadata {\n  /**\n   * Google Search entry point for web searches. This contains an HTML/CSS snippet that must be\n   * embedded in an app to display a Google Search entry point for follow-up web searches related to\n   * a model's \"Grounded Response\".\n   */\n  searchEntryPoint?: SearchEntrypoint;\n  /**\n   * A list of {@link GroundingChunk} objects. Each chunk represents a piece of retrieved content\n   * (for example, from a web page). that the model used to ground its response.\n   */\n  groundingChunks?: GroundingChunk[];\n  /**\n   * A list of {@link GroundingSupport} objects. Each object details how specific segments of the\n   * model's response are supported by the `groundingChunks`.\n   */\n  groundingSupports?: GroundingSupport[];\n  /**\n   * A list of web search queries that the model performed to gather the grounding information.\n   * These can be used to allow users to explore the search results themselves.\n   */\n  webSearchQueries?: string[];\n  /**\n   * @deprecated Use {@link GroundingSupport} instead.\n   */\n  retrievalQueries?: string[];\n}\n\n/**\n * Google search entry point.\n *\n * @public\n */\nexport interface SearchEntrypoint {\n  /**\n   * HTML/CSS snippet that must be embedded in a web page. The snippet is designed to avoid\n   * undesired interaction with the rest of the page's CSS.\n   *\n   * To ensure proper rendering and prevent CSS conflicts, it is recommended\n   * to encapsulate this `renderedContent` within a shadow DOM when embedding it\n   * into a webpage. See {@link https://developer.mozilla.org/en-US/docs/Web/API/Web_components/Using_shadow_DOM | MDN: Using shadow DOM}.\n   *\n   * @example\n   * ```javascript\n   * const container = document.createElement('div');\n   * document.body.appendChild(container);\n   * container.attachShadow({ mode: 'open' }).innerHTML = renderedContent;\n   * ```\n   */\n  renderedContent?: string;\n}\n\n/**\n * Represents a chunk of retrieved data that supports a claim in the model's response. This is part\n * of the grounding information provided when grounding is enabled.\n *\n * @public\n */\nexport interface GroundingChunk {\n  /**\n   * Contains details if the grounding chunk is from a web source.\n   */\n  web?: WebGroundingChunk;\n}\n\n/**\n * A grounding chunk from the web.\n *\n * Important: If using Grounding with Google Search, you are required to comply with the\n * {@link https://cloud.google.com/terms/service-terms | Service Specific Terms} for \"Grounding with Google Search\".\n *\n * @public\n */\nexport interface WebGroundingChunk {\n  /**\n   * The URI of the retrieved web page.\n   */\n  uri?: string;\n  /**\n   * The title of the retrieved web page.\n   */\n  title?: string;\n  /**\n   * The domain of the original URI from which the content was retrieved.\n   *\n   * This property is only supported in the Vertex AI Gemini API ({@link VertexAIBackend}).\n   * When using the Gemini Developer API ({@link GoogleAIBackend}), this property will be\n   * `undefined`.\n   */\n  domain?: string;\n}\n\n/**\n * Provides information about how a specific segment of the model's response is supported by the\n * retrieved grounding chunks.\n *\n * @public\n */\nexport interface GroundingSupport {\n  /**\n   * Specifies the segment of the model's response content that this grounding support pertains to.\n   */\n  segment?: Segment;\n  /**\n   * A list of indices that refer to specific {@link GroundingChunk} objects within the\n   * {@link GroundingMetadata.groundingChunks} array. These referenced chunks\n   * are the sources that support the claim made in the associated `segment` of the response.\n   * For example, an array `[1, 3, 4]` means that `groundingChunks[1]`, `groundingChunks[3]`,\n   * and `groundingChunks[4]` are the retrieved content supporting this part of the response.\n   */\n  groundingChunkIndices?: number[];\n}\n\n/**\n * Represents a specific segment within a {@link Content} object, often used to\n * pinpoint the exact location of text or data that grounding information refers to.\n *\n * @public\n */\nexport interface Segment {\n  /**\n   * The zero-based index of the {@link Part} object within the `parts` array\n   * of its parent {@link Content} object. This identifies which part of the\n   * content the segment belongs to.\n   */\n  partIndex: number;\n  /**\n   * The zero-based start index of the segment within the specified `Part`,\n   * measured in UTF-8 bytes. This offset is inclusive, starting from 0 at the\n   * beginning of the part's content (e.g., `Part.text`).\n   */\n  startIndex: number;\n  /**\n   * The zero-based end index of the segment within the specified `Part`,\n   * measured in UTF-8 bytes. This offset is exclusive, meaning the character\n   * at this index is not included in the segment.\n   */\n  endIndex: number;\n  /**\n   * The text corresponding to the segment from the response.\n   */\n  text: string;\n}\n\n/**\n * Metadata related to {@link URLContextTool}.\n *\n * @beta\n */\nexport interface URLContextMetadata {\n  /**\n   * List of URL metadata used to provide context to the Gemini model.\n   */\n  urlMetadata: URLMetadata[];\n}\n\n/**\n * Metadata for a single URL retrieved by the {@link URLContextTool} tool.\n *\n * @beta\n */\nexport interface URLMetadata {\n  /**\n   * The retrieved URL.\n   */\n  retrievedUrl?: string;\n  /**\n   * The status of the URL retrieval.\n   */\n  urlRetrievalStatus?: URLRetrievalStatus;\n}\n\n/**\n * The status of a URL retrieval.\n *\n * @remarks\n * <b>URL_RETRIEVAL_STATUS_UNSPECIFIED:</b> Unspecified retrieval status.\n * <br/>\n * <b>URL_RETRIEVAL_STATUS_SUCCESS:</b> The URL retrieval was successful.\n * <br/>\n * <b>URL_RETRIEVAL_STATUS_ERROR:</b> The URL retrieval failed.\n * <br/>\n * <b>URL_RETRIEVAL_STATUS_PAYWALL:</b> The URL retrieval failed because the content is behind a paywall.\n * <br/>\n * <b>URL_RETRIEVAL_STATUS_UNSAFE:</b> The URL retrieval failed because the content is unsafe.\n * <br/>\n *\n * @beta\n */\nexport const URLRetrievalStatus = {\n  /**\n   * Unspecified retrieval status.\n   */\n  URL_RETRIEVAL_STATUS_UNSPECIFIED: 'URL_RETRIEVAL_STATUS_UNSPECIFIED',\n  /**\n   * The URL retrieval was successful.\n   */\n  URL_RETRIEVAL_STATUS_SUCCESS: 'URL_RETRIEVAL_STATUS_SUCCESS',\n  /**\n   * The URL retrieval failed.\n   */\n  URL_RETRIEVAL_STATUS_ERROR: 'URL_RETRIEVAL_STATUS_ERROR',\n  /**\n   * The URL retrieval failed because the content is behind a paywall.\n   */\n  URL_RETRIEVAL_STATUS_PAYWALL: 'URL_RETRIEVAL_STATUS_PAYWALL',\n  /**\n   * The URL retrieval failed because the content is unsafe.\n   */\n  URL_RETRIEVAL_STATUS_UNSAFE: 'URL_RETRIEVAL_STATUS_UNSAFE'\n};\n\n/**\n * The status of a URL retrieval.\n *\n * @remarks\n * <b>URL_RETRIEVAL_STATUS_UNSPECIFIED:</b> Unspecified retrieval status.\n * <br/>\n * <b>URL_RETRIEVAL_STATUS_SUCCESS:</b> The URL retrieval was successful.\n * <br/>\n * <b>URL_RETRIEVAL_STATUS_ERROR:</b> The URL retrieval failed.\n * <br/>\n * <b>URL_RETRIEVAL_STATUS_PAYWALL:</b> The URL retrieval failed because the content is behind a paywall.\n * <br/>\n * <b>URL_RETRIEVAL_STATUS_UNSAFE:</b> The URL retrieval failed because the content is unsafe.\n * <br/>\n *\n * @beta\n */\nexport type URLRetrievalStatus =\n  (typeof URLRetrievalStatus)[keyof typeof URLRetrievalStatus];\n\n/**\n * @public\n */\nexport interface WebAttribution {\n  uri: string;\n  title: string;\n}\n\n/**\n * @public\n */\nexport interface RetrievedContextAttribution {\n  uri: string;\n  title: string;\n}\n\n/**\n * Protobuf google.type.Date\n * @public\n */\nexport interface Date {\n  year: number;\n  month: number;\n  day: number;\n}\n\n/**\n * A safety rating associated with a {@link GenerateContentCandidate}\n * @public\n */\nexport interface SafetyRating {\n  category: HarmCategory;\n  probability: HarmProbability;\n  /**\n   * The harm severity level.\n   *\n   * This property is only supported when using the Vertex AI Gemini API ({@link VertexAIBackend}).\n   * When using the Gemini Developer API ({@link GoogleAIBackend}), this property is not supported and will default to `HarmSeverity.UNSUPPORTED`.\n   */\n  severity: HarmSeverity;\n  /**\n   * The probability score of the harm category.\n   *\n   * This property is only supported when using the Vertex AI Gemini API ({@link VertexAIBackend}).\n   * When using the Gemini Developer API ({@link GoogleAIBackend}), this property is not supported and will default to 0.\n   */\n  probabilityScore: number;\n  /**\n   * The severity score of the harm category.\n   *\n   * This property is only supported when using the Vertex AI Gemini API ({@link VertexAIBackend}).\n   * When using the Gemini Developer API ({@link GoogleAIBackend}), this property is not supported and will default to 0.\n   */\n  severityScore: number;\n  blocked: boolean;\n}\n\n/**\n * Response from calling {@link GenerativeModel.countTokens}.\n * @public\n */\nexport interface CountTokensResponse {\n  /**\n   * The total number of tokens counted across all instances from the request.\n   */\n  totalTokens: number;\n  /**\n   * @deprecated Use `totalTokens` instead. This property is undefined when using models greater than `gemini-1.5-*`.\n   *\n   * The total number of billable characters counted across all instances\n   * from the request.\n   */\n  totalBillableCharacters?: number;\n  /**\n   * The breakdown, by modality, of how many tokens are consumed by the prompt.\n   */\n  promptTokensDetails?: ModalityTokenCount[];\n}\n\n/**\n * An incremental content update from the model.\n *\n * @beta\n */\nexport interface LiveServerContent {\n  type: 'serverContent';\n  /**\n   * The content that the model has generated as part of the current conversation with the user.\n   */\n  modelTurn?: Content;\n  /**\n   * Indicates whether the turn is complete. This is `undefined` if the turn is not complete.\n   */\n  turnComplete?: boolean;\n  /**\n   * Indicates whether the model was interrupted by the client. An interruption occurs when\n   * the client sends a message before the model finishes it's turn. This is `undefined` if the\n   * model was not interrupted.\n   */\n  interrupted?: boolean;\n  /**\n   * Transcription of the audio that was input to the model.\n   */\n  inputTranscription?: Transcription;\n  /**\n   * Transcription of the audio output from the model.\n   */\n  outputTranscription?: Transcription;\n}\n\n/**\n * Transcription of audio. This can be returned from a {@link LiveGenerativeModel} if transcription\n * is enabled with the `inputAudioTranscription` or `outputAudioTranscription` properties on\n * the {@link LiveGenerationConfig}.\n *\n * @beta\n */\n\nexport interface Transcription {\n  /**\n   * The text transcription of the audio.\n   */\n  text?: string;\n}\n\n/**\n * A request from the model for the client to execute one or more functions.\n *\n * @beta\n */\nexport interface LiveServerToolCall {\n  type: 'toolCall';\n  /**\n   * An array of function calls to run.\n   */\n  functionCalls: FunctionCall[];\n}\n\n/**\n * Notification to cancel a previous function call triggered by {@link LiveServerToolCall}.\n *\n * @beta\n */\nexport interface LiveServerToolCallCancellation {\n  type: 'toolCallCancellation';\n  /**\n   * IDs of function calls that were cancelled. These refer to the `id` property of a {@link FunctionCall}.\n   */\n  functionIds: string[];\n}\n\n/**\n * The types of responses that can be returned by {@link LiveSession.receive}.\n *\n * @beta\n */\nexport const LiveResponseType = {\n  SERVER_CONTENT: 'serverContent',\n  TOOL_CALL: 'toolCall',\n  TOOL_CALL_CANCELLATION: 'toolCallCancellation'\n};\n\n/**\n * The types of responses that can be returned by {@link LiveSession.receive}.\n * This is a property on all messages that can be used for type narrowing. This property is not\n * returned by the server, it is assigned to a server message object once it's parsed.\n *\n * @beta\n */\nexport type LiveResponseType =\n  (typeof LiveResponseType)[keyof typeof LiveResponseType];\n", "/**\n * @license\n * Copyright 2024 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { GenerateContentResponse } from './responses';\n\n/**\n * Details object that may be included in an error response.\n *\n * @public\n */\nexport interface ErrorDetails {\n  '@type'?: string;\n\n  /** The reason for the error. */\n  reason?: string;\n\n  /** The domain where the error occurred. */\n  domain?: string;\n\n  /** Additional metadata about the error. */\n  metadata?: Record<string, unknown>;\n\n  /** Any other relevant information about the error. */\n  [key: string]: unknown;\n}\n\n/**\n * Details object that contains data originating from a bad HTTP response.\n *\n * @public\n */\nexport interface CustomErrorData {\n  /** HTTP status code of the error response. */\n  status?: number;\n\n  /** HTTP status text of the error response. */\n  statusText?: string;\n\n  /** Response from a {@link GenerateContentRequest} */\n  response?: GenerateContentResponse;\n\n  /** Optional additional details about the error. */\n  errorDetails?: ErrorDetails[];\n}\n\n/**\n * Standardized error codes that {@link AIError} can have.\n *\n * @public\n */\nexport const AIErrorCode = {\n  /** A generic error occurred. */\n  ERROR: 'error',\n\n  /** An error occurred in a request. */\n  REQUEST_ERROR: 'request-error',\n\n  /** An error occurred in a response. */\n  RESPONSE_ERROR: 'response-error',\n\n  /** An error occurred while performing a fetch. */\n  FETCH_ERROR: 'fetch-error',\n\n  /** An error occurred because an operation was attempted on a closed session. */\n  SESSION_CLOSED: 'session-closed',\n\n  /** An error associated with a Content object.  */\n  INVALID_CONTENT: 'invalid-content',\n\n  /** An error due to the Firebase API not being enabled in the Console. */\n  API_NOT_ENABLED: 'api-not-enabled',\n\n  /** An error due to invalid Schema input.  */\n  INVALID_SCHEMA: 'invalid-schema',\n\n  /** An error occurred due to a missing Firebase API key. */\n  NO_API_KEY: 'no-api-key',\n\n  /** An error occurred due to a missing Firebase app ID. */\n  NO_APP_ID: 'no-app-id',\n\n  /** An error occurred due to a model name not being specified during initialization. */\n  NO_MODEL: 'no-model',\n\n  /** An error occurred due to a missing project ID. */\n  NO_PROJECT_ID: 'no-project-id',\n\n  /** An error occurred while parsing. */\n  PARSE_FAILED: 'parse-failed',\n\n  /** An error occurred due an attempt to use an unsupported feature. */\n  UNSUPPORTED: 'unsupported'\n} as const;\n\n/**\n * Standardized error codes that {@link AIError} can have.\n *\n * @public\n */\nexport type AIErrorCode = (typeof AIErrorCode)[keyof typeof AIErrorCode];\n", "/**\n * @license\n * Copyright 2024 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\n/**\n * Contains the list of OpenAPI data types\n * as defined by the\n * {@link https://swagger.io/docs/specification/data-models/data-types/ | OpenAPI specification}\n * @public\n */\nexport const SchemaType = {\n  /** String type. */\n  STRING: 'string',\n  /** Number type. */\n  NUMBER: 'number',\n  /** Integer type. */\n  INTEGER: 'integer',\n  /** Boolean type. */\n  BOOLEAN: 'boolean',\n  /** Array type. */\n  ARRAY: 'array',\n  /** Object type. */\n  OBJECT: 'object'\n} as const;\n\n/**\n * Contains the list of OpenAPI data types\n * as defined by the\n * {@link https://swagger.io/docs/specification/data-models/data-types/ | OpenAPI specification}\n * @public\n */\nexport type SchemaType = (typeof SchemaType)[keyof typeof SchemaType];\n\n/**\n * Basic {@link Schema} properties shared across several Schema-related\n * types.\n * @public\n */\nexport interface SchemaShared<T> {\n  /**\n   * An array of {@link Schema}. The generated data must be valid against any of the schemas\n   * listed in this array. This allows specifying multiple possible structures or types for a\n   * single field.\n   */\n  anyOf?: T[];\n  /** Optional. The format of the property.\n   * When using the Gemini Developer API ({@link GoogleAIBackend}), this must be either `'enum'` or\n   * `'date-time'`, otherwise requests will fail.\n   */\n  format?: string;\n  /** Optional. The description of the property. */\n  description?: string;\n  /**\n   * The title of the property. This helps document the schema's purpose but does not typically\n   * constrain the generated value. It can subtly guide the model by clarifying the intent of a\n   * field.\n   */\n  title?: string;\n  /** Optional. The items of the property. */\n  items?: T;\n  /** The minimum number of items (elements) in a schema of {@link (SchemaType:type)} `array`. */\n  minItems?: number;\n  /** The maximum number of items (elements) in a schema of {@link (SchemaType:type)} `array`. */\n  maxItems?: number;\n  /** Optional. Map of `Schema` objects. */\n  properties?: {\n    [k: string]: T;\n  };\n  /** A hint suggesting the order in which the keys should appear in the generated JSON string. */\n  propertyOrdering?: string[];\n  /** Optional. The enum of the property. */\n  enum?: string[];\n  /** Optional. The example of the property. */\n  example?: unknown;\n  /** Optional. Whether the property is nullable. */\n  nullable?: boolean;\n  /** The minimum value of a numeric type. */\n  minimum?: number;\n  /** The maximum value of a numeric type. */\n  maximum?: number;\n  [key: string]: unknown;\n}\n\n/**\n * Params passed to {@link Schema} static methods to create specific\n * {@link Schema} classes.\n * @public\n */\nexport interface SchemaParams extends SchemaShared<SchemaInterface> {}\n\n/**\n * Final format for {@link Schema} params passed to backend requests.\n * @public\n */\nexport interface SchemaRequest extends SchemaShared<SchemaRequest> {\n  /**\n   * The type of the property. this can only be undefined when using `anyOf` schemas,\n   * which do not have an explicit type in the {@link https://swagger.io/docs/specification/v3_0/data-models/data-types/#any-type | OpenAPI specification }.\n   */\n  type?: SchemaType;\n  /** Optional. Array of required property. */\n  required?: string[];\n}\n\n/**\n * Interface for {@link Schema} class.\n * @public\n */\nexport interface SchemaInterface extends SchemaShared<SchemaInterface> {\n  /**\n   * The type of the property. this can only be undefined when using `anyof` schemas,\n   * which do not have an explicit type in the {@link https://swagger.io/docs/specification/v3_0/data-models/data-types/#any-type | OpenAPI Specification}.\n   */\n  type?: SchemaType;\n}\n\n/**\n * Interface for JSON parameters in a schema of {@link (SchemaType:type)}\n * \"object\" when not using the `Schema.object()` helper.\n * @public\n */\nexport interface ObjectSchemaRequest extends SchemaRequest {\n  type: 'object';\n  /**\n   * This is not a property accepted in the final request to the backend, but is\n   * a client-side convenience property that is only usable by constructing\n   * a schema through the `Schema.object()` helper method. Populating this\n   * property will cause response errors if the object is not wrapped with\n   * `Schema.object()`.\n   */\n  optionalProperties?: never;\n}\n", "/**\n * @license\n * Copyright 2025 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { ImagenImageFormat } from '../../requests/imagen-image-format';\n\n/**\n * Parameters for configuring an {@link ImagenModel}.\n *\n * @public\n */\nexport interface ImagenModelParams {\n  /**\n   * The Imagen model to use for generating images.\n   * For example: `imagen-3.0-generate-002`.\n   *\n   * Only Imagen 3 models (named `imagen-3.0-*`) are supported.\n   *\n   * See {@link https://firebase.google.com/docs/vertex-ai/models | model versions}\n   * for a full list of supported Imagen 3 models.\n   */\n  model: string;\n  /**\n   * Configuration options for generating images with Imagen.\n   */\n  generationConfig?: ImagenGenerationConfig;\n  /**\n   * Safety settings for filtering potentially inappropriate content.\n   */\n  safetySettings?: ImagenSafetySettings;\n}\n\n/**\n * Configuration options for generating images with Imagen.\n *\n * See the {@link http://firebase.google.com/docs/vertex-ai/generate-images-imagen | documentation} for\n * more details.\n *\n * @public\n */\nexport interface ImagenGenerationConfig {\n  /**\n   * A description of what should be omitted from the generated images.\n   *\n   * Support for negative prompts depends on the Imagen model.\n   *\n   * See the {@link http://firebase.google.com/docs/vertex-ai/model-parameters#imagen | documentation} for more details.\n   *\n   * This is no longer supported in the Gemini Developer API ({@link GoogleAIBackend}) in versions\n   * greater than `imagen-3.0-generate-002`.\n   */\n  negativePrompt?: string;\n  /**\n   * The number of images to generate. The default value is 1.\n   *\n   * The number of sample images that may be generated in each request depends on the model\n   * (typically up to 4); see the <a href=\"http://firebase.google.com/docs/vertex-ai/model-parameters#imagen\">sampleCount</a>\n   * documentation for more details.\n   */\n  numberOfImages?: number;\n  /**\n   * The aspect ratio of the generated images. The default value is square 1:1.\n   * Supported aspect ratios depend on the Imagen model, see {@link (ImagenAspectRatio:type)}\n   * for more details.\n   */\n  aspectRatio?: ImagenAspectRatio;\n  /**\n   * The image format of the generated images. The default is PNG.\n   *\n   * See {@link ImagenImageFormat} for more details.\n   */\n  imageFormat?: ImagenImageFormat;\n  /**\n   * Whether to add an invisible watermark to generated images.\n   *\n   * If set to `true`, an invisible SynthID watermark is embedded in generated images to indicate\n   * that they are AI generated. If set to `false`, watermarking will be disabled.\n   *\n   * For Imagen 3 models, the default value is `true`; see the <a href=\"http://firebase.google.com/docs/vertex-ai/model-parameters#imagen\">addWatermark</a>\n   * documentation for more details.\n   *\n   * When using the Gemini Developer API ({@link GoogleAIBackend}), this will default to true,\n   * and cannot be turned off.\n   */\n  addWatermark?: boolean;\n}\n\n/**\n * A filter level controlling how aggressively to filter sensitive content.\n *\n * Text prompts provided as inputs and images (generated or uploaded) through Imagen on Vertex AI\n * are assessed against a list of safety filters, which include 'harmful categories' (for example,\n * `violence`, `sexual`, `derogatory`, and `toxic`). This filter level controls how aggressively to\n * filter out potentially harmful content from responses. See the {@link http://firebase.google.com/docs/vertex-ai/generate-images | documentation }\n * and the {@link https://cloud.google.com/vertex-ai/generative-ai/docs/image/responsible-ai-imagen#safety-filters | Responsible AI and usage guidelines}\n * for more details.\n *\n * @public\n */\nexport const ImagenSafetyFilterLevel = {\n  /**\n   * The most aggressive filtering level; most strict blocking.\n   */\n  BLOCK_LOW_AND_ABOVE: 'block_low_and_above',\n  /**\n   * Blocks some sensitive prompts and responses.\n   */\n  BLOCK_MEDIUM_AND_ABOVE: 'block_medium_and_above',\n  /**\n   * Blocks few sensitive prompts and responses.\n   */\n  BLOCK_ONLY_HIGH: 'block_only_high',\n  /**\n   * The least aggressive filtering level; blocks very few sensitive prompts and responses.\n   *\n   * Access to this feature is restricted and may require your case to be reviewed and approved by\n   * Cloud support.\n   */\n  BLOCK_NONE: 'block_none'\n} as const;\n\n/**\n * A filter level controlling how aggressively to filter sensitive content.\n *\n * Text prompts provided as inputs and images (generated or uploaded) through Imagen on Vertex AI\n * are assessed against a list of safety filters, which include 'harmful categories' (for example,\n * `violence`, `sexual`, `derogatory`, and `toxic`). This filter level controls how aggressively to\n * filter out potentially harmful content from responses. See the {@link http://firebase.google.com/docs/vertex-ai/generate-images | documentation }\n * and the {@link https://cloud.google.com/vertex-ai/generative-ai/docs/image/responsible-ai-imagen#safety-filters | Responsible AI and usage guidelines}\n * for more details.\n *\n * @public\n */\nexport type ImagenSafetyFilterLevel =\n  (typeof ImagenSafetyFilterLevel)[keyof typeof ImagenSafetyFilterLevel];\n\n/**\n * A filter level controlling whether generation of images containing people or faces is allowed.\n *\n * See the <a href=\"http://firebase.google.com/docs/vertex-ai/generate-images\">personGeneration</a>\n * documentation for more details.\n *\n * @public\n */\nexport const ImagenPersonFilterLevel = {\n  /**\n   * Disallow generation of images containing people or faces; images of people are filtered out.\n   */\n  BLOCK_ALL: 'dont_allow',\n  /**\n   * Allow generation of images containing adults only; images of children are filtered out.\n   *\n   * Generation of images containing people or faces may require your use case to be\n   * reviewed and approved by Cloud support; see the {@link https://cloud.google.com/vertex-ai/generative-ai/docs/image/responsible-ai-imagen#person-face-gen | Responsible AI and usage guidelines}\n   * for more details.\n   */\n  ALLOW_ADULT: 'allow_adult',\n  /**\n   * Allow generation of images containing adults only; images of children are filtered out.\n   *\n   * Generation of images containing people or faces may require your use case to be\n   * reviewed and approved by Cloud support; see the {@link https://cloud.google.com/vertex-ai/generative-ai/docs/image/responsible-ai-imagen#person-face-gen | Responsible AI and usage guidelines}\n   * for more details.\n   */\n  ALLOW_ALL: 'allow_all'\n} as const;\n\n/**\n * A filter level controlling whether generation of images containing people or faces is allowed.\n *\n * See the <a href=\"http://firebase.google.com/docs/vertex-ai/generate-images\">personGeneration</a>\n * documentation for more details.\n *\n * @public\n */\nexport type ImagenPersonFilterLevel =\n  (typeof ImagenPersonFilterLevel)[keyof typeof ImagenPersonFilterLevel];\n\n/**\n * Settings for controlling the aggressiveness of filtering out sensitive content.\n *\n * See the {@link http://firebase.google.com/docs/vertex-ai/generate-images | documentation }\n * for more details.\n *\n * @public\n */\nexport interface ImagenSafetySettings {\n  /**\n   * A filter level controlling how aggressive to filter out sensitive content from generated\n   * images.\n   */\n  safetyFilterLevel?: ImagenSafetyFilterLevel;\n  /**\n   * A filter level controlling whether generation of images containing people or faces is allowed.\n   */\n  personFilterLevel?: ImagenPersonFilterLevel;\n}\n\n/**\n * Aspect ratios for Imagen images.\n *\n * To specify an aspect ratio for generated images, set the `aspectRatio` property in your\n * {@link ImagenGenerationConfig}.\n *\n * See the {@link http://firebase.google.com/docs/vertex-ai/generate-images | documentation }\n * for more details and examples of the supported aspect ratios.\n *\n * @public\n */\nexport const ImagenAspectRatio = {\n  /**\n   * Square (1:1) aspect ratio.\n   */\n  'SQUARE': '1:1',\n  /**\n   * Landscape (3:4) aspect ratio.\n   */\n  'LANDSCAPE_3x4': '3:4',\n  /**\n   * Portrait (4:3) aspect ratio.\n   */\n  'PORTRAIT_4x3': '4:3',\n  /**\n   * Landscape (16:9) aspect ratio.\n   */\n  'LANDSCAPE_16x9': '16:9',\n  /**\n   * Portrait (9:16) aspect ratio.\n   */\n  'PORTRAIT_9x16': '9:16'\n} as const;\n\n/**\n * Aspect ratios for Imagen images.\n *\n * To specify an aspect ratio for generated images, set the `aspectRatio` property in your\n * {@link ImagenGenerationConfig}.\n *\n * See the {@link http://firebase.google.com/docs/vertex-ai/generate-images | documentation }\n * for more details and examples of the supported aspect ratios.\n *\n * @public\n */\nexport type ImagenAspectRatio =\n  (typeof ImagenAspectRatio)[keyof typeof ImagenAspectRatio];\n", "/**\n * @license\n * Copyright 2024 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { FirebaseApp } from '@firebase/app';\nimport { Backend } from './backend';\n\nexport * from './types';\n\n/**\n * An instance of the Firebase AI SDK.\n *\n * Do not create this instance directly. Instead, use {@link getAI | getAI()}.\n *\n * @public\n */\nexport interface AI {\n  /**\n   * The {@link @firebase/app#FirebaseApp} this {@link AI} instance is associated with.\n   */\n  app: FirebaseApp;\n  /**\n   * A {@link Backend} instance that specifies the configuration for the target backend,\n   * either the Gemini Developer API (using {@link GoogleAIBackend}) or the\n   * Vertex AI Gemini API (using {@link VertexAIBackend}).\n   */\n  backend: Backend;\n  /**\n   * Options applied to this {@link AI} instance.\n   */\n  options?: AIOptions;\n  /**\n   * @deprecated use `AI.backend.location` instead.\n   *\n   * The location configured for this AI service instance, relevant for Vertex AI backends.\n   */\n  location: string;\n}\n\n/**\n * An enum-like object containing constants that represent the supported backends\n * for the Firebase AI SDK.\n * This determines which backend service (Vertex AI Gemini API or Gemini Developer API)\n * the SDK will communicate with.\n *\n * These values are assigned to the `backendType` property within the specific backend\n * configuration objects ({@link GoogleAIBackend} or {@link VertexAIBackend}) to identify\n * which service to target.\n *\n * @public\n */\nexport const BackendType = {\n  /**\n   * Identifies the backend service for the Vertex AI Gemini API provided through Google Cloud.\n   * Use this constant when creating a {@link VertexAIBackend} configuration.\n   */\n  VERTEX_AI: 'VERTEX_AI',\n\n  /**\n   * Identifies the backend service for the Gemini Developer API ({@link https://ai.google/ | Google AI}).\n   * Use this constant when creating a {@link GoogleAIBackend} configuration.\n   */\n  GOOGLE_AI: 'GOOGLE_AI'\n} as const; // Using 'as const' makes the string values literal types\n\n/**\n * Type alias representing valid backend types.\n * It can be either `'VERTEX_AI'` or `'GOOGLE_AI'`.\n *\n * @public\n */\nexport type BackendType = (typeof BackendType)[keyof typeof BackendType];\n\n/**\n * Options for initializing the AI service using {@link getAI | getAI()}.\n * This allows specifying which backend to use (Vertex AI Gemini API or Gemini Developer API)\n * and configuring its specific options (like location for Vertex AI).\n *\n * @public\n */\nexport interface AIOptions {\n  /**\n   * The backend configuration to use for the AI service instance.\n   * Defaults to the Gemini Developer API backend ({@link GoogleAIBackend}).\n   */\n  backend?: Backend;\n  /**\n   * Whether to use App Check limited use tokens. Defaults to false.\n   */\n  useLimitedUseAppCheckTokens?: boolean;\n}\n", "/**\n * @license\n * Copyright 2025 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { DEFAULT_API_VERSION, DEFAULT_LOCATION } from './constants';\nimport { BackendType } from './public-types';\n\n/**\n * Abstract base class representing the configuration for an AI service backend.\n * This class should not be instantiated directly. Use its subclasses; {@link GoogleAIBackend} for\n * the Gemini Developer API (via {@link https://ai.google/ | Google AI}), and\n * {@link VertexAIBackend} for the Vertex AI Gemini API.\n *\n * @public\n */\nexport abstract class Backend {\n  /**\n   * Specifies the backend type.\n   */\n  readonly backendType: BackendType;\n\n  /**\n   * Protected constructor for use by subclasses.\n   * @param type - The backend type.\n   */\n  protected constructor(type: BackendType) {\n    this.backendType = type;\n  }\n\n  /**\n   * @internal\n   */\n  abstract _getModelPath(project: string, model: string): string;\n\n  /**\n   * @internal\n   */\n  abstract _getTemplatePath(project: string, templateId: string): string;\n}\n\n/**\n * Configuration class for the Gemini Developer API.\n *\n * Use this with {@link AIOptions} when initializing the AI service via\n * {@link getAI | getAI()} to specify the Gemini Developer API as the backend.\n *\n * @public\n */\nexport class GoogleAIBackend extends Backend {\n  /**\n   * Creates a configuration object for the Gemini Developer API backend.\n   */\n  constructor() {\n    super(BackendType.GOOGLE_AI);\n  }\n\n  /**\n   * @internal\n   */\n  _getModelPath(project: string, model: string): string {\n    return `/${DEFAULT_API_VERSION}/projects/${project}/${model}`;\n  }\n\n  /**\n   * @internal\n   */\n  _getTemplatePath(project: string, templateId: string): string {\n    return `/${DEFAULT_API_VERSION}/projects/${project}/templates/${templateId}`;\n  }\n}\n\n/**\n * Configuration class for the Vertex AI Gemini API.\n *\n * Use this with {@link AIOptions} when initializing the AI service via\n * {@link getAI | getAI()} to specify the Vertex AI Gemini API as the backend.\n *\n * @public\n */\nexport class VertexAIBackend extends Backend {\n  /**\n   * The region identifier.\n   * See {@link https://firebase.google.com/docs/vertex-ai/locations#available-locations | Vertex AI locations}\n   * for a list of supported locations.\n   */\n  readonly location: string;\n\n  /**\n   * Creates a configuration object for the Vertex AI backend.\n   *\n   * @param location - The region identifier, defaulting to `us-central1`;\n   * see {@link https://firebase.google.com/docs/vertex-ai/locations#available-locations | Vertex AI locations}\n   * for a list of supported locations.\n   */\n  constructor(location: string = DEFAULT_LOCATION) {\n    super(BackendType.VERTEX_AI);\n    if (!location) {\n      this.location = DEFAULT_LOCATION;\n    } else {\n      this.location = location;\n    }\n  }\n\n  /**\n   * @internal\n   */\n  _getModelPath(project: string, model: string): string {\n    return `/${DEFAULT_API_VERSION}/projects/${project}/locations/${this.location}/${model}`;\n  }\n\n  /**\n   * @internal\n   */\n  _getTemplatePath(project: string, templateId: string): string {\n    return `/${DEFAULT_API_VERSION}/projects/${project}/locations/${this.location}/templates/${templateId}`;\n  }\n}\n", "/**\n * @license\n * Copyright 2025 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { AI_TYPE } from './constants';\nimport { AIError } from './errors';\nimport { AIErrorCode } from './types';\nimport { Backend, GoogleAIBackend, VertexAIBackend } from './backend';\n\n/**\n * Encodes a {@link Backend} into a string that will be used to uniquely identify {@link AI}\n * instances by backend type.\n *\n * @internal\n */\nexport function encodeInstanceIdentifier(backend: Backend): string {\n  if (backend instanceof GoogleAIBackend) {\n    return `${AI_TYPE}/googleai`;\n  } else if (backend instanceof VertexAIBackend) {\n    return `${AI_TYPE}/vertexai/${backend.location}`;\n  } else {\n    throw new AIError(\n      AIErrorCode.ERROR,\n      `Invalid backend: ${JSON.stringify(backend.backendType)}`\n    );\n  }\n}\n\n/**\n * Decodes an instance identifier string into a {@link Backend}.\n *\n * @internal\n */\nexport function decodeInstanceIdentifier(instanceIdentifier: string): Backend {\n  const identifierParts = instanceIdentifier.split('/');\n  if (identifierParts[0] !== AI_TYPE) {\n    throw new AIError(\n      AIErrorCode.ERROR,\n      `Invalid instance identifier, unknown prefix '${identifierParts[0]}'`\n    );\n  }\n  const backendType = identifierParts[1];\n  switch (backendType) {\n    case 'vertexai':\n      const location: string | undefined = identifierParts[2];\n      if (!location) {\n        throw new AIError(\n          AIErrorCode.ERROR,\n          `Invalid instance identifier, unknown location '${instanceIdentifier}'`\n        );\n      }\n      return new VertexAIBackend(location);\n    case 'googleai':\n      return new GoogleAIBackend();\n    default:\n      throw new AIError(\n        AIErrorCode.ERROR,\n        `Invalid instance identifier string: '${instanceIdentifier}'`\n      );\n  }\n}\n", "/**\n * @license\n * Copyright 2024 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { Logger } from '@firebase/logger';\n\nexport const logger = new Logger('@firebase/vertexai');\n", "/**\n * @license\n * Copyright 2025 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n/**\n * The subset of the Prompt API\n * (see {@link https://github.com/webmachinelearning/prompt-api#full-api-surface-in-web-idl }\n * required for hybrid functionality.\n *\n * @internal\n */\nexport interface LanguageModel extends EventTarget {\n  create(options?: LanguageModelCreateOptions): Promise<LanguageModel>;\n  availability(options?: LanguageModelCreateCoreOptions): Promise<Availability>;\n  prompt(\n    input: LanguageModelPrompt,\n    options?: LanguageModelPromptOptions\n  ): Promise<string>;\n  promptStreaming(\n    input: LanguageModelPrompt,\n    options?: LanguageModelPromptOptions\n  ): ReadableStream;\n  measureInputUsage(\n    input: LanguageModelPrompt,\n    options?: LanguageModelPromptOptions\n  ): Promise<number>;\n  destroy(): undefined;\n}\n\n/**\n * @internal\n */\nexport enum Availability {\n  'UNAVAILABLE' = 'unavailable',\n  'DOWNLOADABLE' = 'downloadable',\n  'DOWNLOADING' = 'downloading',\n  'AVAILABLE' = 'available'\n}\n\n/**\n * Configures the creation of an on-device language model session.\n * @beta\n */\nexport interface LanguageModelCreateCoreOptions {\n  topK?: number;\n  temperature?: number;\n  expectedInputs?: LanguageModelExpected[];\n}\n\n/**\n * Configures the creation of an on-device language model session.\n * @beta\n */\nexport interface LanguageModelCreateOptions\n  extends LanguageModelCreateCoreOptions {\n  signal?: AbortSignal;\n  initialPrompts?: LanguageModelMessage[];\n}\n\n/**\n * Options for an on-device language model prompt.\n * @beta\n */\nexport interface LanguageModelPromptOptions {\n  responseConstraint?: object;\n  // TODO: Restore AbortSignal once the API is defined.\n}\n\n/**\n * Options for the expected inputs for an on-device language model.\n * @beta\n */ export interface LanguageModelExpected {\n  type: LanguageModelMessageType;\n  languages?: string[];\n}\n\n/**\n * An on-device language model prompt.\n * @beta\n */\nexport type LanguageModelPrompt = LanguageModelMessage[];\n\n/**\n * An on-device language model message.\n * @beta\n */\nexport interface LanguageModelMessage {\n  role: LanguageModelMessageRole;\n  content: LanguageModelMessageContent[];\n}\n\n/**\n * An on-device language model content object.\n * @beta\n */\nexport interface LanguageModelMessageContent {\n  type: LanguageModelMessageType;\n  value: LanguageModelMessageContentValue;\n}\n\n/**\n * Allowable roles for on-device language model usage.\n * @beta\n */\nexport type LanguageModelMessageRole = 'system' | 'user' | 'assistant';\n\n/**\n * Allowable types for on-device language model messages.\n * @beta\n */\nexport type LanguageModelMessageType = 'text' | 'image' | 'audio';\n\n/**\n * Content formats that can be provided as on-device message content.\n * @beta\n */\nexport type LanguageModelMessageContentValue =\n  | ImageBitmapSource\n  | AudioBuffer\n  | BufferSource\n  | string;\n", "/**\n * @license\n * Copyright 2025 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { AIError } from '../errors';\nimport { logger } from '../logger';\nimport {\n  CountTokensRequest,\n  GenerateContentRequest,\n  InferenceMode,\n  Part,\n  AIErrorCode,\n  OnDeviceParams,\n  Content,\n  Role\n} from '../types';\nimport { ChromeAdapter } from '../types/chrome-adapter';\nimport {\n  Availability,\n  LanguageModel,\n  LanguageModelExpected,\n  LanguageModelMessage,\n  LanguageModelMessageContent,\n  LanguageModelMessageRole\n} from '../types/language-model';\n\n// Defaults to support image inputs for convenience.\nconst defaultExpectedInputs: LanguageModelExpected[] = [{ type: 'image' }];\n\n/**\n * Defines an inference \"backend\" that uses Chrome's on-device model,\n * and encapsulates logic for detecting when on-device inference is\n * possible.\n */\nexport class ChromeAdapterImpl implements ChromeAdapter {\n  // Visible for testing\n  static SUPPORTED_MIME_TYPES = ['image/jpeg', 'image/png'];\n  private isDownloading = false;\n  private downloadPromise: Promise<LanguageModel | void> | undefined;\n  private oldSession: LanguageModel | undefined;\n  onDeviceParams: OnDeviceParams = {\n    createOptions: {\n      expectedInputs: defaultExpectedInputs\n    }\n  };\n  constructor(\n    public languageModelProvider: LanguageModel,\n    public mode: InferenceMode,\n    onDeviceParams?: OnDeviceParams\n  ) {\n    if (onDeviceParams) {\n      this.onDeviceParams = onDeviceParams;\n      if (!this.onDeviceParams.createOptions) {\n        this.onDeviceParams.createOptions = {\n          expectedInputs: defaultExpectedInputs\n        };\n      } else if (!this.onDeviceParams.createOptions.expectedInputs) {\n        this.onDeviceParams.createOptions.expectedInputs =\n          defaultExpectedInputs;\n      }\n    }\n  }\n\n  /**\n   * Checks if a given request can be made on-device.\n   *\n   * Encapsulates a few concerns:\n   *   the mode\n   *   API existence\n   *   prompt formatting\n   *   model availability, including triggering download if necessary\n   *\n   *\n   * Pros: callers needn't be concerned with details of on-device availability.</p>\n   * Cons: this method spans a few concerns and splits request validation from usage.\n   * If instance variables weren't already part of the API, we could consider a better\n   * separation of concerns.\n   */\n  async isAvailable(request: GenerateContentRequest): Promise<boolean> {\n    if (!this.mode) {\n      logger.debug(\n        `On-device inference unavailable because mode is undefined.`\n      );\n      return false;\n    }\n    if (this.mode === InferenceMode.ONLY_IN_CLOUD) {\n      logger.debug(\n        `On-device inference unavailable because mode is \"only_in_cloud\".`\n      );\n      return false;\n    }\n\n    // Triggers out-of-band download so model will eventually become available.\n    const availability = await this.downloadIfAvailable();\n\n    if (this.mode === InferenceMode.ONLY_ON_DEVICE) {\n      // If it will never be available due to API inavailability, throw.\n      if (availability === Availability.UNAVAILABLE) {\n        throw new AIError(\n          AIErrorCode.API_NOT_ENABLED,\n          'Local LanguageModel API not available in this environment.'\n        );\n      } else if (\n        availability === Availability.DOWNLOADABLE ||\n        availability === Availability.DOWNLOADING\n      ) {\n        // TODO(chholland): Better user experience during download - progress?\n        logger.debug(`Waiting for download of LanguageModel to complete.`);\n        await this.downloadPromise;\n        return true;\n      }\n      return true;\n    }\n\n    // Applies prefer_on_device logic.\n    if (availability !== Availability.AVAILABLE) {\n      logger.debug(\n        `On-device inference unavailable because availability is \"${availability}\".`\n      );\n      return false;\n    }\n    if (!ChromeAdapterImpl.isOnDeviceRequest(request)) {\n      logger.debug(\n        `On-device inference unavailable because request is incompatible.`\n      );\n      return false;\n    }\n\n    return true;\n  }\n\n  /**\n   * Generates content on device.\n   *\n   * @remarks\n   * This is comparable to {@link GenerativeModel.generateContent} for generating content in\n   * Cloud.\n   * @param request - a standard Firebase AI {@link GenerateContentRequest}\n   * @returns {@link Response}, so we can reuse common response formatting.\n   */\n  async generateContent(request: GenerateContentRequest): Promise<Response> {\n    const session = await this.createSession();\n    const contents = await Promise.all(\n      request.contents.map(ChromeAdapterImpl.toLanguageModelMessage)\n    );\n    const text = await session.prompt(\n      contents,\n      this.onDeviceParams.promptOptions\n    );\n    return ChromeAdapterImpl.toResponse(text);\n  }\n\n  /**\n   * Generates content stream on device.\n   *\n   * @remarks\n   * This is comparable to {@link GenerativeModel.generateContentStream} for generating content in\n   * Cloud.\n   * @param request - a standard Firebase AI {@link GenerateContentRequest}\n   * @returns {@link Response}, so we can reuse common response formatting.\n   */\n  async generateContentStream(\n    request: GenerateContentRequest\n  ): Promise<Response> {\n    const session = await this.createSession();\n    const contents = await Promise.all(\n      request.contents.map(ChromeAdapterImpl.toLanguageModelMessage)\n    );\n    const stream = session.promptStreaming(\n      contents,\n      this.onDeviceParams.promptOptions\n    );\n    return ChromeAdapterImpl.toStreamResponse(stream);\n  }\n\n  async countTokens(_request: CountTokensRequest): Promise<Response> {\n    throw new AIError(\n      AIErrorCode.REQUEST_ERROR,\n      'Count Tokens is not yet available for on-device model.'\n    );\n  }\n\n  /**\n   * Asserts inference for the given request can be performed by an on-device model.\n   */\n  private static isOnDeviceRequest(request: GenerateContentRequest): boolean {\n    // Returns false if the prompt is empty.\n    if (request.contents.length === 0) {\n      logger.debug('Empty prompt rejected for on-device inference.');\n      return false;\n    }\n\n    for (const content of request.contents) {\n      if (content.role === 'function') {\n        logger.debug(`\"Function\" role rejected for on-device inference.`);\n        return false;\n      }\n\n      // Returns false if request contains an image with an unsupported mime type.\n      for (const part of content.parts) {\n        if (\n          part.inlineData &&\n          ChromeAdapterImpl.SUPPORTED_MIME_TYPES.indexOf(\n            part.inlineData.mimeType\n          ) === -1\n        ) {\n          logger.debug(\n            `Unsupported mime type \"${part.inlineData.mimeType}\" rejected for on-device inference.`\n          );\n          return false;\n        }\n      }\n    }\n\n    return true;\n  }\n\n  /**\n   * Encapsulates logic to get availability and download a model if one is downloadable.\n   */\n  private async downloadIfAvailable(): Promise<Availability | undefined> {\n    const availability = await this.languageModelProvider?.availability(\n      this.onDeviceParams.createOptions\n    );\n\n    if (availability === Availability.DOWNLOADABLE) {\n      this.download();\n    }\n\n    return availability;\n  }\n\n  /**\n   * Triggers out-of-band download of an on-device model.\n   *\n   * Chrome only downloads models as needed. Chrome knows a model is needed when code calls\n   * LanguageModel.create.\n   *\n   * Since Chrome manages the download, the SDK can only avoid redundant download requests by\n   * tracking if a download has previously been requested.\n   */\n  private download(): void {\n    if (this.isDownloading) {\n      return;\n    }\n    this.isDownloading = true;\n    this.downloadPromise = this.languageModelProvider\n      ?.create(this.onDeviceParams.createOptions)\n      .finally(() => {\n        this.isDownloading = false;\n      });\n  }\n\n  /**\n   * Converts Firebase AI {@link Content} object to a Chrome {@link LanguageModelMessage} object.\n   */\n  private static async toLanguageModelMessage(\n    content: Content\n  ): Promise<LanguageModelMessage> {\n    const languageModelMessageContents = await Promise.all(\n      content.parts.map(ChromeAdapterImpl.toLanguageModelMessageContent)\n    );\n    return {\n      role: ChromeAdapterImpl.toLanguageModelMessageRole(content.role),\n      content: languageModelMessageContents\n    };\n  }\n\n  /**\n   * Converts a Firebase AI Part object to a Chrome LanguageModelMessageContent object.\n   */\n  private static async toLanguageModelMessageContent(\n    part: Part\n  ): Promise<LanguageModelMessageContent> {\n    if (part.text) {\n      return {\n        type: 'text',\n        value: part.text\n      };\n    } else if (part.inlineData) {\n      const formattedImageContent = await fetch(\n        `data:${part.inlineData.mimeType};base64,${part.inlineData.data}`\n      );\n      const imageBlob = await formattedImageContent.blob();\n      const imageBitmap = await createImageBitmap(imageBlob);\n      return {\n        type: 'image',\n        value: imageBitmap\n      };\n    }\n    throw new AIError(\n      AIErrorCode.REQUEST_ERROR,\n      `Processing of this Part type is not currently supported.`\n    );\n  }\n\n  /**\n   * Converts a Firebase AI {@link Role} string to a {@link LanguageModelMessageRole} string.\n   */\n  private static toLanguageModelMessageRole(\n    role: Role\n  ): LanguageModelMessageRole {\n    // Assumes 'function' rule has been filtered by isOnDeviceRequest\n    return role === 'model' ? 'assistant' : 'user';\n  }\n\n  /**\n   * Abstracts Chrome session creation.\n   *\n   * Chrome uses a multi-turn session for all inference. Firebase AI uses single-turn for all\n   * inference. To map the Firebase AI API to Chrome's API, the SDK creates a new session for all\n   * inference.\n   *\n   * Chrome will remove a model from memory if it's no longer in use, so this method ensures a\n   * new session is created before an old session is destroyed.\n   */\n  private async createSession(): Promise<LanguageModel> {\n    if (!this.languageModelProvider) {\n      throw new AIError(\n        AIErrorCode.UNSUPPORTED,\n        'Chrome AI requested for unsupported browser version.'\n      );\n    }\n    const newSession = await this.languageModelProvider.create(\n      this.onDeviceParams.createOptions\n    );\n    if (this.oldSession) {\n      this.oldSession.destroy();\n    }\n    // Holds session reference, so model isn't unloaded from memory.\n    this.oldSession = newSession;\n    return newSession;\n  }\n\n  /**\n   * Formats string returned by Chrome as a {@link Response} returned by Firebase AI.\n   */\n  private static toResponse(text: string): Response {\n    return {\n      json: async () => ({\n        candidates: [\n          {\n            content: {\n              parts: [{ text }]\n            }\n          }\n        ]\n      })\n    } as Response;\n  }\n\n  /**\n   * Formats string stream returned by Chrome as SSE returned by Firebase AI.\n   */\n  private static toStreamResponse(stream: ReadableStream<string>): Response {\n    const encoder = new TextEncoder();\n    return {\n      body: stream.pipeThrough(\n        new TransformStream({\n          transform(chunk, controller) {\n            const json = JSON.stringify({\n              candidates: [\n                {\n                  content: {\n                    role: 'model',\n                    parts: [{ text: chunk }]\n                  }\n                }\n              ]\n            });\n            controller.enqueue(encoder.encode(`data: ${json}\\n\\n`));\n          }\n        })\n      )\n    } as Response;\n  }\n}\n\n/**\n * Creates a ChromeAdapterImpl on demand.\n */\nexport function chromeAdapterFactory(\n  mode: InferenceMode,\n  window?: Window,\n  params?: OnDeviceParams\n): ChromeAdapterImpl | undefined {\n  // Do not initialize a ChromeAdapter if we are not in hybrid mode.\n  if (typeof window !== 'undefined' && mode) {\n    return new ChromeAdapterImpl(\n      (window as Window).LanguageModel as LanguageModel,\n      mode,\n      params\n    );\n  }\n}\n", "/**\n * @license\n * Copyright 2024 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { FirebaseApp, _FirebaseService } from '@firebase/app';\nimport {\n  AI,\n  AIOptions,\n  ChromeAdapter,\n  InferenceMode,\n  OnDeviceParams\n} from './public-types';\nimport {\n  AppCheckInternalComponentName,\n  FirebaseAppCheckInternal\n} from '@firebase/app-check-interop-types';\nimport { Provider } from '@firebase/component';\nimport {\n  FirebaseAuthInternal,\n  FirebaseAuthInternalName\n} from '@firebase/auth-interop-types';\nimport { Backend, VertexAIBackend } from './backend';\n\nexport class AIService implements AI, _FirebaseService {\n  auth: FirebaseAuthInternal | null;\n  appCheck: FirebaseAppCheckInternal | null;\n  _options?: Omit<AIOptions, 'backend'>;\n  location: string; // This is here for backwards-compatibility\n\n  constructor(\n    public app: FirebaseApp,\n    public backend: Backend,\n    authProvider?: Provider<FirebaseAuthInternalName>,\n    appCheckProvider?: Provider<AppCheckInternalComponentName>,\n    public chromeAdapterFactory?: (\n      mode: InferenceMode,\n      window?: Window,\n      params?: OnDeviceParams\n    ) => ChromeAdapter | undefined\n  ) {\n    const appCheck = appCheckProvider?.getImmediate({ optional: true });\n    const auth = authProvider?.getImmediate({ optional: true });\n    this.auth = auth || null;\n    this.appCheck = appCheck || null;\n\n    if (backend instanceof VertexAIBackend) {\n      this.location = backend.location;\n    } else {\n      this.location = '';\n    }\n  }\n\n  _delete(): Promise<void> {\n    return Promise.resolve();\n  }\n\n  set options(optionsToSet: AIOptions) {\n    this._options = optionsToSet;\n  }\n\n  get options(): AIOptions | undefined {\n    return this._options;\n  }\n}\n", "/**\n * @license\n * Copyright 2025 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport {\n  ComponentContainer,\n  InstanceFactoryOptions\n} from '@firebase/component';\nimport { AIError } from './errors';\nimport { decodeInstanceIdentifier } from './helpers';\nimport { chromeAdapterFactory } from './methods/chrome-adapter';\nimport { AIService } from './service';\nimport { AIErrorCode } from './types';\n\nexport function factory(\n  container: ComponentContainer,\n  { instanceIdentifier }: InstanceFactoryOptions\n): AIService {\n  if (!instanceIdentifier) {\n    throw new AIError(\n      AIErrorCode.ERROR,\n      'AIService instance identifier is undefined.'\n    );\n  }\n\n  const backend = decodeInstanceIdentifier(instanceIdentifier);\n\n  // getImmediate for FirebaseApp will always succeed\n  const app = container.getProvider('app').getImmediate();\n  const auth = container.getProvider('auth-internal');\n  const appCheckProvider = container.getProvider('app-check-internal');\n\n  return new AIService(\n    app,\n    backend,\n    auth,\n    appCheckProvider,\n    chromeAdapterFactory\n  );\n}\n", "/**\n * @license\n * Copyright 2025 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { _isFirebaseServerApp } from '@firebase/app';\nimport { AIError } from '../errors';\nimport { AI, AIErrorCode } from '../public-types';\nimport { AIService } from '../service';\nimport { ApiSettings } from '../types/internal';\n\n/**\n * Initializes an {@link ApiSettings} object from an {@link AI} instance.\n *\n * If this is a Server App, the {@link ApiSettings} object's `getAppCheckToken()` will resolve\n * with the `FirebaseServerAppSettings.appCheckToken`, instead of requiring that an App Check\n * instance is initialized.\n */\nexport function initApiSettings(ai: AI): ApiSettings {\n  if (!ai.app?.options?.apiKey) {\n    throw new AIError(\n      AIErrorCode.NO_API_KEY,\n      `The \"apiKey\" field is empty in the local Firebase config. Firebase AI requires this field to contain a valid API key.`\n    );\n  } else if (!ai.app?.options?.projectId) {\n    throw new AIError(\n      AIErrorCode.NO_PROJECT_ID,\n      `The \"projectId\" field is empty in the local Firebase config. Firebase AI requires this field to contain a valid project ID.`\n    );\n  } else if (!ai.app?.options?.appId) {\n    throw new AIError(\n      AIErrorCode.NO_APP_ID,\n      `The \"appId\" field is empty in the local Firebase config. Firebase AI requires this field to contain a valid app ID.`\n    );\n  }\n\n  const apiSettings: ApiSettings = {\n    apiKey: ai.app.options.apiKey,\n    project: ai.app.options.projectId,\n    appId: ai.app.options.appId,\n    automaticDataCollectionEnabled: ai.app.automaticDataCollectionEnabled,\n    location: ai.location,\n    backend: ai.backend\n  };\n\n  if (_isFirebaseServerApp(ai.app) && ai.app.settings.appCheckToken) {\n    const token = ai.app.settings.appCheckToken;\n    apiSettings.getAppCheckToken = () => {\n      return Promise.resolve({ token });\n    };\n  } else if ((ai as AIService).appCheck) {\n    if (ai.options?.useLimitedUseAppCheckTokens) {\n      apiSettings.getAppCheckToken = () =>\n        (ai as AIService).appCheck!.getLimitedUseToken();\n    } else {\n      apiSettings.getAppCheckToken = () =>\n        (ai as AIService).appCheck!.getToken();\n    }\n  }\n\n  if ((ai as AIService).auth) {\n    apiSettings.getAuthToken = () => (ai as AIService).auth!.getToken();\n  }\n\n  return apiSettings;\n}\n", "/**\n * @license\n * Copyright 2025 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { AI, BackendType } from '../public-types';\nimport { ApiSettings } from '../types/internal';\nimport { initApiSettings } from './utils';\n\n/**\n * Base class for Firebase AI model APIs.\n *\n * Instances of this class are associated with a specific Firebase AI {@link Backend}\n * and provide methods for interacting with the configured generative model.\n *\n * @public\n */\nexport abstract class AIModel {\n  /**\n   * The fully qualified model resource name to use for generating images\n   * (for example, `publishers/google/models/imagen-3.0-generate-002`).\n   */\n  readonly model: string;\n\n  /**\n   * @internal\n   */\n  _apiSettings: ApiSettings;\n\n  /**\n   * Constructs a new instance of the {@link AIModel} class.\n   *\n   * This constructor should only be called from subclasses that provide\n   * a model API.\n   *\n   * @param ai - an {@link AI} instance.\n   * @param modelName - The name of the model being used. It can be in one of the following formats:\n   * - `my-model` (short name, will resolve to `publishers/google/models/my-model`)\n   * - `models/my-model` (will resolve to `publishers/google/models/my-model`)\n   * - `publishers/my-publisher/models/my-model` (fully qualified model name)\n   *\n   * @throws If the `apiKey` or `projectId` fields are missing in your\n   * Firebase config.\n   *\n   * @internal\n   */\n  protected constructor(ai: AI, modelName: string) {\n    this._apiSettings = initApiSettings(ai);\n    this.model = AIModel.normalizeModelName(\n      modelName,\n      this._apiSettings.backend.backendType\n    );\n  }\n\n  /**\n   * Normalizes the given model name to a fully qualified model resource name.\n   *\n   * @param modelName - The model name to normalize.\n   * @returns The fully qualified model resource name.\n   *\n   * @internal\n   */\n  static normalizeModelName(\n    modelName: string,\n    backendType: BackendType\n  ): string {\n    if (backendType === BackendType.GOOGLE_AI) {\n      return AIModel.normalizeGoogleAIModelName(modelName);\n    } else {\n      return AIModel.normalizeVertexAIModelName(modelName);\n    }\n  }\n\n  /**\n   * @internal\n   */\n  private static normalizeGoogleAIModelName(modelName: string): string {\n    return `models/${modelName}`;\n  }\n\n  /**\n   * @internal\n   */\n  private static normalizeVertexAIModelName(modelName: string): string {\n    let model: string;\n    if (modelName.includes('/')) {\n      if (modelName.startsWith('models/')) {\n        // Add 'publishers/google' if the user is only passing in 'models/model-name'.\n        model = `publishers/google/${modelName}`;\n      } else {\n        // Any other custom format (e.g. tuned models) must be passed in correctly.\n        model = modelName;\n      }\n    } else {\n      // If path is not included, assume it's a non-tuned model.\n      model = `publishers/google/models/${modelName}`;\n    }\n\n    return model;\n  }\n}\n", "/**\n * @license\n * Copyright 2025 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { ErrorDetails, RequestOptions, AIErrorCode } from '../types';\nimport { AIError } from '../errors';\nimport { ApiSettings } from '../types/internal';\nimport {\n  DEFAULT_DOMAIN,\n  DEFAULT_FETCH_TIMEOUT_MS,\n  LANGUAGE_TAG,\n  PACKAGE_VERSION\n} from '../constants';\nimport { logger } from '../logger';\nimport { BackendType } from '../public-types';\n\nexport const enum Task {\n  GENERATE_CONTENT = 'generateContent',\n  STREAM_GENERATE_CONTENT = 'streamGenerateContent',\n  COUNT_TOKENS = 'countTokens',\n  PREDICT = 'predict'\n}\n\nexport const enum ServerPromptTemplateTask {\n  TEMPLATE_GENERATE_CONTENT = 'templateGenerateContent',\n  TEMPLATE_STREAM_GENERATE_CONTENT = 'templateStreamGenerateContent',\n  TEMPLATE_PREDICT = 'templatePredict'\n}\n\ninterface BaseRequestURLParams {\n  apiSettings: ApiSettings;\n  stream: boolean;\n  requestOptions?: RequestOptions;\n}\n\n/**\n * Parameters used to construct the URL of a request to use a model.\n */\ninterface ModelRequestURLParams extends BaseRequestURLParams {\n  task: Task;\n  model: string;\n  templateId?: never;\n}\n\n/**\n * Parameters used to construct the URL of a request to use server side prompt templates.\n */\ninterface TemplateRequestURLParams extends BaseRequestURLParams {\n  task: ServerPromptTemplateTask;\n  templateId: string;\n  model?: never;\n}\n\nexport class RequestURL {\n  constructor(\n    public readonly params: ModelRequestURLParams | TemplateRequestURLParams\n  ) {}\n\n  toString(): string {\n    const url = new URL(this.baseUrl); // Throws if the URL is invalid\n    url.pathname = this.pathname;\n    url.search = this.queryParams.toString();\n    return url.toString();\n  }\n\n  private get pathname(): string {\n    // We need to construct a different URL if the request is for server side prompt templates,\n    // since the URL patterns are different. Server side prompt templates expect a templateId\n    // instead of a model name.\n    if (this.params.templateId) {\n      return `${this.params.apiSettings.backend._getTemplatePath(\n        this.params.apiSettings.project,\n        this.params.templateId\n      )}:${this.params.task}`;\n    } else {\n      return `${this.params.apiSettings.backend._getModelPath(\n        this.params.apiSettings.project,\n        (this.params as ModelRequestURLParams).model\n      )}:${this.params.task}`;\n    }\n  }\n\n  private get baseUrl(): string {\n    return this.params.requestOptions?.baseUrl ?? `https://${DEFAULT_DOMAIN}`;\n  }\n\n  private get queryParams(): URLSearchParams {\n    const params = new URLSearchParams();\n    if (this.params.stream) {\n      params.set('alt', 'sse');\n    }\n\n    return params;\n  }\n}\n\nexport class WebSocketUrl {\n  constructor(public apiSettings: ApiSettings) {}\n  toString(): string {\n    const url = new URL(`wss://${DEFAULT_DOMAIN}`);\n    url.pathname = this.pathname;\n\n    const queryParams = new URLSearchParams();\n    queryParams.set('key', this.apiSettings.apiKey);\n    url.search = queryParams.toString();\n\n    return url.toString();\n  }\n\n  private get pathname(): string {\n    if (this.apiSettings.backend.backendType === BackendType.GOOGLE_AI) {\n      return 'ws/google.firebase.vertexai.v1beta.GenerativeService/BidiGenerateContent';\n    } else {\n      return `ws/google.firebase.vertexai.v1beta.LlmBidiService/BidiGenerateContent/locations/${this.apiSettings.location}`;\n    }\n  }\n}\n\n/**\n * Log language and \"fire/version\" to x-goog-api-client\n */\nfunction getClientHeaders(): string {\n  const loggingTags = [];\n  loggingTags.push(`${LANGUAGE_TAG}/${PACKAGE_VERSION}`);\n  loggingTags.push(`fire/${PACKAGE_VERSION}`);\n  return loggingTags.join(' ');\n}\n\nexport async function getHeaders(url: RequestURL): Promise<Headers> {\n  const headers = new Headers();\n  headers.append('Content-Type', 'application/json');\n  headers.append('x-goog-api-client', getClientHeaders());\n  headers.append('x-goog-api-key', url.params.apiSettings.apiKey);\n  if (url.params.apiSettings.automaticDataCollectionEnabled) {\n    headers.append('X-Firebase-Appid', url.params.apiSettings.appId);\n  }\n  if (url.params.apiSettings.getAppCheckToken) {\n    const appCheckToken = await url.params.apiSettings.getAppCheckToken();\n    if (appCheckToken) {\n      headers.append('X-Firebase-AppCheck', appCheckToken.token);\n      if (appCheckToken.error) {\n        logger.warn(\n          `Unable to obtain a valid App Check token: ${appCheckToken.error.message}`\n        );\n      }\n    }\n  }\n\n  if (url.params.apiSettings.getAuthToken) {\n    const authToken = await url.params.apiSettings.getAuthToken();\n    if (authToken) {\n      headers.append('Authorization', `Firebase ${authToken.accessToken}`);\n    }\n  }\n\n  return headers;\n}\n\nexport async function makeRequest(\n  requestUrlParams: TemplateRequestURLParams | ModelRequestURLParams,\n  body: string\n): Promise<Response> {\n  const url = new RequestURL(requestUrlParams);\n  let response;\n  let fetchTimeoutId: string | number | NodeJS.Timeout | undefined;\n  try {\n    const fetchOptions: RequestInit = {\n      method: 'POST',\n      headers: await getHeaders(url),\n      body\n    };\n\n    // Timeout is 180s by default.\n    const timeoutMillis =\n      requestUrlParams.requestOptions?.timeout != null &&\n      requestUrlParams.requestOptions.timeout >= 0\n        ? requestUrlParams.requestOptions.timeout\n        : DEFAULT_FETCH_TIMEOUT_MS;\n    const abortController = new AbortController();\n    fetchTimeoutId = setTimeout(() => abortController.abort(), timeoutMillis);\n    fetchOptions.signal = abortController.signal;\n\n    response = await fetch(url.toString(), fetchOptions);\n    if (!response.ok) {\n      let message = '';\n      let errorDetails;\n      try {\n        const json = await response.json();\n        message = json.error.message;\n        if (json.error.details) {\n          message += ` ${JSON.stringify(json.error.details)}`;\n          errorDetails = json.error.details;\n        }\n      } catch (e) {\n        // ignored\n      }\n      if (\n        response.status === 403 &&\n        errorDetails &&\n        errorDetails.some(\n          (detail: ErrorDetails) => detail.reason === 'SERVICE_DISABLED'\n        ) &&\n        errorDetails.some((detail: ErrorDetails) =>\n          (\n            detail.links as Array<Record<string, string>>\n          )?.[0]?.description.includes(\n            'Google developers console API activation'\n          )\n        )\n      ) {\n        throw new AIError(\n          AIErrorCode.API_NOT_ENABLED,\n          `The Firebase AI SDK requires the Firebase AI ` +\n            `API ('firebasevertexai.googleapis.com') to be enabled in your ` +\n            `Firebase project. Enable this API by visiting the Firebase Console ` +\n            `at https://console.firebase.google.com/project/${url.params.apiSettings.project}/genai/ ` +\n            `and clicking \"Get started\". If you enabled this API recently, ` +\n            `wait a few minutes for the action to propagate to our systems and ` +\n            `then retry.`,\n          {\n            status: response.status,\n            statusText: response.statusText,\n            errorDetails\n          }\n        );\n      }\n      throw new AIError(\n        AIErrorCode.FETCH_ERROR,\n        `Error fetching from ${url}: [${response.status} ${response.statusText}] ${message}`,\n        {\n          status: response.status,\n          statusText: response.statusText,\n          errorDetails\n        }\n      );\n    }\n  } catch (e) {\n    let err = e as Error;\n    if (\n      (e as AIError).code !== AIErrorCode.FETCH_ERROR &&\n      (e as AIError).code !== AIErrorCode.API_NOT_ENABLED &&\n      e instanceof Error\n    ) {\n      err = new AIError(\n        AIErrorCode.ERROR,\n        `Error fetching from ${url.toString()}: ${e.message}`\n      );\n      err.stack = e.stack;\n    }\n\n    throw err;\n  } finally {\n    if (fetchTimeoutId) {\n      clearTimeout(fetchTimeoutId);\n    }\n  }\n  return response;\n}\n", "/**\n * @license\n * Copyright 2024 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport {\n  EnhancedGenerateContentResponse,\n  FinishReason,\n  FunctionCall,\n  GenerateContentCandidate,\n  GenerateContentResponse,\n  ImagenGCSImage,\n  ImagenInlineImage,\n  AIErrorCode,\n  InlineDataPart,\n  Part,\n  InferenceSource\n} from '../types';\nimport { AIError } from '../errors';\nimport { logger } from '../logger';\nimport { ImagenResponseInternal } from '../types/internal';\n\n/**\n * Check that at least one candidate exists and does not have a bad\n * finish reason. Warns if multiple candidates exist.\n */\nfunction hasValidCandidates(response: GenerateContentResponse): boolean {\n  if (response.candidates && response.candidates.length > 0) {\n    if (response.candidates.length > 1) {\n      logger.warn(\n        `This response had ${response.candidates.length} ` +\n          `candidates. Returning text from the first candidate only. ` +\n          `Access response.candidates directly to use the other candidates.`\n      );\n    }\n    if (hadBadFinishReason(response.candidates[0])) {\n      throw new AIError(\n        AIErrorCode.RESPONSE_ERROR,\n        `Response error: ${formatBlockErrorMessage(\n          response\n        )}. Response body stored in error.response`,\n        {\n          response\n        }\n      );\n    }\n    return true;\n  } else {\n    return false;\n  }\n}\n\n/**\n * Creates an EnhancedGenerateContentResponse object that has helper functions and\n * other modifications that improve usability.\n */\nexport function createEnhancedContentResponse(\n  response: GenerateContentResponse,\n  inferenceSource: InferenceSource = InferenceSource.IN_CLOUD\n): EnhancedGenerateContentResponse {\n  /**\n   * The Vertex AI backend omits default values.\n   * This causes the `index` property to be omitted from the first candidate in the\n   * response, since it has index 0, and 0 is a default value.\n   * See: https://github.com/firebase/firebase-js-sdk/issues/8566\n   */\n  if (response.candidates && !response.candidates[0].hasOwnProperty('index')) {\n    response.candidates[0].index = 0;\n  }\n\n  const responseWithHelpers = addHelpers(response);\n  responseWithHelpers.inferenceSource = inferenceSource;\n  return responseWithHelpers;\n}\n\n/**\n * Adds convenience helper methods to a response object, including stream\n * chunks (as long as each chunk is a complete GenerateContentResponse JSON).\n */\nexport function addHelpers(\n  response: GenerateContentResponse\n): EnhancedGenerateContentResponse {\n  (response as EnhancedGenerateContentResponse).text = () => {\n    if (hasValidCandidates(response)) {\n      return getText(response, part => !part.thought);\n    } else if (response.promptFeedback) {\n      throw new AIError(\n        AIErrorCode.RESPONSE_ERROR,\n        `Text not available. ${formatBlockErrorMessage(response)}`,\n        {\n          response\n        }\n      );\n    }\n    return '';\n  };\n  (response as EnhancedGenerateContentResponse).thoughtSummary = () => {\n    if (hasValidCandidates(response)) {\n      const result = getText(response, part => !!part.thought);\n      return result === '' ? undefined : result;\n    } else if (response.promptFeedback) {\n      throw new AIError(\n        AIErrorCode.RESPONSE_ERROR,\n        `Thought summary not available. ${formatBlockErrorMessage(response)}`,\n        {\n          response\n        }\n      );\n    }\n    return undefined;\n  };\n  (response as EnhancedGenerateContentResponse).inlineDataParts = ():\n    | InlineDataPart[]\n    | undefined => {\n    if (hasValidCandidates(response)) {\n      return getInlineDataParts(response);\n    } else if (response.promptFeedback) {\n      throw new AIError(\n        AIErrorCode.RESPONSE_ERROR,\n        `Data not available. ${formatBlockErrorMessage(response)}`,\n        {\n          response\n        }\n      );\n    }\n    return undefined;\n  };\n  (response as EnhancedGenerateContentResponse).functionCalls = () => {\n    if (hasValidCandidates(response)) {\n      return getFunctionCalls(response);\n    } else if (response.promptFeedback) {\n      throw new AIError(\n        AIErrorCode.RESPONSE_ERROR,\n        `Function call not available. ${formatBlockErrorMessage(response)}`,\n        {\n          response\n        }\n      );\n    }\n    return undefined;\n  };\n  return response as EnhancedGenerateContentResponse;\n}\n\n/**\n * Returns all text from the first candidate's parts, filtering by whether\n * `partFilter()` returns true.\n *\n * @param response - The `GenerateContentResponse` from which to extract text.\n * @param partFilter - Only return `Part`s for which this returns true\n */\nexport function getText(\n  response: GenerateContentResponse,\n  partFilter: (part: Part) => boolean\n): string {\n  const textStrings = [];\n  if (response.candidates?.[0].content?.parts) {\n    for (const part of response.candidates?.[0].content?.parts) {\n      if (part.text && partFilter(part)) {\n        textStrings.push(part.text);\n      }\n    }\n  }\n  if (textStrings.length > 0) {\n    return textStrings.join('');\n  } else {\n    return '';\n  }\n}\n\n/**\n * Returns every {@link FunctionCall} associated with first candidate.\n */\nexport function getFunctionCalls(\n  response: GenerateContentResponse\n): FunctionCall[] | undefined {\n  const functionCalls: FunctionCall[] = [];\n  if (response.candidates?.[0].content?.parts) {\n    for (const part of response.candidates?.[0].content?.parts) {\n      if (part.functionCall) {\n        functionCalls.push(part.functionCall);\n      }\n    }\n  }\n  if (functionCalls.length > 0) {\n    return functionCalls;\n  } else {\n    return undefined;\n  }\n}\n\n/**\n * Returns every {@link InlineDataPart} in the first candidate if present.\n *\n * @internal\n */\nexport function getInlineDataParts(\n  response: GenerateContentResponse\n): InlineDataPart[] | undefined {\n  const data: InlineDataPart[] = [];\n\n  if (response.candidates?.[0].content?.parts) {\n    for (const part of response.candidates?.[0].content?.parts) {\n      if (part.inlineData) {\n        data.push(part);\n      }\n    }\n  }\n\n  if (data.length > 0) {\n    return data;\n  } else {\n    return undefined;\n  }\n}\n\nconst badFinishReasons = [FinishReason.RECITATION, FinishReason.SAFETY];\n\nfunction hadBadFinishReason(candidate: GenerateContentCandidate): boolean {\n  return (\n    !!candidate.finishReason &&\n    badFinishReasons.some(reason => reason === candidate.finishReason)\n  );\n}\n\nexport function formatBlockErrorMessage(\n  response: GenerateContentResponse\n): string {\n  let message = '';\n  if (\n    (!response.candidates || response.candidates.length === 0) &&\n    response.promptFeedback\n  ) {\n    message += 'Response was blocked';\n    if (response.promptFeedback?.blockReason) {\n      message += ` due to ${response.promptFeedback.blockReason}`;\n    }\n    if (response.promptFeedback?.blockReasonMessage) {\n      message += `: ${response.promptFeedback.blockReasonMessage}`;\n    }\n  } else if (response.candidates?.[0]) {\n    const firstCandidate = response.candidates[0];\n    if (hadBadFinishReason(firstCandidate)) {\n      message += `Candidate was blocked due to ${firstCandidate.finishReason}`;\n      if (firstCandidate.finishMessage) {\n        message += `: ${firstCandidate.finishMessage}`;\n      }\n    }\n  }\n  return message;\n}\n\n/**\n * Convert a generic successful fetch response body to an Imagen response object\n * that can be returned to the user. This converts the REST APIs response format to our\n * APIs representation of a response.\n *\n * @internal\n */\nexport async function handlePredictResponse<\n  T extends ImagenInlineImage | ImagenGCSImage\n>(response: Response): Promise<{ images: T[]; filteredReason?: string }> {\n  const responseJson: ImagenResponseInternal = await response.json();\n\n  const images: T[] = [];\n  let filteredReason: string | undefined = undefined;\n\n  // The backend should always send a non-empty array of predictions if the response was successful.\n  if (!responseJson.predictions || responseJson.predictions?.length === 0) {\n    throw new AIError(\n      AIErrorCode.RESPONSE_ERROR,\n      'No predictions or filtered reason received from Vertex AI. Please report this issue with the full error details at https://github.com/firebase/firebase-js-sdk/issues.'\n    );\n  }\n\n  for (const prediction of responseJson.predictions) {\n    if (prediction.raiFilteredReason) {\n      filteredReason = prediction.raiFilteredReason;\n    } else if (prediction.mimeType && prediction.bytesBase64Encoded) {\n      images.push({\n        mimeType: prediction.mimeType,\n        bytesBase64Encoded: prediction.bytesBase64Encoded\n      } as T);\n    } else if (prediction.mimeType && prediction.gcsUri) {\n      images.push({\n        mimeType: prediction.mimeType,\n        gcsURI: prediction.gcsUri\n      } as T);\n    } else if (prediction.safetyAttributes) {\n      // Ignore safetyAttributes \"prediction\" to avoid throwing an error below.\n    } else {\n      throw new AIError(\n        AIErrorCode.RESPONSE_ERROR,\n        `Unexpected element in 'predictions' array in response: '${JSON.stringify(\n          prediction\n        )}'`\n      );\n    }\n  }\n\n  return { images, filteredReason };\n}\n", "/**\n * @license\n * Copyright 2025 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { AIError } from './errors';\nimport { logger } from './logger';\nimport {\n  CitationMetadata,\n  CountTokensRequest,\n  GenerateContentCandidate,\n  GenerateContentRequest,\n  GenerateContentResponse,\n  HarmSeverity,\n  InlineDataPart,\n  PromptFeedback,\n  SafetyRating,\n  AIErrorCode\n} from './types';\nimport {\n  GoogleAIGenerateContentResponse,\n  GoogleAIGenerateContentCandidate,\n  GoogleAICountTokensRequest\n} from './types/googleai';\n\n/**\n * This SDK supports both the Vertex AI Gemini API and the Gemini Developer API (using Google AI).\n * The public API prioritizes the format used by the Vertex AI Gemini API.\n * We avoid having two sets of types by translating requests and responses between the two API formats.\n * This translation allows developers to switch between the Vertex AI Gemini API and the Gemini Developer API\n * with minimal code changes.\n *\n * In here are functions that map requests and responses between the two API formats.\n * Requests in the Vertex AI format are mapped to the Google AI format before being sent.\n * Responses from the Google AI backend are mapped back to the Vertex AI format before being returned to the user.\n */\n\n/**\n * Maps a Vertex AI {@link GenerateContentRequest} to a format that can be sent to Google AI.\n *\n * @param generateContentRequest The {@link GenerateContentRequest} to map.\n * @returns A {@link GenerateContentResponse} that conforms to the Google AI format.\n *\n * @throws If the request contains properties that are unsupported by Google AI.\n *\n * @internal\n */\nexport function mapGenerateContentRequest(\n  generateContentRequest: GenerateContentRequest\n): GenerateContentRequest {\n  generateContentRequest.safetySettings?.forEach(safetySetting => {\n    if (safetySetting.method) {\n      throw new AIError(\n        AIErrorCode.UNSUPPORTED,\n        'SafetySetting.method is not supported in the the Gemini Developer API. Please remove this property.'\n      );\n    }\n  });\n\n  if (generateContentRequest.generationConfig?.topK) {\n    const roundedTopK = Math.round(\n      generateContentRequest.generationConfig.topK\n    );\n\n    if (roundedTopK !== generateContentRequest.generationConfig.topK) {\n      logger.warn(\n        'topK in GenerationConfig has been rounded to the nearest integer to match the format for requests to the Gemini Developer API.'\n      );\n      generateContentRequest.generationConfig.topK = roundedTopK;\n    }\n  }\n\n  return generateContentRequest;\n}\n\n/**\n * Maps a {@link GenerateContentResponse} from Google AI to the format of the\n * {@link GenerateContentResponse} that we get from VertexAI that is exposed in the public API.\n *\n * @param googleAIResponse The {@link GenerateContentResponse} from Google AI.\n * @returns A {@link GenerateContentResponse} that conforms to the public API's format.\n *\n * @internal\n */\nexport function mapGenerateContentResponse(\n  googleAIResponse: GoogleAIGenerateContentResponse\n): GenerateContentResponse {\n  const generateContentResponse = {\n    candidates: googleAIResponse.candidates\n      ? mapGenerateContentCandidates(googleAIResponse.candidates)\n      : undefined,\n    prompt: googleAIResponse.promptFeedback\n      ? mapPromptFeedback(googleAIResponse.promptFeedback)\n      : undefined,\n    usageMetadata: googleAIResponse.usageMetadata\n  };\n\n  return generateContentResponse;\n}\n\n/**\n * Maps a Vertex AI {@link CountTokensRequest} to a format that can be sent to Google AI.\n *\n * @param countTokensRequest The {@link CountTokensRequest} to map.\n * @param model The model to count tokens with.\n * @returns A {@link CountTokensRequest} that conforms to the Google AI format.\n *\n * @internal\n */\nexport function mapCountTokensRequest(\n  countTokensRequest: CountTokensRequest,\n  model: string\n): GoogleAICountTokensRequest {\n  const mappedCountTokensRequest: GoogleAICountTokensRequest = {\n    generateContentRequest: {\n      model,\n      ...countTokensRequest\n    }\n  };\n\n  return mappedCountTokensRequest;\n}\n\n/**\n * Maps a Google AI {@link GoogleAIGenerateContentCandidate} to a format that conforms\n * to the Vertex AI API format.\n *\n * @param candidates The {@link GoogleAIGenerateContentCandidate} to map.\n * @returns A {@link GenerateContentCandidate} that conforms to the Vertex AI format.\n *\n * @throws If any {@link Part} in the candidates has a `videoMetadata` property.\n *\n * @internal\n */\nexport function mapGenerateContentCandidates(\n  candidates: GoogleAIGenerateContentCandidate[]\n): GenerateContentCandidate[] {\n  const mappedCandidates: GenerateContentCandidate[] = [];\n  let mappedSafetyRatings: SafetyRating[];\n  if (mappedCandidates) {\n    candidates.forEach(candidate => {\n      // Map citationSources to citations.\n      let citationMetadata: CitationMetadata | undefined;\n      if (candidate.citationMetadata) {\n        citationMetadata = {\n          citations: candidate.citationMetadata.citationSources\n        };\n      }\n\n      // Assign missing candidate SafetyRatings properties to their defaults if undefined.\n      if (candidate.safetyRatings) {\n        mappedSafetyRatings = candidate.safetyRatings.map(safetyRating => {\n          return {\n            ...safetyRating,\n            severity:\n              safetyRating.severity ?? HarmSeverity.HARM_SEVERITY_UNSUPPORTED,\n            probabilityScore: safetyRating.probabilityScore ?? 0,\n            severityScore: safetyRating.severityScore ?? 0\n          };\n        });\n      }\n\n      // videoMetadata is not supported.\n      // Throw early since developers may send a long video as input and only expect to pay\n      // for inference on a small portion of the video.\n      if (\n        candidate.content?.parts?.some(\n          part => (part as InlineDataPart)?.videoMetadata\n        )\n      ) {\n        throw new AIError(\n          AIErrorCode.UNSUPPORTED,\n          'Part.videoMetadata is not supported in the Gemini Developer API. Please remove this property.'\n        );\n      }\n\n      const mappedCandidate = {\n        index: candidate.index,\n        content: candidate.content,\n        finishReason: candidate.finishReason,\n        finishMessage: candidate.finishMessage,\n        safetyRatings: mappedSafetyRatings,\n        citationMetadata,\n        groundingMetadata: candidate.groundingMetadata,\n        urlContextMetadata: candidate.urlContextMetadata\n      };\n      mappedCandidates.push(mappedCandidate);\n    });\n  }\n\n  return mappedCandidates;\n}\n\nexport function mapPromptFeedback(\n  promptFeedback: PromptFeedback\n): PromptFeedback {\n  // Assign missing SafetyRating properties to their defaults if undefined.\n  const mappedSafetyRatings: SafetyRating[] = [];\n  promptFeedback.safetyRatings.forEach(safetyRating => {\n    mappedSafetyRatings.push({\n      category: safetyRating.category,\n      probability: safetyRating.probability,\n      severity: safetyRating.severity ?? HarmSeverity.HARM_SEVERITY_UNSUPPORTED,\n      probabilityScore: safetyRating.probabilityScore ?? 0,\n      severityScore: safetyRating.severityScore ?? 0,\n      blocked: safetyRating.blocked\n    });\n  });\n\n  const mappedPromptFeedback: PromptFeedback = {\n    blockReason: promptFeedback.blockReason,\n    safetyRatings: mappedSafetyRatings,\n    blockReasonMessage: promptFeedback.blockReasonMessage\n  };\n  return mappedPromptFeedback;\n}\n", "/**\n * @license\n * Copyright 2024 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport {\n  EnhancedGenerateContentResponse,\n  GenerateContentCandidate,\n  GenerateContentResponse,\n  GenerateContentStreamResult,\n  Part,\n  AIErrorCode\n} from '../types';\nimport { AIError } from '../errors';\nimport { createEnhancedContentResponse } from './response-helpers';\nimport * as GoogleAIMapper from '../googleai-mappers';\nimport { GoogleAIGenerateContentResponse } from '../types/googleai';\nimport { ApiSettings } from '../types/internal';\nimport {\n  BackendType,\n  InferenceSource,\n  URLContextMetadata\n} from '../public-types';\n\nconst responseLineRE = /^data\\: (.*)(?:\\n\\n|\\r\\r|\\r\\n\\r\\n)/;\n\n/**\n * Process a response.body stream from the backend and return an\n * iterator that provides one complete GenerateContentResponse at a time\n * and a promise that resolves with a single aggregated\n * GenerateContentResponse.\n *\n * @param response - Response from a fetch call\n */\nexport function processStream(\n  response: Response,\n  apiSettings: ApiSettings,\n  inferenceSource?: InferenceSource\n): GenerateContentStreamResult {\n  const inputStream = response.body!.pipeThrough(\n    new TextDecoderStream('utf8', { fatal: true })\n  );\n  const responseStream =\n    getResponseStream<GenerateContentResponse>(inputStream);\n  const [stream1, stream2] = responseStream.tee();\n  return {\n    stream: generateResponseSequence(stream1, apiSettings, inferenceSource),\n    response: getResponsePromise(stream2, apiSettings, inferenceSource)\n  };\n}\n\nasync function getResponsePromise(\n  stream: ReadableStream<GenerateContentResponse>,\n  apiSettings: ApiSettings,\n  inferenceSource?: InferenceSource\n): Promise<EnhancedGenerateContentResponse> {\n  const allResponses: GenerateContentResponse[] = [];\n  const reader = stream.getReader();\n  while (true) {\n    const { done, value } = await reader.read();\n    if (done) {\n      let generateContentResponse = aggregateResponses(allResponses);\n      if (apiSettings.backend.backendType === BackendType.GOOGLE_AI) {\n        generateContentResponse = GoogleAIMapper.mapGenerateContentResponse(\n          generateContentResponse as GoogleAIGenerateContentResponse\n        );\n      }\n      return createEnhancedContentResponse(\n        generateContentResponse,\n        inferenceSource\n      );\n    }\n\n    allResponses.push(value);\n  }\n}\n\nasync function* generateResponseSequence(\n  stream: ReadableStream<GenerateContentResponse>,\n  apiSettings: ApiSettings,\n  inferenceSource?: InferenceSource\n): AsyncGenerator<EnhancedGenerateContentResponse> {\n  const reader = stream.getReader();\n  while (true) {\n    const { value, done } = await reader.read();\n    if (done) {\n      break;\n    }\n\n    let enhancedResponse: EnhancedGenerateContentResponse;\n    if (apiSettings.backend.backendType === BackendType.GOOGLE_AI) {\n      enhancedResponse = createEnhancedContentResponse(\n        GoogleAIMapper.mapGenerateContentResponse(\n          value as GoogleAIGenerateContentResponse\n        ),\n        inferenceSource\n      );\n    } else {\n      enhancedResponse = createEnhancedContentResponse(value, inferenceSource);\n    }\n\n    const firstCandidate = enhancedResponse.candidates?.[0];\n    // Don't yield a response with no useful data for the developer.\n    if (\n      !firstCandidate?.content?.parts &&\n      !firstCandidate?.finishReason &&\n      !firstCandidate?.citationMetadata &&\n      !firstCandidate?.urlContextMetadata\n    ) {\n      continue;\n    }\n\n    yield enhancedResponse;\n  }\n}\n\n/**\n * Reads a raw stream from the fetch response and join incomplete\n * chunks, returning a new stream that provides a single complete\n * GenerateContentResponse in each iteration.\n */\nexport function getResponseStream<T>(\n  inputStream: ReadableStream<string>\n): ReadableStream<T> {\n  const reader = inputStream.getReader();\n  const stream = new ReadableStream<T>({\n    start(controller) {\n      let currentText = '';\n      return pump();\n      function pump(): Promise<(() => Promise<void>) | undefined> {\n        return reader.read().then(({ value, done }) => {\n          if (done) {\n            if (currentText.trim()) {\n              controller.error(\n                new AIError(AIErrorCode.PARSE_FAILED, 'Failed to parse stream')\n              );\n              return;\n            }\n            controller.close();\n            return;\n          }\n\n          currentText += value;\n          let match = currentText.match(responseLineRE);\n          let parsedResponse: T;\n          while (match) {\n            try {\n              parsedResponse = JSON.parse(match[1]);\n            } catch (e) {\n              controller.error(\n                new AIError(\n                  AIErrorCode.PARSE_FAILED,\n                  `Error parsing JSON response: \"${match[1]}`\n                )\n              );\n              return;\n            }\n            controller.enqueue(parsedResponse);\n            currentText = currentText.substring(match[0].length);\n            match = currentText.match(responseLineRE);\n          }\n          return pump();\n        });\n      }\n    }\n  });\n  return stream;\n}\n\n/**\n * Aggregates an array of `GenerateContentResponse`s into a single\n * GenerateContentResponse.\n */\nexport function aggregateResponses(\n  responses: GenerateContentResponse[]\n): GenerateContentResponse {\n  const lastResponse = responses[responses.length - 1];\n  const aggregatedResponse: GenerateContentResponse = {\n    promptFeedback: lastResponse?.promptFeedback\n  };\n  for (const response of responses) {\n    if (response.candidates) {\n      for (const candidate of response.candidates) {\n        // Index will be undefined if it's the first index (0), so we should use 0 if it's undefined.\n        // See: https://github.com/firebase/firebase-js-sdk/issues/8566\n        const i = candidate.index || 0;\n        if (!aggregatedResponse.candidates) {\n          aggregatedResponse.candidates = [];\n        }\n        if (!aggregatedResponse.candidates[i]) {\n          aggregatedResponse.candidates[i] = {\n            index: candidate.index\n          } as GenerateContentCandidate;\n        }\n        // Keep overwriting, the last one will be final\n        aggregatedResponse.candidates[i].citationMetadata =\n          candidate.citationMetadata;\n        aggregatedResponse.candidates[i].finishReason = candidate.finishReason;\n        aggregatedResponse.candidates[i].finishMessage =\n          candidate.finishMessage;\n        aggregatedResponse.candidates[i].safetyRatings =\n          candidate.safetyRatings;\n        aggregatedResponse.candidates[i].groundingMetadata =\n          candidate.groundingMetadata;\n\n        // The urlContextMetadata object is defined in the first chunk of the response stream.\n        // In all subsequent chunks, the urlContextMetadata object will be undefined. We need to\n        // make sure that we don't overwrite the first value urlContextMetadata object with undefined.\n        // FIXME: What happens if we receive a second, valid urlContextMetadata object?\n        const urlContextMetadata = candidate.urlContextMetadata as unknown;\n        if (\n          typeof urlContextMetadata === 'object' &&\n          urlContextMetadata !== null &&\n          Object.keys(urlContextMetadata).length > 0\n        ) {\n          aggregatedResponse.candidates[i].urlContextMetadata =\n            urlContextMetadata as URLContextMetadata;\n        }\n\n        /**\n         * Candidates should always have content and parts, but this handles\n         * possible malformed responses.\n         */\n        if (candidate.content) {\n          // Skip a candidate without parts.\n          if (!candidate.content.parts) {\n            continue;\n          }\n          if (!aggregatedResponse.candidates[i].content) {\n            aggregatedResponse.candidates[i].content = {\n              role: candidate.content.role || 'user',\n              parts: []\n            };\n          }\n          for (const part of candidate.content.parts) {\n            const newPart: Part = { ...part };\n            // The backend can send empty text parts. If these are sent back\n            // (e.g. in chat history), the backend will respond with an error.\n            // To prevent this, ignore empty text parts.\n            if (part.text === '') {\n              continue;\n            }\n            if (Object.keys(newPart).length > 0) {\n              aggregatedResponse.candidates[i].content.parts.push(\n                newPart as Part\n              );\n            }\n          }\n        }\n      }\n    }\n  }\n  return aggregatedResponse;\n}\n", "/**\n * @license\n * Copyright 2025 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { AIError } from '../errors';\nimport {\n  GenerateContentRequest,\n  InferenceMode,\n  AIErrorCode,\n  ChromeAdapter,\n  InferenceSource\n} from '../types';\n\nconst errorsCausingFallback: AIErrorCode[] = [\n  // most network errors\n  AIErrorCode.FETCH_ERROR,\n  // fallback code for all other errors in makeRequest\n  AIErrorCode.ERROR,\n  // error due to API not being enabled in project\n  AIErrorCode.API_NOT_ENABLED\n];\n\ninterface CallResult<Response> {\n  response: Response;\n  inferenceSource: InferenceSource;\n}\n\n/**\n * Dispatches a request to the appropriate backend (on-device or in-cloud)\n * based on the inference mode.\n *\n * @param request - The request to be sent.\n * @param chromeAdapter - The on-device model adapter.\n * @param onDeviceCall - The function to call for on-device inference.\n * @param inCloudCall - The function to call for in-cloud inference.\n * @returns The response from the backend.\n */\nexport async function callCloudOrDevice<Response>(\n  request: GenerateContentRequest,\n  chromeAdapter: ChromeAdapter | undefined,\n  onDeviceCall: () => Promise<Response>,\n  inCloudCall: () => Promise<Response>\n): Promise<CallResult<Response>> {\n  if (!chromeAdapter) {\n    return {\n      response: await inCloudCall(),\n      inferenceSource: InferenceSource.IN_CLOUD\n    };\n  }\n  switch (chromeAdapter.mode) {\n    case InferenceMode.ONLY_ON_DEVICE:\n      if (await chromeAdapter.isAvailable(request)) {\n        return {\n          response: await onDeviceCall(),\n          inferenceSource: InferenceSource.ON_DEVICE\n        };\n      }\n      throw new AIError(\n        AIErrorCode.UNSUPPORTED,\n        'Inference mode is ONLY_ON_DEVICE, but an on-device model is not available.'\n      );\n    case InferenceMode.ONLY_IN_CLOUD:\n      return {\n        response: await inCloudCall(),\n        inferenceSource: InferenceSource.IN_CLOUD\n      };\n    case InferenceMode.PREFER_IN_CLOUD:\n      try {\n        return {\n          response: await inCloudCall(),\n          inferenceSource: InferenceSource.IN_CLOUD\n        };\n      } catch (e) {\n        if (e instanceof AIError && errorsCausingFallback.includes(e.code)) {\n          return {\n            response: await onDeviceCall(),\n            inferenceSource: InferenceSource.ON_DEVICE\n          };\n        }\n        throw e;\n      }\n    case InferenceMode.PREFER_ON_DEVICE:\n      if (await chromeAdapter.isAvailable(request)) {\n        return {\n          response: await onDeviceCall(),\n          inferenceSource: InferenceSource.ON_DEVICE\n        };\n      }\n      return {\n        response: await inCloudCall(),\n        inferenceSource: InferenceSource.IN_CLOUD\n      };\n    default:\n      throw new AIError(\n        AIErrorCode.ERROR,\n        `Unexpected infererence mode: ${chromeAdapter.mode}`\n      );\n  }\n}\n", "/**\n * @license\n * Copyright 2024 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport {\n  GenerateContentRequest,\n  GenerateContentResponse,\n  GenerateContentResult,\n  GenerateContentStreamResult,\n  RequestOptions\n} from '../types';\nimport {\n  makeRequest,\n  ServerPromptTemplateTask,\n  Task\n} from '../requests/request';\nimport { createEnhancedContentResponse } from '../requests/response-helpers';\nimport { processStream } from '../requests/stream-reader';\nimport { ApiSettings } from '../types/internal';\nimport * as GoogleAIMapper from '../googleai-mappers';\nimport { BackendType } from '../public-types';\nimport { ChromeAdapter } from '../types/chrome-adapter';\nimport { callCloudOrDevice } from '../requests/hybrid-helpers';\n\nasync function generateContentStreamOnCloud(\n  apiSettings: ApiSettings,\n  model: string,\n  params: GenerateContentRequest,\n  requestOptions?: RequestOptions\n): Promise<Response> {\n  if (apiSettings.backend.backendType === BackendType.GOOGLE_AI) {\n    params = GoogleAIMapper.mapGenerateContentRequest(params);\n  }\n  return makeRequest(\n    {\n      task: Task.STREAM_GENERATE_CONTENT,\n      model,\n      apiSettings,\n      stream: true,\n      requestOptions\n    },\n    JSON.stringify(params)\n  );\n}\n\nexport async function generateContentStream(\n  apiSettings: ApiSettings,\n  model: string,\n  params: GenerateContentRequest,\n  chromeAdapter?: ChromeAdapter,\n  requestOptions?: RequestOptions\n): Promise<GenerateContentStreamResult> {\n  const callResult = await callCloudOrDevice(\n    params,\n    chromeAdapter,\n    () => chromeAdapter!.generateContentStream(params),\n    () =>\n      generateContentStreamOnCloud(apiSettings, model, params, requestOptions)\n  );\n  return processStream(callResult.response, apiSettings); // TODO: Map streaming responses\n}\n\nasync function generateContentOnCloud(\n  apiSettings: ApiSettings,\n  model: string,\n  params: GenerateContentRequest,\n  requestOptions?: RequestOptions\n): Promise<Response> {\n  if (apiSettings.backend.backendType === BackendType.GOOGLE_AI) {\n    params = GoogleAIMapper.mapGenerateContentRequest(params);\n  }\n  return makeRequest(\n    {\n      model,\n      task: Task.GENERATE_CONTENT,\n      apiSettings,\n      stream: false,\n      requestOptions\n    },\n    JSON.stringify(params)\n  );\n}\n\nexport async function templateGenerateContent(\n  apiSettings: ApiSettings,\n  templateId: string,\n  templateParams: object,\n  requestOptions?: RequestOptions\n): Promise<GenerateContentResult> {\n  const response = await makeRequest(\n    {\n      task: ServerPromptTemplateTask.TEMPLATE_GENERATE_CONTENT,\n      templateId,\n      apiSettings,\n      stream: false,\n      requestOptions\n    },\n    JSON.stringify(templateParams)\n  );\n  const generateContentResponse = await processGenerateContentResponse(\n    response,\n    apiSettings\n  );\n  const enhancedResponse = createEnhancedContentResponse(\n    generateContentResponse\n  );\n  return {\n    response: enhancedResponse\n  };\n}\n\nexport async function templateGenerateContentStream(\n  apiSettings: ApiSettings,\n  templateId: string,\n  templateParams: object,\n  requestOptions?: RequestOptions\n): Promise<GenerateContentStreamResult> {\n  const response = await makeRequest(\n    {\n      task: ServerPromptTemplateTask.TEMPLATE_STREAM_GENERATE_CONTENT,\n      templateId,\n      apiSettings,\n      stream: true,\n      requestOptions\n    },\n    JSON.stringify(templateParams)\n  );\n  return processStream(response, apiSettings);\n}\n\nexport async function generateContent(\n  apiSettings: ApiSettings,\n  model: string,\n  params: GenerateContentRequest,\n  chromeAdapter?: ChromeAdapter,\n  requestOptions?: RequestOptions\n): Promise<GenerateContentResult> {\n  const callResult = await callCloudOrDevice(\n    params,\n    chromeAdapter,\n    () => chromeAdapter!.generateContent(params),\n    () => generateContentOnCloud(apiSettings, model, params, requestOptions)\n  );\n  const generateContentResponse = await processGenerateContentResponse(\n    callResult.response,\n    apiSettings\n  );\n  const enhancedResponse = createEnhancedContentResponse(\n    generateContentResponse,\n    callResult.inferenceSource\n  );\n  return {\n    response: enhancedResponse\n  };\n}\n\nasync function processGenerateContentResponse(\n  response: Response,\n  apiSettings: ApiSettings\n): Promise<GenerateContentResponse> {\n  const responseJson = await response.json();\n  if (apiSettings.backend.backendType === BackendType.GOOGLE_AI) {\n    return GoogleAIMapper.mapGenerateContentResponse(responseJson);\n  } else {\n    return responseJson;\n  }\n}\n", "/**\n * @license\n * Copyright 2024 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { Content, GenerateContentRequest, Part, AIErrorCode } from '../types';\nimport { AIError } from '../errors';\nimport { ImagenGenerationParams, PredictRequestBody } from '../types/internal';\n\nexport function formatSystemInstruction(\n  input?: string | Part | Content\n): Content | undefined {\n  // null or undefined\n  if (input == null) {\n    return undefined;\n  } else if (typeof input === 'string') {\n    return { role: 'system', parts: [{ text: input }] } as Content;\n  } else if ((input as Part).text) {\n    return { role: 'system', parts: [input as Part] };\n  } else if ((input as Content).parts) {\n    if (!(input as Content).role) {\n      return { role: 'system', parts: (input as Content).parts };\n    } else {\n      return input as Content;\n    }\n  }\n}\n\nexport function formatNewContent(\n  request: string | Array<string | Part>\n): Content {\n  let newParts: Part[] = [];\n  if (typeof request === 'string') {\n    newParts = [{ text: request }];\n  } else {\n    for (const partOrString of request) {\n      if (typeof partOrString === 'string') {\n        newParts.push({ text: partOrString });\n      } else {\n        newParts.push(partOrString);\n      }\n    }\n  }\n  return assignRoleToPartsAndValidateSendMessageRequest(newParts);\n}\n\n/**\n * When multiple Part types (i.e. FunctionResponsePart and TextPart) are\n * passed in a single Part array, we may need to assign different roles to each\n * part. Currently only FunctionResponsePart requires a role other than 'user'.\n * @private\n * @param parts Array of parts to pass to the model\n * @returns Array of content items\n */\nfunction assignRoleToPartsAndValidateSendMessageRequest(\n  parts: Part[]\n): Content {\n  const userContent: Content = { role: 'user', parts: [] };\n  const functionContent: Content = { role: 'function', parts: [] };\n  let hasUserContent = false;\n  let hasFunctionContent = false;\n  for (const part of parts) {\n    if ('functionResponse' in part) {\n      functionContent.parts.push(part);\n      hasFunctionContent = true;\n    } else {\n      userContent.parts.push(part);\n      hasUserContent = true;\n    }\n  }\n\n  if (hasUserContent && hasFunctionContent) {\n    throw new AIError(\n      AIErrorCode.INVALID_CONTENT,\n      'Within a single message, FunctionResponse cannot be mixed with other type of Part in the request for sending chat message.'\n    );\n  }\n\n  if (!hasUserContent && !hasFunctionContent) {\n    throw new AIError(\n      AIErrorCode.INVALID_CONTENT,\n      'No Content is provided for sending chat message.'\n    );\n  }\n\n  if (hasUserContent) {\n    return userContent;\n  }\n\n  return functionContent;\n}\n\nexport function formatGenerateContentInput(\n  params: GenerateContentRequest | string | Array<string | Part>\n): GenerateContentRequest {\n  let formattedRequest: GenerateContentRequest;\n  if ((params as GenerateContentRequest).contents) {\n    formattedRequest = params as GenerateContentRequest;\n  } else {\n    // Array or string\n    const content = formatNewContent(params as string | Array<string | Part>);\n    formattedRequest = { contents: [content] };\n  }\n  if ((params as GenerateContentRequest).systemInstruction) {\n    formattedRequest.systemInstruction = formatSystemInstruction(\n      (params as GenerateContentRequest).systemInstruction\n    );\n  }\n  return formattedRequest;\n}\n\n/**\n * Convert the user-defined parameters in {@link ImagenGenerationParams} to the format\n * that is expected from the REST API.\n *\n * @internal\n */\nexport function createPredictRequestBody(\n  prompt: string,\n  {\n    gcsURI,\n    imageFormat,\n    addWatermark,\n    numberOfImages = 1,\n    negativePrompt,\n    aspectRatio,\n    safetyFilterLevel,\n    personFilterLevel\n  }: ImagenGenerationParams\n): PredictRequestBody {\n  // Properties that are undefined will be omitted from the JSON string that is sent in the request.\n  const body: PredictRequestBody = {\n    instances: [\n      {\n        prompt\n      }\n    ],\n    parameters: {\n      storageUri: gcsURI,\n      negativePrompt,\n      sampleCount: numberOfImages,\n      aspectRatio,\n      outputOptions: imageFormat,\n      addWatermark,\n      safetyFilterLevel,\n      personGeneration: personFilterLevel,\n      includeRaiReason: true,\n      includeSafetyAttributes: true\n    }\n  };\n  return body;\n}\n", "/**\n * @license\n * Copyright 2024 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { Content, POSSIBLE_ROLES, Part, Role, AIErrorCode } from '../types';\nimport { AIError } from '../errors';\n\n// https://ai.google.dev/api/rest/v1beta/Content#part\n\nconst VALID_PART_FIELDS: Array<keyof Part> = [\n  'text',\n  'inlineData',\n  'functionCall',\n  'functionResponse',\n  'thought',\n  'thoughtSignature'\n];\n\nconst VALID_PARTS_PER_ROLE: { [key in Role]: Array<keyof Part> } = {\n  user: ['text', 'inlineData'],\n  function: ['functionResponse'],\n  model: ['text', 'functionCall', 'thought', 'thoughtSignature'],\n  // System instructions shouldn't be in history anyway.\n  system: ['text']\n};\n\nconst VALID_PREVIOUS_CONTENT_ROLES: { [key in Role]: Role[] } = {\n  user: ['model'],\n  function: ['model'],\n  model: ['user', 'function'],\n  // System instructions shouldn't be in history.\n  system: []\n};\n\nexport function validateChatHistory(history: Content[]): void {\n  let prevContent: Content | null = null;\n  for (const currContent of history) {\n    const { role, parts } = currContent;\n    if (!prevContent && role !== 'user') {\n      throw new AIError(\n        AIErrorCode.INVALID_CONTENT,\n        `First Content should be with role 'user', got ${role}`\n      );\n    }\n    if (!POSSIBLE_ROLES.includes(role)) {\n      throw new AIError(\n        AIErrorCode.INVALID_CONTENT,\n        `Each item should include role field. Got ${role} but valid roles are: ${JSON.stringify(\n          POSSIBLE_ROLES\n        )}`\n      );\n    }\n\n    if (!Array.isArray(parts)) {\n      throw new AIError(\n        AIErrorCode.INVALID_CONTENT,\n        `Content should have 'parts' property with an array of Parts`\n      );\n    }\n\n    if (parts.length === 0) {\n      throw new AIError(\n        AIErrorCode.INVALID_CONTENT,\n        `Each Content should have at least one part`\n      );\n    }\n\n    const countFields: Record<keyof Part, number> = {\n      text: 0,\n      inlineData: 0,\n      functionCall: 0,\n      functionResponse: 0,\n      thought: 0,\n      thoughtSignature: 0,\n      executableCode: 0,\n      codeExecutionResult: 0\n    };\n\n    for (const part of parts) {\n      for (const key of VALID_PART_FIELDS) {\n        if (key in part) {\n          countFields[key] += 1;\n        }\n      }\n    }\n    const validParts = VALID_PARTS_PER_ROLE[role];\n    for (const key of VALID_PART_FIELDS) {\n      if (!validParts.includes(key) && countFields[key] > 0) {\n        throw new AIError(\n          AIErrorCode.INVALID_CONTENT,\n          `Content with role '${role}' can't contain '${key}' part`\n        );\n      }\n    }\n\n    if (prevContent) {\n      const validPreviousContentRoles = VALID_PREVIOUS_CONTENT_ROLES[role];\n      if (!validPreviousContentRoles.includes(prevContent.role)) {\n        throw new AIError(\n          AIErrorCode.INVALID_CONTENT,\n          `Content with role '${role}' can't follow '${\n            prevContent.role\n          }'. Valid previous roles: ${JSON.stringify(\n            VALID_PREVIOUS_CONTENT_ROLES\n          )}`\n        );\n      }\n    }\n    prevContent = currContent;\n  }\n}\n", "/**\n * @license\n * Copyright 2024 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport {\n  Content,\n  GenerateContentRequest,\n  GenerateContentResult,\n  GenerateContentStreamResult,\n  Part,\n  RequestOptions,\n  StartChatParams\n} from '../types';\nimport { formatNewContent } from '../requests/request-helpers';\nimport { formatBlockErrorMessage } from '../requests/response-helpers';\nimport { validateChatHistory } from './chat-session-helpers';\nimport { generateContent, generateContentStream } from './generate-content';\nimport { ApiSettings } from '../types/internal';\nimport { logger } from '../logger';\nimport { ChromeAdapter } from '../types/chrome-adapter';\n\n/**\n * Do not log a message for this error.\n */\nconst SILENT_ERROR = 'SILENT_ERROR';\n\n/**\n * ChatSession class that enables sending chat messages and stores\n * history of sent and received messages so far.\n *\n * @public\n */\nexport class ChatSession {\n  private _apiSettings: ApiSettings;\n  private _history: Content[] = [];\n  private _sendPromise: Promise<void> = Promise.resolve();\n\n  constructor(\n    apiSettings: ApiSettings,\n    public model: string,\n    private chromeAdapter?: ChromeAdapter,\n    public params?: StartChatParams,\n    public requestOptions?: RequestOptions\n  ) {\n    this._apiSettings = apiSettings;\n    if (params?.history) {\n      validateChatHistory(params.history);\n      this._history = params.history;\n    }\n  }\n\n  /**\n   * Gets the chat history so far. Blocked prompts are not added to history.\n   * Neither blocked candidates nor the prompts that generated them are added\n   * to history.\n   */\n  async getHistory(): Promise<Content[]> {\n    await this._sendPromise;\n    return this._history;\n  }\n\n  /**\n   * Sends a chat message and receives a non-streaming\n   * {@link GenerateContentResult}\n   */\n  async sendMessage(\n    request: string | Array<string | Part>\n  ): Promise<GenerateContentResult> {\n    await this._sendPromise;\n    const newContent = formatNewContent(request);\n    const generateContentRequest: GenerateContentRequest = {\n      safetySettings: this.params?.safetySettings,\n      generationConfig: this.params?.generationConfig,\n      tools: this.params?.tools,\n      toolConfig: this.params?.toolConfig,\n      systemInstruction: this.params?.systemInstruction,\n      contents: [...this._history, newContent]\n    };\n    let finalResult = {} as GenerateContentResult;\n    // Add onto the chain.\n    this._sendPromise = this._sendPromise\n      .then(() =>\n        generateContent(\n          this._apiSettings,\n          this.model,\n          generateContentRequest,\n          this.chromeAdapter,\n          this.requestOptions\n        )\n      )\n      .then(result => {\n        if (\n          result.response.candidates &&\n          result.response.candidates.length > 0\n        ) {\n          this._history.push(newContent);\n          const responseContent: Content = {\n            parts: result.response.candidates?.[0].content.parts || [],\n            // Response seems to come back without a role set.\n            role: result.response.candidates?.[0].content.role || 'model'\n          };\n          this._history.push(responseContent);\n        } else {\n          const blockErrorMessage = formatBlockErrorMessage(result.response);\n          if (blockErrorMessage) {\n            logger.warn(\n              `sendMessage() was unsuccessful. ${blockErrorMessage}. Inspect response object for details.`\n            );\n          }\n        }\n        finalResult = result;\n      });\n    await this._sendPromise;\n    return finalResult;\n  }\n\n  /**\n   * Sends a chat message and receives the response as a\n   * {@link GenerateContentStreamResult} containing an iterable stream\n   * and a response promise.\n   */\n  async sendMessageStream(\n    request: string | Array<string | Part>\n  ): Promise<GenerateContentStreamResult> {\n    await this._sendPromise;\n    const newContent = formatNewContent(request);\n    const generateContentRequest: GenerateContentRequest = {\n      safetySettings: this.params?.safetySettings,\n      generationConfig: this.params?.generationConfig,\n      tools: this.params?.tools,\n      toolConfig: this.params?.toolConfig,\n      systemInstruction: this.params?.systemInstruction,\n      contents: [...this._history, newContent]\n    };\n    const streamPromise = generateContentStream(\n      this._apiSettings,\n      this.model,\n      generateContentRequest,\n      this.chromeAdapter,\n      this.requestOptions\n    );\n\n    // Add onto the chain.\n    this._sendPromise = this._sendPromise\n      .then(() => streamPromise)\n      // This must be handled to avoid unhandled rejection, but jump\n      // to the final catch block with a label to not log this error.\n      .catch(_ignored => {\n        throw new Error(SILENT_ERROR);\n      })\n      .then(streamResult => streamResult.response)\n      .then(response => {\n        if (response.candidates && response.candidates.length > 0) {\n          this._history.push(newContent);\n          const responseContent = { ...response.candidates[0].content };\n          // Response seems to come back without a role set.\n          if (!responseContent.role) {\n            responseContent.role = 'model';\n          }\n          this._history.push(responseContent);\n        } else {\n          const blockErrorMessage = formatBlockErrorMessage(response);\n          if (blockErrorMessage) {\n            logger.warn(\n              `sendMessageStream() was unsuccessful. ${blockErrorMessage}. Inspect response object for details.`\n            );\n          }\n        }\n      })\n      .catch(e => {\n        // Errors in streamPromise are already catchable by the user as\n        // streamPromise is returned.\n        // Avoid duplicating the error message in logs.\n        if (e.message !== SILENT_ERROR) {\n          // Users do not have access to _sendPromise to catch errors\n          // downstream from streamPromise, so they should not throw.\n          logger.error(e);\n        }\n      });\n    return streamPromise;\n  }\n}\n", "/**\n * @license\n * Copyright 2024 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { AIError } from '../errors';\nimport {\n  CountTokensRequest,\n  CountTokensResponse,\n  InferenceMode,\n  RequestOptions,\n  AIErrorCode\n} from '../types';\nimport { makeRequest, Task } from '../requests/request';\nimport { ApiSettings } from '../types/internal';\nimport * as GoogleAIMapper from '../googleai-mappers';\nimport { BackendType } from '../public-types';\nimport { ChromeAdapter } from '../types/chrome-adapter';\n\nexport async function countTokensOnCloud(\n  apiSettings: ApiSettings,\n  model: string,\n  params: CountTokensRequest,\n  requestOptions?: RequestOptions\n): Promise<CountTokensResponse> {\n  let body: string = '';\n  if (apiSettings.backend.backendType === BackendType.GOOGLE_AI) {\n    const mappedParams = GoogleAIMapper.mapCountTokensRequest(params, model);\n    body = JSON.stringify(mappedParams);\n  } else {\n    body = JSON.stringify(params);\n  }\n  const response = await makeRequest(\n    {\n      model,\n      task: Task.COUNT_TOKENS,\n      apiSettings,\n      stream: false,\n      requestOptions\n    },\n    body\n  );\n  return response.json();\n}\n\nexport async function countTokens(\n  apiSettings: ApiSettings,\n  model: string,\n  params: CountTokensRequest,\n  chromeAdapter?: ChromeAdapter,\n  requestOptions?: RequestOptions\n): Promise<CountTokensResponse> {\n  if (chromeAdapter?.mode === InferenceMode.ONLY_ON_DEVICE) {\n    throw new AIError(\n      AIErrorCode.UNSUPPORTED,\n      'countTokens() is not supported for on-device models.'\n    );\n  }\n  return countTokensOnCloud(apiSettings, model, params, requestOptions);\n}\n", "/**\n * @license\n * Copyright 2024 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport {\n  generateContent,\n  generateContentStream\n} from '../methods/generate-content';\nimport {\n  Content,\n  CountTokensRequest,\n  CountTokensResponse,\n  GenerateContentRequest,\n  GenerateContentResult,\n  GenerateContentStreamResult,\n  GenerationConfig,\n  ModelParams,\n  Part,\n  RequestOptions,\n  SafetySetting,\n  StartChatParams,\n  Tool,\n  ToolConfig\n} from '../types';\nimport { ChatSession } from '../methods/chat-session';\nimport { countTokens } from '../methods/count-tokens';\nimport {\n  formatGenerateContentInput,\n  formatSystemInstruction\n} from '../requests/request-helpers';\nimport { AI } from '../public-types';\nimport { AIModel } from './ai-model';\nimport { ChromeAdapter } from '../types/chrome-adapter';\n\n/**\n * Class for generative model APIs.\n * @public\n */\nexport class GenerativeModel extends AIModel {\n  generationConfig: GenerationConfig;\n  safetySettings: SafetySetting[];\n  requestOptions?: RequestOptions;\n  tools?: Tool[];\n  toolConfig?: ToolConfig;\n  systemInstruction?: Content;\n\n  constructor(\n    ai: AI,\n    modelParams: ModelParams,\n    requestOptions?: RequestOptions,\n    private chromeAdapter?: ChromeAdapter\n  ) {\n    super(ai, modelParams.model);\n    this.generationConfig = modelParams.generationConfig || {};\n    this.safetySettings = modelParams.safetySettings || [];\n    this.tools = modelParams.tools;\n    this.toolConfig = modelParams.toolConfig;\n    this.systemInstruction = formatSystemInstruction(\n      modelParams.systemInstruction\n    );\n    this.requestOptions = requestOptions || {};\n  }\n\n  /**\n   * Makes a single non-streaming call to the model\n   * and returns an object containing a single {@link GenerateContentResponse}.\n   */\n  async generateContent(\n    request: GenerateContentRequest | string | Array<string | Part>\n  ): Promise<GenerateContentResult> {\n    const formattedParams = formatGenerateContentInput(request);\n    return generateContent(\n      this._apiSettings,\n      this.model,\n      {\n        generationConfig: this.generationConfig,\n        safetySettings: this.safetySettings,\n        tools: this.tools,\n        toolConfig: this.toolConfig,\n        systemInstruction: this.systemInstruction,\n        ...formattedParams\n      },\n      this.chromeAdapter,\n      this.requestOptions\n    );\n  }\n\n  /**\n   * Makes a single streaming call to the model\n   * and returns an object containing an iterable stream that iterates\n   * over all chunks in the streaming response as well as\n   * a promise that returns the final aggregated response.\n   */\n  async generateContentStream(\n    request: GenerateContentRequest | string | Array<string | Part>\n  ): Promise<GenerateContentStreamResult> {\n    const formattedParams = formatGenerateContentInput(request);\n    return generateContentStream(\n      this._apiSettings,\n      this.model,\n      {\n        generationConfig: this.generationConfig,\n        safetySettings: this.safetySettings,\n        tools: this.tools,\n        toolConfig: this.toolConfig,\n        systemInstruction: this.systemInstruction,\n        ...formattedParams\n      },\n      this.chromeAdapter,\n      this.requestOptions\n    );\n  }\n\n  /**\n   * Gets a new {@link ChatSession} instance which can be used for\n   * multi-turn chats.\n   */\n  startChat(startChatParams?: StartChatParams): ChatSession {\n    return new ChatSession(\n      this._apiSettings,\n      this.model,\n      this.chromeAdapter,\n      {\n        tools: this.tools,\n        toolConfig: this.toolConfig,\n        systemInstruction: this.systemInstruction,\n        generationConfig: this.generationConfig,\n        safetySettings: this.safetySettings,\n        /**\n         * Overrides params inherited from GenerativeModel with those explicitly set in the\n         * StartChatParams. For example, if startChatParams.generationConfig is set, it'll override\n         * this.generationConfig.\n         */\n        ...startChatParams\n      },\n      this.requestOptions\n    );\n  }\n\n  /**\n   * Counts the tokens in the provided request.\n   */\n  async countTokens(\n    request: CountTokensRequest | string | Array<string | Part>\n  ): Promise<CountTokensResponse> {\n    const formattedParams = formatGenerateContentInput(request);\n    return countTokens(\n      this._apiSettings,\n      this.model,\n      formattedParams,\n      this.chromeAdapter\n    );\n  }\n}\n", "/**\n * @license\n * Copyright 2025 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport {\n  AIErrorCode,\n  FunctionResponse,\n  GenerativeContentBlob,\n  LiveResponseType,\n  LiveServerContent,\n  LiveServerToolCall,\n  LiveServerToolCallCancellation,\n  Part\n} from '../public-types';\nimport { formatNewContent } from '../requests/request-helpers';\nimport { AIError } from '../errors';\nimport { WebSocketHandler } from '../websocket';\nimport { logger } from '../logger';\nimport {\n  _LiveClientContent,\n  _LiveClientRealtimeInput,\n  _LiveClientToolResponse\n} from '../types/live-responses';\n\n/**\n * Represents an active, real-time, bidirectional conversation with the model.\n *\n * This class should only be instantiated by calling {@link LiveGenerativeModel.connect}.\n *\n * @beta\n */\nexport class LiveSession {\n  /**\n   * Indicates whether this Live session is closed.\n   *\n   * @beta\n   */\n  isClosed = false;\n  /**\n   * Indicates whether this Live session is being controlled by an `AudioConversationController`.\n   *\n   * @beta\n   */\n  inConversation = false;\n\n  /**\n   * @internal\n   */\n  constructor(\n    private webSocketHandler: WebSocketHandler,\n    private serverMessages: AsyncGenerator<unknown>\n  ) {}\n\n  /**\n   * Sends content to the server.\n   *\n   * @param request - The message to send to the model.\n   * @param turnComplete - Indicates if the turn is complete. Defaults to false.\n   * @throws If this session has been closed.\n   *\n   * @beta\n   */\n  async send(\n    request: string | Array<string | Part>,\n    turnComplete = true\n  ): Promise<void> {\n    if (this.isClosed) {\n      throw new AIError(\n        AIErrorCode.REQUEST_ERROR,\n        'This LiveSession has been closed and cannot be used.'\n      );\n    }\n\n    const newContent = formatNewContent(request);\n\n    const message: _LiveClientContent = {\n      clientContent: {\n        turns: [newContent],\n        turnComplete\n      }\n    };\n    this.webSocketHandler.send(JSON.stringify(message));\n  }\n\n  /**\n   * Sends text to the server in realtime.\n   *\n   * @example\n   * ```javascript\n   * liveSession.sendTextRealtime(\"Hello, how are you?\");\n   * ```\n   *\n   * @param text - The text data to send.\n   * @throws If this session has been closed.\n   *\n   * @beta\n   */\n  async sendTextRealtime(text: string): Promise<void> {\n    if (this.isClosed) {\n      throw new AIError(\n        AIErrorCode.REQUEST_ERROR,\n        'This LiveSession has been closed and cannot be used.'\n      );\n    }\n\n    const message: _LiveClientRealtimeInput = {\n      realtimeInput: {\n        text\n      }\n    };\n    this.webSocketHandler.send(JSON.stringify(message));\n  }\n\n  /**\n   * Sends audio data to the server in realtime.\n   *\n   * @remarks The server requires that the audio data is base64-encoded 16-bit PCM at 16kHz\n   * little-endian.\n   *\n   * @example\n   * ```javascript\n   * // const pcmData = ... base64-encoded 16-bit PCM at 16kHz little-endian.\n   * const blob = { mimeType: \"audio/pcm\", data: pcmData };\n   * liveSession.sendAudioRealtime(blob);\n   * ```\n   *\n   * @param blob - The base64-encoded PCM data to send to the server in realtime.\n   * @throws If this session has been closed.\n   *\n   * @beta\n   */\n  async sendAudioRealtime(blob: GenerativeContentBlob): Promise<void> {\n    if (this.isClosed) {\n      throw new AIError(\n        AIErrorCode.REQUEST_ERROR,\n        'This LiveSession has been closed and cannot be used.'\n      );\n    }\n\n    const message: _LiveClientRealtimeInput = {\n      realtimeInput: {\n        audio: blob\n      }\n    };\n    this.webSocketHandler.send(JSON.stringify(message));\n  }\n\n  /**\n   * Sends video data to the server in realtime.\n   *\n   * @remarks The server requires that the video is sent as individual video frames at 1 FPS. It\n   * is recommended to set `mimeType` to `image/jpeg`.\n   *\n   * @example\n   * ```javascript\n   * // const videoFrame = ... base64-encoded JPEG data\n   * const blob = { mimeType: \"image/jpeg\", data: videoFrame };\n   * liveSession.sendVideoRealtime(blob);\n   * ```\n   * @param blob - The base64-encoded video data to send to the server in realtime.\n   * @throws If this session has been closed.\n   *\n   * @beta\n   */\n  async sendVideoRealtime(blob: GenerativeContentBlob): Promise<void> {\n    if (this.isClosed) {\n      throw new AIError(\n        AIErrorCode.REQUEST_ERROR,\n        'This LiveSession has been closed and cannot be used.'\n      );\n    }\n\n    const message: _LiveClientRealtimeInput = {\n      realtimeInput: {\n        video: blob\n      }\n    };\n    this.webSocketHandler.send(JSON.stringify(message));\n  }\n\n  /**\n   * Sends function responses to the server.\n   *\n   * @param functionResponses - The function responses to send.\n   * @throws If this session has been closed.\n   *\n   * @beta\n   */\n  async sendFunctionResponses(\n    functionResponses: FunctionResponse[]\n  ): Promise<void> {\n    if (this.isClosed) {\n      throw new AIError(\n        AIErrorCode.REQUEST_ERROR,\n        'This LiveSession has been closed and cannot be used.'\n      );\n    }\n\n    const message: _LiveClientToolResponse = {\n      toolResponse: {\n        functionResponses\n      }\n    };\n    this.webSocketHandler.send(JSON.stringify(message));\n  }\n\n  /**\n   * Yields messages received from the server.\n   * This can only be used by one consumer at a time.\n   *\n   * @returns An `AsyncGenerator` that yields server messages as they arrive.\n   * @throws If the session is already closed, or if we receive a response that we don't support.\n   *\n   * @beta\n   */\n  async *receive(): AsyncGenerator<\n    LiveServerContent | LiveServerToolCall | LiveServerToolCallCancellation\n  > {\n    if (this.isClosed) {\n      throw new AIError(\n        AIErrorCode.SESSION_CLOSED,\n        'Cannot read from a Live session that is closed. Try starting a new Live session.'\n      );\n    }\n    for await (const message of this.serverMessages) {\n      if (message && typeof message === 'object') {\n        if (LiveResponseType.SERVER_CONTENT in message) {\n          yield {\n            type: 'serverContent',\n            ...(message as { serverContent: Omit<LiveServerContent, 'type'> })\n              .serverContent\n          } as LiveServerContent;\n        } else if (LiveResponseType.TOOL_CALL in message) {\n          yield {\n            type: 'toolCall',\n            ...(message as { toolCall: Omit<LiveServerToolCall, 'type'> })\n              .toolCall\n          } as LiveServerToolCall;\n        } else if (LiveResponseType.TOOL_CALL_CANCELLATION in message) {\n          yield {\n            type: 'toolCallCancellation',\n            ...(\n              message as {\n                toolCallCancellation: Omit<\n                  LiveServerToolCallCancellation,\n                  'type'\n                >;\n              }\n            ).toolCallCancellation\n          } as LiveServerToolCallCancellation;\n        } else {\n          logger.warn(\n            `Received an unknown message type from the server: ${JSON.stringify(\n              message\n            )}`\n          );\n        }\n      } else {\n        logger.warn(\n          `Received an invalid message from the server: ${JSON.stringify(\n            message\n          )}`\n        );\n      }\n    }\n  }\n\n  /**\n   * Closes this session.\n   * All methods on this session will throw an error once this resolves.\n   *\n   * @beta\n   */\n  async close(): Promise<void> {\n    if (!this.isClosed) {\n      this.isClosed = true;\n      await this.webSocketHandler.close(1000, 'Client closed session.');\n    }\n  }\n\n  /**\n   * Sends realtime input to the server.\n   *\n   * @deprecated Use `sendTextRealtime()`, `sendAudioRealtime()`, and `sendVideoRealtime()` instead.\n   *\n   * @param mediaChunks - The media chunks to send.\n   * @throws If this session has been closed.\n   *\n   * @beta\n   */\n  async sendMediaChunks(mediaChunks: GenerativeContentBlob[]): Promise<void> {\n    if (this.isClosed) {\n      throw new AIError(\n        AIErrorCode.REQUEST_ERROR,\n        'This LiveSession has been closed and cannot be used.'\n      );\n    }\n\n    // The backend does not support sending more than one mediaChunk in one message.\n    // Work around this limitation by sending mediaChunks in separate messages.\n    mediaChunks.forEach(mediaChunk => {\n      const message: _LiveClientRealtimeInput = {\n        realtimeInput: { mediaChunks: [mediaChunk] }\n      };\n      this.webSocketHandler.send(JSON.stringify(message));\n    });\n  }\n\n  /**\n   * @deprecated Use `sendTextRealtime()`, `sendAudioRealtime()`, and `sendVideoRealtime()` instead.\n   *\n   * Sends a stream of {@link GenerativeContentBlob}.\n   *\n   * @param mediaChunkStream - The stream of {@link GenerativeContentBlob} to send.\n   * @throws If this session has been closed.\n   *\n   * @beta\n   */\n  async sendMediaStream(\n    mediaChunkStream: ReadableStream<GenerativeContentBlob>\n  ): Promise<void> {\n    if (this.isClosed) {\n      throw new AIError(\n        AIErrorCode.REQUEST_ERROR,\n        'This LiveSession has been closed and cannot be used.'\n      );\n    }\n\n    const reader = mediaChunkStream.getReader();\n    while (true) {\n      try {\n        const { done, value } = await reader.read();\n\n        if (done) {\n          break;\n        } else if (!value) {\n          throw new Error('Missing chunk in reader, but reader is not done.');\n        }\n\n        await this.sendMediaChunks([value]);\n      } catch (e) {\n        // Re-throw any errors that occur during stream consumption or sending.\n        const message =\n          e instanceof Error ? e.message : 'Error processing media stream.';\n        throw new AIError(AIErrorCode.REQUEST_ERROR, message);\n      }\n    }\n  }\n}\n", "/**\n * @license\n * Copyright 2025 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { AIModel } from './ai-model';\nimport { LiveSession } from '../methods/live-session';\nimport { AIError } from '../errors';\nimport {\n  AI,\n  AIErrorCode,\n  BackendType,\n  Content,\n  LiveGenerationConfig,\n  LiveModelParams,\n  Tool,\n  ToolConfig\n} from '../public-types';\nimport { WebSocketHandler } from '../websocket';\nimport { WebSocketUrl } from '../requests/request';\nimport { formatSystemInstruction } from '../requests/request-helpers';\nimport { _LiveClientSetup } from '../types/live-responses';\n\n/**\n * Class for Live generative model APIs. The Live API enables low-latency, two-way multimodal\n * interactions with Gemini.\n *\n * This class should only be instantiated with {@link getLiveGenerativeModel}.\n *\n * @beta\n */\nexport class LiveGenerativeModel extends AIModel {\n  generationConfig: LiveGenerationConfig;\n  tools?: Tool[];\n  toolConfig?: ToolConfig;\n  systemInstruction?: Content;\n\n  /**\n   * @internal\n   */\n  constructor(\n    ai: AI,\n    modelParams: LiveModelParams,\n    /**\n     * @internal\n     */\n    private _webSocketHandler: WebSocketHandler\n  ) {\n    super(ai, modelParams.model);\n    this.generationConfig = modelParams.generationConfig || {};\n    this.tools = modelParams.tools;\n    this.toolConfig = modelParams.toolConfig;\n    this.systemInstruction = formatSystemInstruction(\n      modelParams.systemInstruction\n    );\n  }\n\n  /**\n   * Starts a {@link LiveSession}.\n   *\n   * @returns A {@link LiveSession}.\n   * @throws If the connection failed to be established with the server.\n   *\n   * @beta\n   */\n  async connect(): Promise<LiveSession> {\n    const url = new WebSocketUrl(this._apiSettings);\n    await this._webSocketHandler.connect(url.toString());\n\n    let fullModelPath: string;\n    if (this._apiSettings.backend.backendType === BackendType.GOOGLE_AI) {\n      fullModelPath = `projects/${this._apiSettings.project}/${this.model}`;\n    } else {\n      fullModelPath = `projects/${this._apiSettings.project}/locations/${this._apiSettings.location}/${this.model}`;\n    }\n\n    // inputAudioTranscription and outputAudioTranscription are on the generation config in the public API,\n    // but the backend expects them to be in the `setup` message.\n    const {\n      inputAudioTranscription,\n      outputAudioTranscription,\n      ...generationConfig\n    } = this.generationConfig;\n\n    const setupMessage: _LiveClientSetup = {\n      setup: {\n        model: fullModelPath,\n        generationConfig,\n        tools: this.tools,\n        toolConfig: this.toolConfig,\n        systemInstruction: this.systemInstruction,\n        inputAudioTranscription,\n        outputAudioTranscription\n      }\n    };\n\n    try {\n      // Begin listening for server messages, and begin the handshake by sending the 'setupMessage'\n      const serverMessages = this._webSocketHandler.listen();\n      this._webSocketHandler.send(JSON.stringify(setupMessage));\n\n      // Verify we received the handshake response 'setupComplete'\n      const firstMessage = (await serverMessages.next()).value;\n      if (\n        !firstMessage ||\n        !(typeof firstMessage === 'object') ||\n        !('setupComplete' in firstMessage)\n      ) {\n        await this._webSocketHandler.close(1011, 'Handshake failure');\n        throw new AIError(\n          AIErrorCode.RESPONSE_ERROR,\n          'Server connection handshake failed. The server did not respond with a setupComplete message.'\n        );\n      }\n\n      return new LiveSession(this._webSocketHandler, serverMessages);\n    } catch (e) {\n      // Ensure connection is closed on any setup error\n      await this._webSocketHandler.close();\n      throw e;\n    }\n  }\n}\n", "/**\n * @license\n * Copyright 2025 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { AI } from '../public-types';\nimport { makeRequest, Task } from '../requests/request';\nimport { createPredictRequestBody } from '../requests/request-helpers';\nimport { handlePredictResponse } from '../requests/response-helpers';\nimport {\n  ImagenGCSImage,\n  ImagenGenerationConfig,\n  ImagenInlineImage,\n  RequestOptions,\n  ImagenModelParams,\n  ImagenGenerationResponse,\n  ImagenSafetySettings\n} from '../types';\nimport { AIModel } from './ai-model';\n\n/**\n * Class for Imagen model APIs.\n *\n * This class provides methods for generating images using the Imagen model.\n *\n * @example\n * ```javascript\n * const imagen = new ImagenModel(\n *   ai,\n *   {\n *     model: 'imagen-3.0-generate-002'\n *   }\n * );\n *\n * const response = await imagen.generateImages('A photo of a cat');\n * if (response.images.length > 0) {\n *   console.log(response.images[0].bytesBase64Encoded);\n * }\n * ```\n *\n * @public\n */\nexport class ImagenModel extends AIModel {\n  /**\n   * The Imagen generation configuration.\n   */\n  generationConfig?: ImagenGenerationConfig;\n  /**\n   * Safety settings for filtering inappropriate content.\n   */\n  safetySettings?: ImagenSafetySettings;\n\n  /**\n   * Constructs a new instance of the {@link ImagenModel} class.\n   *\n   * @param ai - an {@link AI} instance.\n   * @param modelParams - Parameters to use when making requests to Imagen.\n   * @param requestOptions - Additional options to use when making requests.\n   *\n   * @throws If the `apiKey` or `projectId` fields are missing in your\n   * Firebase config.\n   */\n  constructor(\n    ai: AI,\n    modelParams: ImagenModelParams,\n    public requestOptions?: RequestOptions\n  ) {\n    const { model, generationConfig, safetySettings } = modelParams;\n    super(ai, model);\n    this.generationConfig = generationConfig;\n    this.safetySettings = safetySettings;\n  }\n\n  /**\n   * Generates images using the Imagen model and returns them as\n   * base64-encoded strings.\n   *\n   * @param prompt - A text prompt describing the image(s) to generate.\n   * @returns A promise that resolves to an {@link ImagenGenerationResponse}\n   * object containing the generated images.\n   *\n   * @throws If the request to generate images fails. This happens if the\n   * prompt is blocked.\n   *\n   * @remarks\n   * If the prompt was not blocked, but one or more of the generated images were filtered, the\n   * returned object will have a `filteredReason` property.\n   * If all images are filtered, the `images` array will be empty.\n   *\n   * @public\n   */\n  async generateImages(\n    prompt: string\n  ): Promise<ImagenGenerationResponse<ImagenInlineImage>> {\n    const body = createPredictRequestBody(prompt, {\n      ...this.generationConfig,\n      ...this.safetySettings\n    });\n    const response = await makeRequest(\n      {\n        task: Task.PREDICT,\n        model: this.model,\n        apiSettings: this._apiSettings,\n        stream: false,\n        requestOptions: this.requestOptions\n      },\n      JSON.stringify(body)\n    );\n    return handlePredictResponse<ImagenInlineImage>(response);\n  }\n\n  /**\n   * Generates images to Cloud Storage for Firebase using the Imagen model.\n   *\n   * @internal This method is temporarily internal.\n   *\n   * @param prompt - A text prompt describing the image(s) to generate.\n   * @param gcsURI - The URI of file stored in a Cloud Storage for Firebase bucket.\n   * This should be a directory. For example, `gs://my-bucket/my-directory/`.\n   * @returns A promise that resolves to an {@link ImagenGenerationResponse}\n   * object containing the URLs of the generated images.\n   *\n   * @throws If the request fails to generate images fails. This happens if\n   * the prompt is blocked.\n   *\n   * @remarks\n   * If the prompt was not blocked, but one or more of the generated images were filtered, the\n   * returned object will have a `filteredReason` property.\n   * If all images are filtered, the `images` array will be empty.\n   */\n  async generateImagesGCS(\n    prompt: string,\n    gcsURI: string\n  ): Promise<ImagenGenerationResponse<ImagenGCSImage>> {\n    const body = createPredictRequestBody(prompt, {\n      gcsURI,\n      ...this.generationConfig,\n      ...this.safetySettings\n    });\n    const response = await makeRequest(\n      {\n        task: Task.PREDICT,\n        model: this.model,\n        apiSettings: this._apiSettings,\n        stream: false,\n        requestOptions: this.requestOptions\n      },\n      JSON.stringify(body)\n    );\n    return handlePredictResponse<ImagenGCSImage>(response);\n  }\n}\n", "/**\n * @license\n * Copyright 2025 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { AIError } from './errors';\nimport { logger } from './logger';\nimport { AIErrorCode } from './types';\n\n/**\n * A standardized interface for interacting with a WebSocket connection.\n * This abstraction allows the SDK to use the appropriate WebSocket implementation\n * for the current JS environment (Browser vs. Node) without\n * changing the core logic of the `LiveSession`.\n * @internal\n */\n\nexport interface WebSocketHandler {\n  /**\n   * Establishes a connection to the given URL.\n   *\n   * @param url The WebSocket URL (e.g., wss://...).\n   * @returns A promise that resolves on successful connection or rejects on failure.\n   */\n  connect(url: string): Promise<void>;\n\n  /**\n   * Sends data over the WebSocket.\n   *\n   * @param data The string or binary data to send.\n   */\n  send(data: string | ArrayBuffer): void;\n\n  /**\n   * Returns an async generator that yields parsed JSON objects from the server.\n   * The yielded type is `unknown` because the handler cannot guarantee the shape of the data.\n   * The consumer is responsible for type validation.\n   * The generator terminates when the connection is closed.\n   *\n   * @returns A generator that allows consumers to pull messages using a `for await...of` loop.\n   */\n  listen(): AsyncGenerator<unknown>;\n\n  /**\n   * Closes the WebSocket connection.\n   *\n   * @param code - A numeric status code explaining why the connection is closing.\n   * @param reason - A human-readable string explaining why the connection is closing.\n   */\n  close(code?: number, reason?: string): Promise<void>;\n}\n\n/**\n * A wrapper for the native `WebSocket` available in both Browsers and Node >= 22.\n *\n * @internal\n */\nexport class WebSocketHandlerImpl implements WebSocketHandler {\n  private ws?: WebSocket;\n\n  constructor() {\n    if (typeof WebSocket === 'undefined') {\n      throw new AIError(\n        AIErrorCode.UNSUPPORTED,\n        'The WebSocket API is not available in this environment. ' +\n          'The \"Live\" feature is not supported here. It is supported in ' +\n          'modern browser windows, Web Workers with WebSocket support, and Node >= 22.'\n      );\n    }\n  }\n\n  connect(url: string): Promise<void> {\n    return new Promise((resolve, reject) => {\n      this.ws = new WebSocket(url);\n      this.ws.binaryType = 'blob'; // Only important to set in Node\n      this.ws.addEventListener('open', () => resolve(), { once: true });\n      this.ws.addEventListener(\n        'error',\n        () =>\n          reject(\n            new AIError(\n              AIErrorCode.FETCH_ERROR,\n              `Error event raised on WebSocket`\n            )\n          ),\n        { once: true }\n      );\n      this.ws!.addEventListener('close', (closeEvent: CloseEvent) => {\n        if (closeEvent.reason) {\n          logger.warn(\n            `WebSocket connection closed by server. Reason: '${closeEvent.reason}'`\n          );\n        }\n      });\n    });\n  }\n\n  send(data: string | ArrayBuffer): void {\n    if (!this.ws || this.ws.readyState !== WebSocket.OPEN) {\n      throw new AIError(AIErrorCode.REQUEST_ERROR, 'WebSocket is not open.');\n    }\n    this.ws.send(data);\n  }\n\n  async *listen(): AsyncGenerator<unknown> {\n    if (!this.ws) {\n      throw new AIError(\n        AIErrorCode.REQUEST_ERROR,\n        'WebSocket is not connected.'\n      );\n    }\n\n    const messageQueue: unknown[] = [];\n    const errorQueue: Error[] = [];\n    let resolvePromise: (() => void) | null = null;\n    let isClosed = false;\n\n    const messageListener = async (event: MessageEvent): Promise<void> => {\n      let data: string;\n      if (event.data instanceof Blob) {\n        data = await event.data.text();\n      } else if (typeof event.data === 'string') {\n        data = event.data;\n      } else {\n        errorQueue.push(\n          new AIError(\n            AIErrorCode.PARSE_FAILED,\n            `Failed to parse WebSocket response. Expected data to be a Blob or string, but was ${typeof event.data}.`\n          )\n        );\n        if (resolvePromise) {\n          resolvePromise();\n          resolvePromise = null;\n        }\n        return;\n      }\n\n      try {\n        const obj = JSON.parse(data) as unknown;\n        messageQueue.push(obj);\n      } catch (e) {\n        const err = e as Error;\n        errorQueue.push(\n          new AIError(\n            AIErrorCode.PARSE_FAILED,\n            `Error parsing WebSocket message to JSON: ${err.message}`\n          )\n        );\n      }\n\n      if (resolvePromise) {\n        resolvePromise();\n        resolvePromise = null;\n      }\n    };\n\n    const errorListener = (): void => {\n      errorQueue.push(\n        new AIError(AIErrorCode.FETCH_ERROR, 'WebSocket connection error.')\n      );\n      if (resolvePromise) {\n        resolvePromise();\n        resolvePromise = null;\n      }\n    };\n\n    const closeListener = (event: CloseEvent): void => {\n      if (event.reason) {\n        logger.warn(\n          `WebSocket connection closed by the server with reason: ${event.reason}`\n        );\n      }\n      isClosed = true;\n      if (resolvePromise) {\n        resolvePromise();\n        resolvePromise = null;\n      }\n      // Clean up listeners to prevent memory leaks\n      this.ws?.removeEventListener('message', messageListener);\n      this.ws?.removeEventListener('close', closeListener);\n      this.ws?.removeEventListener('error', errorListener);\n    };\n\n    this.ws.addEventListener('message', messageListener);\n    this.ws.addEventListener('close', closeListener);\n    this.ws.addEventListener('error', errorListener);\n\n    while (!isClosed) {\n      if (errorQueue.length > 0) {\n        const error = errorQueue.shift()!;\n        throw error;\n      }\n      if (messageQueue.length > 0) {\n        yield messageQueue.shift()!;\n      } else {\n        await new Promise<void>(resolve => {\n          resolvePromise = resolve;\n        });\n      }\n    }\n\n    // If the loop terminated because isClosed is true, check for any final errors\n    if (errorQueue.length > 0) {\n      const error = errorQueue.shift()!;\n      throw error;\n    }\n  }\n\n  close(code?: number, reason?: string): Promise<void> {\n    return new Promise(resolve => {\n      if (!this.ws) {\n        return resolve();\n      }\n\n      this.ws.addEventListener('close', () => resolve(), { once: true });\n      // Calling 'close' during these states results in an error.\n      if (\n        this.ws.readyState === WebSocket.CLOSED ||\n        this.ws.readyState === WebSocket.CONNECTING\n      ) {\n        return resolve();\n      }\n\n      if (this.ws.readyState !== WebSocket.CLOSING) {\n        this.ws.close(code, reason);\n      }\n    });\n  }\n}\n", "/**\n * @license\n * Copyright 2025 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport {\n  templateGenerateContent,\n  templateGenerateContentStream\n} from '../methods/generate-content';\nimport { GenerateContentResult, RequestOptions } from '../types';\nimport { AI, GenerateContentStreamResult } from '../public-types';\nimport { ApiSettings } from '../types/internal';\nimport { initApiSettings } from './utils';\n\n/**\n * {@link GenerativeModel} APIs that execute on a server-side template.\n *\n * This class should only be instantiated with {@link getTemplateGenerativeModel}.\n *\n * @beta\n */\nexport class TemplateGenerativeModel {\n  /**\n   * @internal\n   */\n  _apiSettings: ApiSettings;\n\n  /**\n   * Additional options to use when making requests.\n   */\n  requestOptions?: RequestOptions;\n\n  /**\n   * @hideconstructor\n   */\n  constructor(ai: AI, requestOptions?: RequestOptions) {\n    this.requestOptions = requestOptions || {};\n    this._apiSettings = initApiSettings(ai);\n  }\n\n  /**\n   * Makes a single non-streaming call to the model and returns an object\n   * containing a single {@link GenerateContentResponse}.\n   *\n   * @param templateId - The ID of the server-side template to execute.\n   * @param templateVariables - A key-value map of variables to populate the\n   * template with.\n   *\n   * @beta\n   */\n  async generateContent(\n    templateId: string,\n    templateVariables: object // anything!\n  ): Promise<GenerateContentResult> {\n    return templateGenerateContent(\n      this._apiSettings,\n      templateId,\n      { inputs: templateVariables },\n      this.requestOptions\n    );\n  }\n\n  /**\n   * Makes a single streaming call to the model and returns an object\n   * containing an iterable stream that iterates over all chunks in the\n   * streaming response as well as a promise that returns the final aggregated\n   * response.\n   *\n   * @param templateId - The ID of the server-side template to execute.\n   * @param templateVariables - A key-value map of variables to populate the\n   * template with.\n   *\n   * @beta\n   */\n  async generateContentStream(\n    templateId: string,\n    templateVariables: object\n  ): Promise<GenerateContentStreamResult> {\n    return templateGenerateContentStream(\n      this._apiSettings,\n      templateId,\n      { inputs: templateVariables },\n      this.requestOptions\n    );\n  }\n}\n", "/**\n * @license\n * Copyright 2025 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { RequestOptions } from '../types';\nimport {\n  AI,\n  ImagenGenerationResponse,\n  ImagenInlineImage\n} from '../public-types';\nimport { ApiSettings } from '../types/internal';\nimport { makeRequest, ServerPromptTemplateTask } from '../requests/request';\nimport { handlePredictResponse } from '../requests/response-helpers';\nimport { initApiSettings } from './utils';\n\n/**\n * Class for Imagen model APIs that execute on a server-side template.\n *\n * This class should only be instantiated with {@link getTemplateImagenModel}.\n *\n * @beta\n */\nexport class TemplateImagenModel {\n  /**\n   * @internal\n   */\n  _apiSettings: ApiSettings;\n\n  /**\n   * Additional options to use when making requests.\n   */\n  requestOptions?: RequestOptions;\n\n  /**\n   * @hideconstructor\n   */\n  constructor(ai: AI, requestOptions?: RequestOptions) {\n    this.requestOptions = requestOptions || {};\n    this._apiSettings = initApiSettings(ai);\n  }\n\n  /**\n   * Makes a single call to the model and returns an object containing a single\n   * {@link ImagenGenerationResponse}.\n   *\n   * @param templateId - The ID of the server-side template to execute.\n   * @param templateVariables - A key-value map of variables to populate the\n   * template with.\n   *\n   * @beta\n   */\n  async generateImages(\n    templateId: string,\n    templateVariables: object\n  ): Promise<ImagenGenerationResponse<ImagenInlineImage>> {\n    const response = await makeRequest(\n      {\n        task: ServerPromptTemplateTask.TEMPLATE_PREDICT,\n        templateId,\n        apiSettings: this._apiSettings,\n        stream: false,\n        requestOptions: this.requestOptions\n      },\n      JSON.stringify({ inputs: templateVariables })\n    );\n    return handlePredictResponse<ImagenInlineImage>(response);\n  }\n}\n", "/**\n * @license\n * Copyright 2024 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { AIError } from '../errors';\nimport { AIErrorCode } from '../types';\nimport {\n  SchemaInterface,\n  SchemaType,\n  SchemaParams,\n  SchemaRequest\n} from '../types/schema';\n\n/**\n * Parent class encompassing all Schema types, with static methods that\n * allow building specific Schema types. This class can be converted with\n * `JSON.stringify()` into a JSON string accepted by Vertex AI REST endpoints.\n * (This string conversion is automatically done when calling SDK methods.)\n * @public\n */\nexport abstract class Schema implements SchemaInterface {\n  /**\n   * Optional. The type of the property.\n   * This can only be undefined when using `anyOf` schemas, which do not have an\n   * explicit type in the {@link https://swagger.io/docs/specification/v3_0/data-models/data-types/#any-type | OpenAPI specification}.\n   */\n  type?: SchemaType;\n  /** Optional. The format of the property.\n   * Supported formats:<br/>\n   * <ul>\n   *  <li>for NUMBER type: \"float\", \"double\"</li>\n   *  <li>for INTEGER type: \"int32\", \"int64\"</li>\n   *  <li>for STRING type: \"email\", \"byte\", etc</li>\n   * </ul>\n   */\n  format?: string;\n  /** Optional. The description of the property. */\n  description?: string;\n  /** Optional. The items of the property. */\n  items?: SchemaInterface;\n  /** The minimum number of items (elements) in a schema of {@link (SchemaType:type)} `array`. */\n  minItems?: number;\n  /** The maximum number of items (elements) in a schema of {@link (SchemaType:type)} `array`. */\n  maxItems?: number;\n  /** Optional. Whether the property is nullable. Defaults to false. */\n  nullable: boolean;\n  /** Optional. The example of the property. */\n  example?: unknown;\n  /**\n   * Allows user to add other schema properties that have not yet\n   * been officially added to the SDK.\n   */\n  [key: string]: unknown;\n\n  constructor(schemaParams: SchemaInterface) {\n    // TODO(dlarocque): Enforce this with union types\n    if (!schemaParams.type && !schemaParams.anyOf) {\n      throw new AIError(\n        AIErrorCode.INVALID_SCHEMA,\n        \"A schema must have either a 'type' or an 'anyOf' array of sub-schemas.\"\n      );\n    }\n    // eslint-disable-next-line guard-for-in\n    for (const paramKey in schemaParams) {\n      this[paramKey] = schemaParams[paramKey];\n    }\n    // Ensure these are explicitly set to avoid TS errors.\n    this.type = schemaParams.type;\n    this.format = schemaParams.hasOwnProperty('format')\n      ? schemaParams.format\n      : undefined;\n    this.nullable = schemaParams.hasOwnProperty('nullable')\n      ? !!schemaParams.nullable\n      : false;\n  }\n\n  /**\n   * Defines how this Schema should be serialized as JSON.\n   * See https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/JSON/stringify#tojson_behavior\n   * @internal\n   */\n  toJSON(): SchemaRequest {\n    const obj: { type?: SchemaType; [key: string]: unknown } = {\n      type: this.type\n    };\n    for (const prop in this) {\n      if (this.hasOwnProperty(prop) && this[prop] !== undefined) {\n        if (prop !== 'required' || this.type === SchemaType.OBJECT) {\n          obj[prop] = this[prop];\n        }\n      }\n    }\n    return obj as SchemaRequest;\n  }\n\n  static array(arrayParams: SchemaParams & { items: Schema }): ArraySchema {\n    return new ArraySchema(arrayParams, arrayParams.items);\n  }\n\n  static object(\n    objectParams: SchemaParams & {\n      properties: {\n        [k: string]: Schema;\n      };\n      optionalProperties?: string[];\n    }\n  ): ObjectSchema {\n    return new ObjectSchema(\n      objectParams,\n      objectParams.properties,\n      objectParams.optionalProperties\n    );\n  }\n\n  // eslint-disable-next-line id-blacklist\n  static string(stringParams?: SchemaParams): StringSchema {\n    return new StringSchema(stringParams);\n  }\n\n  static enumString(\n    stringParams: SchemaParams & { enum: string[] }\n  ): StringSchema {\n    return new StringSchema(stringParams, stringParams.enum);\n  }\n\n  static integer(integerParams?: SchemaParams): IntegerSchema {\n    return new IntegerSchema(integerParams);\n  }\n\n  // eslint-disable-next-line id-blacklist\n  static number(numberParams?: SchemaParams): NumberSchema {\n    return new NumberSchema(numberParams);\n  }\n\n  // eslint-disable-next-line id-blacklist\n  static boolean(booleanParams?: SchemaParams): BooleanSchema {\n    return new BooleanSchema(booleanParams);\n  }\n\n  static anyOf(\n    anyOfParams: SchemaParams & { anyOf: TypedSchema[] }\n  ): AnyOfSchema {\n    return new AnyOfSchema(anyOfParams);\n  }\n}\n\n/**\n * A type that includes all specific Schema types.\n * @public\n */\nexport type TypedSchema =\n  | IntegerSchema\n  | NumberSchema\n  | StringSchema\n  | BooleanSchema\n  | ObjectSchema\n  | ArraySchema\n  | AnyOfSchema;\n\n/**\n * Schema class for \"integer\" types.\n * @public\n */\nexport class IntegerSchema extends Schema {\n  constructor(schemaParams?: SchemaParams) {\n    super({\n      type: SchemaType.INTEGER,\n      ...schemaParams\n    });\n  }\n}\n\n/**\n * Schema class for \"number\" types.\n * @public\n */\nexport class NumberSchema extends Schema {\n  constructor(schemaParams?: SchemaParams) {\n    super({\n      type: SchemaType.NUMBER,\n      ...schemaParams\n    });\n  }\n}\n\n/**\n * Schema class for \"boolean\" types.\n * @public\n */\nexport class BooleanSchema extends Schema {\n  constructor(schemaParams?: SchemaParams) {\n    super({\n      type: SchemaType.BOOLEAN,\n      ...schemaParams\n    });\n  }\n}\n\n/**\n * Schema class for \"string\" types. Can be used with or without\n * enum values.\n * @public\n */\nexport class StringSchema extends Schema {\n  enum?: string[];\n  constructor(schemaParams?: SchemaParams, enumValues?: string[]) {\n    super({\n      type: SchemaType.STRING,\n      ...schemaParams\n    });\n    this.enum = enumValues;\n  }\n\n  /**\n   * @internal\n   */\n  toJSON(): SchemaRequest {\n    const obj = super.toJSON();\n    if (this.enum) {\n      obj['enum'] = this.enum;\n    }\n    return obj as SchemaRequest;\n  }\n}\n\n/**\n * Schema class for \"array\" types.\n * The `items` param should refer to the type of item that can be a member\n * of the array.\n * @public\n */\nexport class ArraySchema extends Schema {\n  constructor(schemaParams: SchemaParams, public items: TypedSchema) {\n    super({\n      type: SchemaType.ARRAY,\n      ...schemaParams\n    });\n  }\n\n  /**\n   * @internal\n   */\n  toJSON(): SchemaRequest {\n    const obj = super.toJSON();\n    obj.items = this.items.toJSON();\n    return obj;\n  }\n}\n\n/**\n * Schema class for \"object\" types.\n * The `properties` param must be a map of `Schema` objects.\n * @public\n */\nexport class ObjectSchema extends Schema {\n  constructor(\n    schemaParams: SchemaParams,\n    public properties: {\n      [k: string]: TypedSchema;\n    },\n    public optionalProperties: string[] = []\n  ) {\n    super({\n      type: SchemaType.OBJECT,\n      ...schemaParams\n    });\n  }\n\n  /**\n   * @internal\n   */\n  toJSON(): SchemaRequest {\n    const obj = super.toJSON();\n    obj.properties = { ...this.properties };\n    const required = [];\n    if (this.optionalProperties) {\n      for (const propertyKey of this.optionalProperties) {\n        if (!this.properties.hasOwnProperty(propertyKey)) {\n          throw new AIError(\n            AIErrorCode.INVALID_SCHEMA,\n            `Property \"${propertyKey}\" specified in \"optionalProperties\" does not exist.`\n          );\n        }\n      }\n    }\n    for (const propertyKey in this.properties) {\n      if (this.properties.hasOwnProperty(propertyKey)) {\n        obj.properties[propertyKey] = this.properties[\n          propertyKey\n        ].toJSON() as SchemaRequest;\n        if (!this.optionalProperties.includes(propertyKey)) {\n          required.push(propertyKey);\n        }\n      }\n    }\n    if (required.length > 0) {\n      obj.required = required;\n    }\n    delete obj.optionalProperties;\n    return obj as SchemaRequest;\n  }\n}\n\n/**\n * Schema class representing a value that can conform to any of the provided sub-schemas. This is\n * useful when a field can accept multiple distinct types or structures.\n * @public\n */\nexport class AnyOfSchema extends Schema {\n  anyOf: TypedSchema[]; // Re-define field to narrow to required type\n  constructor(schemaParams: SchemaParams & { anyOf: TypedSchema[] }) {\n    if (schemaParams.anyOf.length === 0) {\n      throw new AIError(\n        AIErrorCode.INVALID_SCHEMA,\n        \"The 'anyOf' array must not be empty.\"\n      );\n    }\n    super({\n      ...schemaParams,\n      type: undefined // anyOf schemas do not have an explicit type\n    });\n    this.anyOf = schemaParams.anyOf;\n  }\n\n  /**\n   * @internal\n   */\n  toJSON(): SchemaRequest {\n    const obj = super.toJSON();\n    // Ensure the 'anyOf' property contains serialized SchemaRequest objects.\n    if (this.anyOf && Array.isArray(this.anyOf)) {\n      obj.anyOf = (this.anyOf as TypedSchema[]).map(s => s.toJSON());\n    }\n    return obj;\n  }\n}\n", "/**\n * @license\n * Copyright 2025 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { logger } from '../logger';\n\n/**\n * Defines the image format for images generated by Imagen.\n *\n * Use this class to specify the desired format (JPEG or PNG) and compression quality\n * for images generated by Imagen. This is typically included as part of\n * {@link ImagenModelParams}.\n *\n * @example\n * ```javascript\n * const imagenModelParams = {\n *   // ... other ImagenModelParams\n *   imageFormat: ImagenImageFormat.jpeg(75) // JPEG with a compression level of 75.\n * }\n * ```\n *\n * @public\n */\nexport class ImagenImageFormat {\n  /**\n   * The MIME type.\n   */\n  mimeType: string;\n  /**\n   * The level of compression (a number between 0 and 100).\n   */\n  compressionQuality?: number;\n\n  private constructor() {\n    this.mimeType = 'image/png';\n  }\n\n  /**\n   * Creates an {@link ImagenImageFormat} for a JPEG image.\n   *\n   * @param compressionQuality - The level of compression (a number between 0 and 100).\n   * @returns An {@link ImagenImageFormat} object for a JPEG image.\n   *\n   * @public\n   */\n  static jpeg(compressionQuality?: number): ImagenImageFormat {\n    if (\n      compressionQuality &&\n      (compressionQuality < 0 || compressionQuality > 100)\n    ) {\n      logger.warn(\n        `Invalid JPEG compression quality of ${compressionQuality} specified; the supported range is [0, 100].`\n      );\n    }\n    return { mimeType: 'image/jpeg', compressionQuality };\n  }\n\n  /**\n   * Creates an {@link ImagenImageFormat} for a PNG image.\n   *\n   * @returns An {@link ImagenImageFormat} object for a PNG image.\n   *\n   * @public\n   */\n  static png(): ImagenImageFormat {\n    return { mimeType: 'image/png' };\n  }\n}\n", "/**\n * @license\n * Copyright 2025 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { AIError } from '../errors';\nimport { logger } from '../logger';\nimport {\n  AIErrorCode,\n  FunctionCall,\n  FunctionResponse,\n  GenerativeContentBlob,\n  LiveServerContent\n} from '../types';\nimport { LiveSession } from './live-session';\nimport { Deferred } from '@firebase/util';\n\nconst SERVER_INPUT_SAMPLE_RATE = 16_000;\nconst SERVER_OUTPUT_SAMPLE_RATE = 24_000;\n\nconst AUDIO_PROCESSOR_NAME = 'audio-processor';\n\n/**\n * The JS for an `AudioWorkletProcessor`.\n * This processor is responsible for taking raw audio from the microphone,\n * converting it to the required 16-bit 16kHz PCM, and posting it back to the main thread.\n *\n * See: https://developer.mozilla.org/en-US/docs/Web/API/AudioWorkletProcessor\n *\n * It is defined as a string here so that it can be converted into a `Blob`\n * and loaded at runtime.\n */\nconst audioProcessorWorkletString = `\n  class AudioProcessor extends AudioWorkletProcessor {\n    constructor(options) {\n      super();\n      this.targetSampleRate = options.processorOptions.targetSampleRate;\n      // 'sampleRate' is a global variable available inside the AudioWorkletGlobalScope,\n      // representing the native sample rate of the AudioContext.\n      this.inputSampleRate = sampleRate;\n    }\n\n    /**\n     * This method is called by the browser's audio engine for each block of audio data.\n     * Input is a single input, with a single channel (input[0][0]).\n     */\n    process(inputs) {\n      const input = inputs[0];\n      if (input && input.length > 0 && input[0].length > 0) {\n        const pcmData = input[0]; // Float32Array of raw audio samples.\n        \n        // Simple linear interpolation for resampling.\n        const resampled = new Float32Array(Math.round(pcmData.length * this.targetSampleRate / this.inputSampleRate));\n        const ratio = pcmData.length / resampled.length;\n        for (let i = 0; i < resampled.length; i++) {\n          resampled[i] = pcmData[Math.floor(i * ratio)];\n        }\n\n        // Convert Float32 (-1, 1) samples to Int16 (-32768, 32767)\n        const resampledInt16 = new Int16Array(resampled.length);\n        for (let i = 0; i < resampled.length; i++) {\n          const sample = Math.max(-1, Math.min(1, resampled[i]));\n          if (sample < 0) {\n            resampledInt16[i] = sample * 32768;\n          } else {\n            resampledInt16[i] = sample * 32767;\n          }\n        }\n        \n        this.port.postMessage(resampledInt16);\n      }\n      // Return true to keep the processor alive and processing the next audio block.\n      return true;\n    }\n  }\n\n  // Register the processor with a name that can be used to instantiate it from the main thread.\n  registerProcessor('${AUDIO_PROCESSOR_NAME}', AudioProcessor);\n`;\n\n/**\n * A controller for managing an active audio conversation.\n *\n * @beta\n */\nexport interface AudioConversationController {\n  /**\n   * Stops the audio conversation, closes the microphone connection, and\n   * cleans up resources. Returns a promise that resolves when cleanup is complete.\n   */\n  stop: () => Promise<void>;\n}\n\n/**\n * Options for {@link startAudioConversation}.\n *\n * @beta\n */\nexport interface StartAudioConversationOptions {\n  /**\n   * An async handler that is called when the model requests a function to be executed.\n   * The handler should perform the function call and return the result as a `Part`,\n   * which will then be sent back to the model.\n   */\n  functionCallingHandler?: (\n    functionCalls: FunctionCall[]\n  ) => Promise<FunctionResponse>;\n}\n\n/**\n * Dependencies needed by the {@link AudioConversationRunner}.\n *\n * @internal\n */\ninterface RunnerDependencies {\n  audioContext: AudioContext;\n  mediaStream: MediaStream;\n  sourceNode: MediaStreamAudioSourceNode;\n  workletNode: AudioWorkletNode;\n}\n\n/**\n * Encapsulates the core logic of an audio conversation.\n *\n * @internal\n */\nexport class AudioConversationRunner {\n  /** A flag to indicate if the conversation has been stopped. */\n  private isStopped = false;\n  /** A deferred that contains a promise that is resolved when stop() is called, to unblock the receive loop. */\n  private readonly stopDeferred = new Deferred<void>();\n  /** A promise that tracks the lifecycle of the main `runReceiveLoop`. */\n  private readonly receiveLoopPromise: Promise<void>;\n\n  /** A FIFO queue of 24kHz, 16-bit PCM audio chunks received from the server. */\n  private readonly playbackQueue: ArrayBuffer[] = [];\n  /** Tracks scheduled audio sources. Used to cancel scheduled audio when the model is interrupted. */\n  private scheduledSources: AudioBufferSourceNode[] = [];\n  /** A high-precision timeline pointer for scheduling gapless audio playback. */\n  private nextStartTime = 0;\n  /** A mutex to prevent the playback processing loop from running multiple times concurrently. */\n  private isPlaybackLoopRunning = false;\n\n  constructor(\n    private readonly liveSession: LiveSession,\n    private readonly options: StartAudioConversationOptions,\n    private readonly deps: RunnerDependencies\n  ) {\n    this.liveSession.inConversation = true;\n\n    // Start listening for messages from the server.\n    this.receiveLoopPromise = this.runReceiveLoop().finally(() =>\n      this.cleanup()\n    );\n\n    // Set up the handler for receiving processed audio data from the worklet.\n    // Message data has been resampled to 16kHz 16-bit PCM.\n    this.deps.workletNode.port.onmessage = event => {\n      if (this.isStopped) {\n        return;\n      }\n\n      const pcm16 = event.data as Int16Array;\n      const base64 = btoa(\n        String.fromCharCode.apply(\n          null,\n          Array.from(new Uint8Array(pcm16.buffer))\n        )\n      );\n\n      const chunk: GenerativeContentBlob = {\n        mimeType: 'audio/pcm',\n        data: base64\n      };\n      void this.liveSession.sendAudioRealtime(chunk);\n    };\n  }\n\n  /**\n   * Stops the conversation and unblocks the main receive loop.\n   */\n  async stop(): Promise<void> {\n    if (this.isStopped) {\n      return;\n    }\n    this.isStopped = true;\n    this.stopDeferred.resolve(); // Unblock the receive loop\n    await this.receiveLoopPromise; // Wait for the loop and cleanup to finish\n  }\n\n  /**\n   * Cleans up all audio resources (nodes, stream tracks, context) and marks the\n   * session as no longer in a conversation.\n   */\n  private cleanup(): void {\n    this.interruptPlayback(); // Ensure all audio is stopped on final cleanup.\n    this.deps.workletNode.port.onmessage = null;\n    this.deps.workletNode.disconnect();\n    this.deps.sourceNode.disconnect();\n    this.deps.mediaStream.getTracks().forEach(track => track.stop());\n    if (this.deps.audioContext.state !== 'closed') {\n      void this.deps.audioContext.close();\n    }\n    this.liveSession.inConversation = false;\n  }\n\n  /**\n   * Adds audio data to the queue and ensures the playback loop is running.\n   */\n  private enqueueAndPlay(audioData: ArrayBuffer): void {\n    this.playbackQueue.push(audioData);\n    // Will no-op if it's already running.\n    void this.processPlaybackQueue();\n  }\n\n  /**\n   * Stops all current and pending audio playback and clears the queue. This is\n   * called when the server indicates the model's speech was interrupted with\n   * `LiveServerContent.modelTurn.interrupted`.\n   */\n  private interruptPlayback(): void {\n    // Stop all sources that have been scheduled. The onended event will fire for each,\n    // which will clean up the scheduledSources array.\n    [...this.scheduledSources].forEach(source => source.stop(0));\n\n    // Clear the internal buffer of unprocessed audio chunks.\n    this.playbackQueue.length = 0;\n\n    // Reset the playback clock to start fresh.\n    this.nextStartTime = this.deps.audioContext.currentTime;\n  }\n\n  /**\n   * Processes the playback queue in a loop, scheduling each chunk in a gapless sequence.\n   */\n  private async processPlaybackQueue(): Promise<void> {\n    if (this.isPlaybackLoopRunning) {\n      return;\n    }\n    this.isPlaybackLoopRunning = true;\n\n    while (this.playbackQueue.length > 0 && !this.isStopped) {\n      const pcmRawBuffer = this.playbackQueue.shift()!;\n      try {\n        const pcm16 = new Int16Array(pcmRawBuffer);\n        const frameCount = pcm16.length;\n\n        const audioBuffer = this.deps.audioContext.createBuffer(\n          1,\n          frameCount,\n          SERVER_OUTPUT_SAMPLE_RATE\n        );\n\n        // Convert 16-bit PCM to 32-bit PCM, required by the Web Audio API.\n        const channelData = audioBuffer.getChannelData(0);\n        for (let i = 0; i < frameCount; i++) {\n          channelData[i] = pcm16[i] / 32768; // Normalize to Float32 range [-1.0, 1.0]\n        }\n\n        const source = this.deps.audioContext.createBufferSource();\n        source.buffer = audioBuffer;\n        source.connect(this.deps.audioContext.destination);\n\n        // Track the source and set up a handler to remove it from tracking when it finishes.\n        this.scheduledSources.push(source);\n        source.onended = () => {\n          this.scheduledSources = this.scheduledSources.filter(\n            s => s !== source\n          );\n        };\n\n        // To prevent gaps, schedule the next chunk to start either now (if we're catching up)\n        // or exactly when the previous chunk is scheduled to end.\n        this.nextStartTime = Math.max(\n          this.deps.audioContext.currentTime,\n          this.nextStartTime\n        );\n        source.start(this.nextStartTime);\n\n        // Update the schedule for the *next* chunk.\n        this.nextStartTime += audioBuffer.duration;\n      } catch (e) {\n        logger.error('Error playing audio:', e);\n      }\n    }\n\n    this.isPlaybackLoopRunning = false;\n  }\n\n  /**\n   * The main loop that listens for and processes messages from the server.\n   */\n  private async runReceiveLoop(): Promise<void> {\n    const messageGenerator = this.liveSession.receive();\n    while (!this.isStopped) {\n      const result = await Promise.race([\n        messageGenerator.next(),\n        this.stopDeferred.promise\n      ]);\n\n      if (this.isStopped || !result || result.done) {\n        break;\n      }\n\n      const message = result.value;\n      if (message.type === 'serverContent') {\n        const serverContent = message as LiveServerContent;\n        if (serverContent.interrupted) {\n          this.interruptPlayback();\n        }\n\n        const audioPart = serverContent.modelTurn?.parts.find(part =>\n          part.inlineData?.mimeType.startsWith('audio/')\n        );\n        if (audioPart?.inlineData) {\n          const audioData = Uint8Array.from(\n            atob(audioPart.inlineData.data),\n            c => c.charCodeAt(0)\n          ).buffer;\n          this.enqueueAndPlay(audioData);\n        }\n      } else if (message.type === 'toolCall') {\n        if (!this.options.functionCallingHandler) {\n          logger.warn(\n            'Received tool call message, but StartAudioConversationOptions.functionCallingHandler is undefined. Ignoring tool call.'\n          );\n        } else {\n          try {\n            const functionResponse = await this.options.functionCallingHandler(\n              message.functionCalls\n            );\n            if (!this.isStopped) {\n              void this.liveSession.sendFunctionResponses([functionResponse]);\n            }\n          } catch (e) {\n            throw new AIError(\n              AIErrorCode.ERROR,\n              `Function calling handler failed: ${(e as Error).message}`\n            );\n          }\n        }\n      }\n    }\n  }\n}\n\n/**\n * Starts a real-time, bidirectional audio conversation with the model. This helper function manages\n * the complexities of microphone access, audio recording, playback, and interruptions.\n *\n * @remarks Important: This function must be called in response to a user gesture\n * (for example, a button click) to comply with {@link https://developer.mozilla.org/en-US/docs/Web/API/Web_Audio_API/Best_practices#autoplay_policy | browser autoplay policies}.\n *\n * @example\n * ```javascript\n * const liveSession = await model.connect();\n * let conversationController;\n *\n * // This function must be called from within a click handler.\n * async function startConversation() {\n *   try {\n *     conversationController = await startAudioConversation(liveSession);\n *   } catch (e) {\n *     // Handle AI-specific errors\n *     if (e instanceof AIError) {\n *       console.error(\"AI Error:\", e.message);\n *     }\n *     // Handle microphone permission and hardware errors\n *     else if (e instanceof DOMException) {\n *       console.error(\"Microphone Error:\", e.message);\n *     }\n *     // Handle other unexpected errors\n *     else {\n *       console.error(\"An unexpected error occurred:\", e);\n *     }\n *   }\n * }\n *\n * // Later, to stop the conversation:\n * // if (conversationController) {\n * //   await conversationController.stop();\n * // }\n * ```\n *\n * @param liveSession - An active {@link LiveSession} instance.\n * @param options - Configuration options for the audio conversation.\n * @returns A `Promise` that resolves with an {@link AudioConversationController}.\n * @throws `AIError` if the environment does not support required Web APIs (`UNSUPPORTED`), if a conversation is already active (`REQUEST_ERROR`), the session is closed (`SESSION_CLOSED`), or if an unexpected initialization error occurs (`ERROR`).\n * @throws `DOMException` Thrown by `navigator.mediaDevices.getUserMedia()` if issues occur with microphone access, such as permissions being denied (`NotAllowedError`) or no compatible hardware being found (`NotFoundError`). See the {@link https://developer.mozilla.org/en-US/docs/Web/API/MediaDevices/getUserMedia#exceptions | MDN documentation} for a full list of exceptions.\n *\n * @beta\n */\nexport async function startAudioConversation(\n  liveSession: LiveSession,\n  options: StartAudioConversationOptions = {}\n): Promise<AudioConversationController> {\n  if (liveSession.isClosed) {\n    throw new AIError(\n      AIErrorCode.SESSION_CLOSED,\n      'Cannot start audio conversation on a closed LiveSession.'\n    );\n  }\n\n  if (liveSession.inConversation) {\n    throw new AIError(\n      AIErrorCode.REQUEST_ERROR,\n      'An audio conversation is already in progress for this session.'\n    );\n  }\n\n  // Check for necessary Web API support.\n  if (\n    typeof AudioWorkletNode === 'undefined' ||\n    typeof AudioContext === 'undefined' ||\n    typeof navigator === 'undefined' ||\n    !navigator.mediaDevices\n  ) {\n    throw new AIError(\n      AIErrorCode.UNSUPPORTED,\n      'Audio conversation is not supported in this environment. It requires the Web Audio API and AudioWorklet support.'\n    );\n  }\n\n  let audioContext: AudioContext | undefined;\n  try {\n    // 1. Set up the audio context. This must be in response to a user gesture.\n    // See: https://developer.mozilla.org/en-US/docs/Web/API/Web_Audio_API/Best_practices#autoplay_policy\n    audioContext = new AudioContext();\n    if (audioContext.state === 'suspended') {\n      await audioContext.resume();\n    }\n\n    // 2. Prompt for microphone access and get the media stream.\n    // This can throw a variety of permission or hardware-related errors.\n    const mediaStream = await navigator.mediaDevices.getUserMedia({\n      audio: true\n    });\n\n    // 3. Load the AudioWorklet processor.\n    // See: https://developer.mozilla.org/en-US/docs/Web/API/AudioWorklet\n    const workletBlob = new Blob([audioProcessorWorkletString], {\n      type: 'application/javascript'\n    });\n    const workletURL = URL.createObjectURL(workletBlob);\n    await audioContext.audioWorklet.addModule(workletURL);\n\n    // 4. Create the audio graph: Microphone -> Source Node -> Worklet Node\n    const sourceNode = audioContext.createMediaStreamSource(mediaStream);\n    const workletNode = new AudioWorkletNode(\n      audioContext,\n      AUDIO_PROCESSOR_NAME,\n      {\n        processorOptions: { targetSampleRate: SERVER_INPUT_SAMPLE_RATE }\n      }\n    );\n    sourceNode.connect(workletNode);\n\n    // 5. Instantiate and return the runner which manages the conversation.\n    const runner = new AudioConversationRunner(liveSession, options, {\n      audioContext,\n      mediaStream,\n      sourceNode,\n      workletNode\n    });\n\n    return { stop: () => runner.stop() };\n  } catch (e) {\n    // Ensure the audio context is closed on any setup error.\n    if (audioContext && audioContext.state !== 'closed') {\n      void audioContext.close();\n    }\n\n    // Re-throw specific, known error types directly. The user may want to handle `DOMException`\n    // errors differently (for example, if permission to access audio device was denied).\n    if (e instanceof AIError || e instanceof DOMException) {\n      throw e;\n    }\n\n    // Wrap any other unexpected errors in a standard AIError.\n    throw new AIError(\n      AIErrorCode.ERROR,\n      `Failed to initialize audio recording: ${(e as Error).message}`\n    );\n  }\n}\n", "/**\n * @license\n * Copyright 2024 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { FirebaseApp, getApp, _getProvider } from '@firebase/app';\nimport { Provider } from '@firebase/component';\nimport { getModularInstance } from '@firebase/util';\nimport { AI_TYPE, DEFAULT_HYBRID_IN_CLOUD_MODEL } from './constants';\nimport { AIService } from './service';\nimport { AI, AIOptions } from './public-types';\nimport {\n  ImagenModelParams,\n  HybridParams,\n  ModelParams,\n  RequestOptions,\n  AIErrorCode,\n  LiveModelParams\n} from './types';\nimport { AIError } from './errors';\nimport {\n  AIModel,\n  GenerativeModel,\n  LiveGenerativeModel,\n  ImagenModel\n} from './models';\nimport { encodeInstanceIdentifier } from './helpers';\nimport { GoogleAIBackend } from './backend';\nimport { WebSocketHandlerImpl } from './websocket';\nimport { TemplateGenerativeModel } from './models/template-generative-model';\nimport { TemplateImagenModel } from './models/template-imagen-model';\n\nexport { ChatSession } from './methods/chat-session';\nexport { LiveSession } from './methods/live-session';\nexport * from './requests/schema-builder';\nexport { ImagenImageFormat } from './requests/imagen-image-format';\nexport {\n  AIModel,\n  GenerativeModel,\n  LiveGenerativeModel,\n  ImagenModel,\n  TemplateGenerativeModel,\n  TemplateImagenModel,\n  AIError\n};\nexport { Backend, VertexAIBackend, GoogleAIBackend } from './backend';\nexport {\n  startAudioConversation,\n  AudioConversationController,\n  StartAudioConversationOptions\n} from './methods/live-session-helpers';\n\ndeclare module '@firebase/component' {\n  interface NameServiceMapping {\n    [AI_TYPE]: AIService;\n  }\n}\n\n/**\n * Returns the default {@link AI} instance that is associated with the provided\n * {@link @firebase/app#FirebaseApp}. If no instance exists, initializes a new instance with the\n * default settings.\n *\n * @example\n * ```javascript\n * const ai = getAI(app);\n * ```\n *\n * @example\n * ```javascript\n * // Get an AI instance configured to use the Gemini Developer API (via Google AI).\n * const ai = getAI(app, { backend: new GoogleAIBackend() });\n * ```\n *\n * @example\n * ```javascript\n * // Get an AI instance configured to use the Vertex AI Gemini API.\n * const ai = getAI(app, { backend: new VertexAIBackend() });\n * ```\n *\n * @param app - The {@link @firebase/app#FirebaseApp} to use.\n * @param options - {@link AIOptions} that configure the AI instance.\n * @returns The default {@link AI} instance for the given {@link @firebase/app#FirebaseApp}.\n *\n * @public\n */\nexport function getAI(app: FirebaseApp = getApp(), options?: AIOptions): AI {\n  app = getModularInstance(app);\n  // Dependencies\n  const AIProvider: Provider<'AI'> = _getProvider(app, AI_TYPE);\n\n  const backend = options?.backend ?? new GoogleAIBackend();\n\n  const finalOptions: Omit<AIOptions, 'backend'> = {\n    useLimitedUseAppCheckTokens: options?.useLimitedUseAppCheckTokens ?? false\n  };\n\n  const identifier = encodeInstanceIdentifier(backend);\n  const aiInstance = AIProvider.getImmediate({\n    identifier\n  });\n\n  aiInstance.options = finalOptions;\n\n  return aiInstance;\n}\n\n/**\n * Returns a {@link GenerativeModel} class with methods for inference\n * and other functionality.\n *\n * @public\n */\nexport function getGenerativeModel(\n  ai: AI,\n  modelParams: ModelParams | HybridParams,\n  requestOptions?: RequestOptions\n): GenerativeModel {\n  // Uses the existence of HybridParams.mode to clarify the type of the modelParams input.\n  const hybridParams = modelParams as HybridParams;\n  let inCloudParams: ModelParams;\n  if (hybridParams.mode) {\n    inCloudParams = hybridParams.inCloudParams || {\n      model: DEFAULT_HYBRID_IN_CLOUD_MODEL\n    };\n  } else {\n    inCloudParams = modelParams as ModelParams;\n  }\n\n  if (!inCloudParams.model) {\n    throw new AIError(\n      AIErrorCode.NO_MODEL,\n      `Must provide a model name. Example: getGenerativeModel({ model: 'my-model-name' })`\n    );\n  }\n\n  /**\n   * An AIService registered by index.node.ts will not have a\n   * chromeAdapterFactory() method.\n   */\n  const chromeAdapter = (ai as AIService).chromeAdapterFactory?.(\n    hybridParams.mode,\n    typeof window === 'undefined' ? undefined : window,\n    hybridParams.onDeviceParams\n  );\n\n  return new GenerativeModel(ai, inCloudParams, requestOptions, chromeAdapter);\n}\n\n/**\n * Returns an {@link ImagenModel} class with methods for using Imagen.\n *\n * Only Imagen 3 models (named `imagen-3.0-*`) are supported.\n *\n * @param ai - An {@link AI} instance.\n * @param modelParams - Parameters to use when making Imagen requests.\n * @param requestOptions - Additional options to use when making requests.\n *\n * @throws If the `apiKey` or `projectId` fields are missing in your\n * Firebase config.\n *\n * @public\n */\nexport function getImagenModel(\n  ai: AI,\n  modelParams: ImagenModelParams,\n  requestOptions?: RequestOptions\n): ImagenModel {\n  if (!modelParams.model) {\n    throw new AIError(\n      AIErrorCode.NO_MODEL,\n      `Must provide a model name. Example: getImagenModel({ model: 'my-model-name' })`\n    );\n  }\n  return new ImagenModel(ai, modelParams, requestOptions);\n}\n\n/**\n * Returns a {@link LiveGenerativeModel} class for real-time, bidirectional communication.\n *\n * The Live API is only supported in modern browser windows and Node >= 22.\n *\n * @param ai - An {@link AI} instance.\n * @param modelParams - Parameters to use when setting up a {@link LiveSession}.\n * @throws If the `apiKey` or `projectId` fields are missing in your\n * Firebase config.\n *\n * @beta\n */\nexport function getLiveGenerativeModel(\n  ai: AI,\n  modelParams: LiveModelParams\n): LiveGenerativeModel {\n  if (!modelParams.model) {\n    throw new AIError(\n      AIErrorCode.NO_MODEL,\n      `Must provide a model name for getLiveGenerativeModel. Example: getLiveGenerativeModel(ai, { model: 'my-model-name' })`\n    );\n  }\n  const webSocketHandler = new WebSocketHandlerImpl();\n  return new LiveGenerativeModel(ai, modelParams, webSocketHandler);\n}\n\n/**\n * Returns a {@link TemplateGenerativeModel} class for executing server-side\n * templates.\n *\n * @param ai - An {@link AI} instance.\n * @param requestOptions - Additional options to use when making requests.\n *\n * @beta\n */\nexport function getTemplateGenerativeModel(\n  ai: AI,\n  requestOptions?: RequestOptions\n): TemplateGenerativeModel {\n  return new TemplateGenerativeModel(ai, requestOptions);\n}\n\n/**\n * Returns a {@link TemplateImagenModel} class for executing server-side\n * Imagen templates.\n *\n * @param ai - An {@link AI} instance.\n * @param requestOptions - Additional options to use when making requests.\n *\n * @beta\n */\nexport function getTemplateImagenModel(\n  ai: AI,\n  requestOptions?: RequestOptions\n): TemplateImagenModel {\n  return new TemplateImagenModel(ai, requestOptions);\n}\n", "/**\n * The Firebase AI Web SDK.\n *\n * @packageDocumentation\n */\n\n/**\n * @license\n * Copyright 2025 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { registerVersion, _registerComponent } from '@firebase/app';\nimport { AI_TYPE } from './constants';\nimport { Component, ComponentType } from '@firebase/component';\nimport { name, version } from '../package.json';\nimport { LanguageModel } from './types/language-model';\nimport { factory } from './factory-browser';\n\ndeclare global {\n  interface Window {\n    LanguageModel: LanguageModel;\n  }\n}\n\nfunction registerAI(): void {\n  _registerComponent(\n    new Component(AI_TYPE, factory, ComponentType.PUBLIC).setMultipleInstances(\n      true\n    )\n  );\n\n  registerVersion(name, version);\n  // BUILD_TARGET will be replaced by values like esm, cjs, etc during the compilation\n  registerVersion(name, version, '__BUILD_TARGET__');\n}\n\nregisterAI();\n\nexport * from './api';\nexport * from './public-types';\n"],
  "mappings": ";;;;;;;;;;;;;;;;;AAmBO,IAAM,UAAU;AAEhB,IAAM,mBAAmB;AAEzB,IAAM,iBAAiB;AAKvB,IAAM,sBAAsB;AAE5B,IAAM,kBAAkB;AAExB,IAAM,eAAe;AAErB,IAAM,2BAA2B,MAAM;AAKvC,IAAM,gCAAgC;ACbvC,IAAO,UAAP,MAAO,iBAAgB,cAAa;;;;;;;;EAQxC,YACW,MACT,SACS,iBAAiC;AAG1C,UAAM,UAAU;AAChB,UAAM,WAAW,GAAG,OAAO,IAAI,IAAI;AACnC,UAAM,cAAc,GAAG,OAAO,KAAK,OAAO,KAAK,QAAQ;AACvD,UAAM,MAAM,WAAW;AARd,SAAI,OAAJ;AAEA,SAAe,kBAAf;AAYT,QAAI,MAAM,mBAAmB;AAG3B,YAAM,kBAAkB,MAAM,QAAO;;AAOvC,WAAO,eAAe,MAAM,SAAQ,SAAS;AAG7C,SAAK,WAAW,MAAM;;AAEzB;ACrCM,IAAM,iBAAiB,CAAC,QAAQ,SAAS,YAAY,QAAQ;AAMvD,IAAA,eAAe;EAC1B,2BAA2B;EAC3B,iCAAiC;EACjC,0BAA0B;EAC1B,iCAAiC;;AAatB,IAAA,qBAAqB;;;;EAIhC,qBAAqB;;;;EAIrB,wBAAwB;;;;EAIxB,iBAAiB;;;;EAIjB,YAAY;;;;;EAKZ,KAAK;;AAeM,IAAA,kBAAkB;;;;EAI7B,UAAU;;;;EAIV,aAAa;;AAeF,IAAA,kBAAkB;;;;EAI7B,YAAY;;;;EAIZ,KAAK;;;;EAIL,QAAQ;;;;EAIR,MAAM;;AAcK,IAAA,eAAe;;;;EAI1B,0BAA0B;;;;EAI1B,mBAAmB;;;;EAInB,sBAAsB;;;;EAItB,oBAAoB;;;;;;;EAOpB,2BAA2B;;AAahB,IAAA,cAAc;;;;EAIzB,QAAQ;;;;EAIR,OAAO;;;;EAIP,WAAW;;;;EAIX,oBAAoB;;AAaT,IAAA,eAAe;;;;EAI1B,MAAM;;;;EAIN,YAAY;;;;EAIZ,QAAQ;;;;EAIR,YAAY;;;;EAIZ,OAAO;;;;EAIP,WAAW;;;;EAIX,oBAAoB;;;;EAIpB,MAAM;;;;EAIN,yBAAyB;;AAYd,IAAA,sBAAsB;;;;;EAKjC,MAAM;;;;;;;EAON,KAAK;;;;;EAKL,MAAM;;AAaK,IAAA,WAAW;;;;EAItB,sBAAsB;;;;EAItB,MAAM;;;;EAIN,OAAO;;;;EAIP,OAAO;;;;EAIP,OAAO;;;;EAIP,UAAU;;AAcC,IAAA,mBAAmB;;;;;EAK9B,MAAM;;;;;EAKN,OAAO;;;;;EAKP,OAAO;;AAgCI,IAAA,gBAAgB;EAC3B,oBAAoB;EACpB,kBAAkB;EAClB,iBAAiB;EACjB,mBAAmB;;AAeR,IAAA,kBAAkB;EAC7B,aAAa;EACb,YAAY;;AAgBD,IAAA,UAAU;EACrB,aAAa;EACb,IAAI;EACJ,QAAQ;EACR,mBAAmB;;AAeR,IAAA,WAAW;EACtB,aAAa;EACb,QAAQ;;ACbG,IAAA,qBAAqB;;;;EAIhC,kCAAkC;;;;EAIlC,8BAA8B;;;;EAI9B,4BAA4B;;;;EAI5B,8BAA8B;;;;EAI9B,6BAA6B;;AAmLlB,IAAA,mBAAmB;EAC9B,gBAAgB;EAChB,WAAW;EACX,wBAAwB;;ACtiBb,IAAA,cAAc;;EAEzB,OAAO;;EAGP,eAAe;;EAGf,gBAAgB;;EAGhB,aAAa;;EAGb,gBAAgB;;EAGhB,iBAAiB;;EAGjB,iBAAiB;;EAGjB,gBAAgB;;EAGhB,YAAY;;EAGZ,WAAW;;EAGX,UAAU;;EAGV,eAAe;;EAGf,cAAc;;EAGd,aAAa;;AClFF,IAAA,aAAa;;EAExB,QAAQ;;EAER,QAAQ;;EAER,SAAS;;EAET,SAAS;;EAET,OAAO;;EAEP,QAAQ;;AC6EG,IAAA,0BAA0B;;;;EAIrC,qBAAqB;;;;EAIrB,wBAAwB;;;;EAIxB,iBAAiB;;;;;;;EAOjB,YAAY;;AA0BD,IAAA,0BAA0B;;;;EAIrC,WAAW;;;;;;;;EAQX,aAAa;;;;;;;;EAQb,WAAW;;AA6CA,IAAA,oBAAoB;;;;EAI/B,UAAU;;;;EAIV,iBAAiB;;;;EAIjB,gBAAgB;;;;EAIhB,kBAAkB;;;;EAIlB,iBAAiB;;AClLN,IAAA,cAAc;;;;;EAKzB,WAAW;;;;;EAMX,WAAW;AACH;IChDY,gBAAO;;;;;EAU3B,YAAsB,MAAiB;AACrC,SAAK,cAAc;;AAYtB;AAUK,IAAO,kBAAP,cAA+B,QAAO;;;;EAI1C,cAAA;AACE,UAAM,YAAY,SAAS;;;;;EAM7B,cAAc,SAAiB,OAAa;AAC1C,WAAO,IAAI,mBAAmB,aAAa,OAAO,IAAI,KAAK;;;;;EAM7D,iBAAiB,SAAiB,YAAkB;AAClD,WAAO,IAAI,mBAAmB,aAAa,OAAO,cAAc,UAAU;;AAE7E;AAUK,IAAO,kBAAP,cAA+B,QAAO;;;;;;;;EAe1C,YAAY,WAAmB,kBAAgB;AAC7C,UAAM,YAAY,SAAS;AAC3B,QAAI,CAAC,UAAU;AACb,WAAK,WAAW;WACX;AACL,WAAK,WAAW;;;;;;EAOpB,cAAc,SAAiB,OAAa;AAC1C,WAAO,IAAI,mBAAmB,aAAa,OAAO,cAAc,KAAK,QAAQ,IAAI,KAAK;;;;;EAMxF,iBAAiB,SAAiB,YAAkB;AAClD,WAAO,IAAI,mBAAmB,aAAa,OAAO,cAAc,KAAK,QAAQ,cAAc,UAAU;;AAExG;ACrGK,SAAU,yBAAyB,SAAgB;AACvD,MAAI,mBAAmB,iBAAiB;AACtC,WAAO,GAAG,OAAO;aACR,mBAAmB,iBAAiB;AAC7C,WAAO,GAAG,OAAO,aAAa,QAAQ,QAAQ;SACzC;AACL,UAAM,IAAI,QACR,YAAY,OACZ,oBAAoB,KAAK,UAAU,QAAQ,WAAW,CAAC,EAAE;;AAG/D;AAOM,SAAU,yBAAyB,oBAA0B;AACjE,QAAM,kBAAkB,mBAAmB,MAAM,GAAG;AACpD,MAAI,gBAAgB,CAAC,MAAM,SAAS;AAClC,UAAM,IAAI,QACR,YAAY,OACZ,gDAAgD,gBAAgB,CAAC,CAAC,GAAG;;AAGzE,QAAM,cAAc,gBAAgB,CAAC;AACrC,UAAQ,aAAW;IACjB,KAAK;AACH,YAAM,WAA+B,gBAAgB,CAAC;AACtD,UAAI,CAAC,UAAU;AACb,cAAM,IAAI,QACR,YAAY,OACZ,kDAAkD,kBAAkB,GAAG;;AAG3E,aAAO,IAAI,gBAAgB,QAAQ;IACrC,KAAK;AACH,aAAO,IAAI,gBAAe;IAC5B;AACE,YAAM,IAAI,QACR,YAAY,OACZ,wCAAwC,kBAAkB,GAAG;;AAGrE;ACtDO,IAAM,SAAS,IAAI,OAAO,oBAAoB;ACyBrD,IAAY;CAAZ,SAAYA,eAAY;AACtB,EAAAA,cAAA,aAAA,IAAA;AACA,EAAAA,cAAA,cAAA,IAAA;AACA,EAAAA,cAAA,aAAA,IAAA;AACA,EAAAA,cAAA,WAAA,IAAA;AACF,GALY,iBAAA,eAKX,CAAA,EAAA;ACTD,IAAM,wBAAiD,CAAC,EAAE,MAAM,QAAO,CAAE;IAO5D,0BAAA,mBAAiB;EAW5B,YACS,uBACA,MACP,gBAA+B;AAFxB,SAAqB,wBAArB;AACA,SAAI,OAAJ;AAVD,SAAa,gBAAG;AAGxB,SAAA,iBAAiC;MAC/B,eAAe;QACb,gBAAgB;MACjB;;AAOD,QAAI,gBAAgB;AAClB,WAAK,iBAAiB;AACtB,UAAI,CAAC,KAAK,eAAe,eAAe;AACtC,aAAK,eAAe,gBAAgB;UAClC,gBAAgB;;iBAET,CAAC,KAAK,eAAe,cAAc,gBAAgB;AAC5D,aAAK,eAAe,cAAc,iBAChC;;;;;;;;;;;;;;;;;;;EAoBR,MAAM,YAAY,SAA+B;AAC/C,QAAI,CAAC,KAAK,MAAM;AACd,aAAO,MACL,4DAA4D;AAE9D,aAAO;;AAET,QAAI,KAAK,SAAS,cAAc,eAAe;AAC7C,aAAO,MACL,kEAAkE;AAEpE,aAAO;;AAIT,UAAM,eAAe,MAAM,KAAK,oBAAmB;AAEnD,QAAI,KAAK,SAAS,cAAc,gBAAgB;AAE9C,UAAI,iBAAiB,aAAa,aAAa;AAC7C,cAAM,IAAI,QACR,YAAY,iBACZ,4DAA4D;iBAG9D,iBAAiB,aAAa,gBAC9B,iBAAiB,aAAa,aAC9B;AAEA,eAAO,MAAM,oDAAoD;AACjE,cAAM,KAAK;AACX,eAAO;;AAET,aAAO;;AAIT,QAAI,iBAAiB,aAAa,WAAW;AAC3C,aAAO,MACL,4DAA4D,YAAY,IAAI;AAE9E,aAAO;;AAET,QAAI,CAAC,mBAAkB,kBAAkB,OAAO,GAAG;AACjD,aAAO,MACL,kEAAkE;AAEpE,aAAO;;AAGT,WAAO;;;;;;;;;;;EAYT,MAAM,gBAAgB,SAA+B;AACnD,UAAM,UAAU,MAAM,KAAK,cAAa;AACxC,UAAM,WAAW,MAAM,QAAQ,IAC7B,QAAQ,SAAS,IAAI,mBAAkB,sBAAsB,CAAC;AAEhE,UAAM,OAAO,MAAM,QAAQ,OACzB,UACA,KAAK,eAAe,aAAa;AAEnC,WAAO,mBAAkB,WAAW,IAAI;;;;;;;;;;;EAY1C,MAAM,sBACJ,SAA+B;AAE/B,UAAM,UAAU,MAAM,KAAK,cAAa;AACxC,UAAM,WAAW,MAAM,QAAQ,IAC7B,QAAQ,SAAS,IAAI,mBAAkB,sBAAsB,CAAC;AAEhE,UAAM,SAAS,QAAQ,gBACrB,UACA,KAAK,eAAe,aAAa;AAEnC,WAAO,mBAAkB,iBAAiB,MAAM;;EAGlD,MAAM,YAAY,UAA4B;AAC5C,UAAM,IAAI,QACR,YAAY,eACZ,wDAAwD;;;;;EAOpD,OAAO,kBAAkB,SAA+B;AAE9D,QAAI,QAAQ,SAAS,WAAW,GAAG;AACjC,aAAO,MAAM,gDAAgD;AAC7D,aAAO;;AAGT,eAAW,WAAW,QAAQ,UAAU;AACtC,UAAI,QAAQ,SAAS,YAAY;AAC/B,eAAO,MAAM,mDAAmD;AAChE,eAAO;;AAIT,iBAAW,QAAQ,QAAQ,OAAO;AAChC,YACE,KAAK,cACL,mBAAkB,qBAAqB,QACrC,KAAK,WAAW,QAAQ,MACpB,IACN;AACA,iBAAO,MACL,0BAA0B,KAAK,WAAW,QAAQ,qCAAqC;AAEzF,iBAAO;;;;AAKb,WAAO;;;;;EAMD,MAAM,sBAAmB;;AAC/B,UAAM,eAAe,QAAM,UAAK,0BAAL,mBAA4B,aACrD,KAAK,eAAe;AAGtB,QAAI,iBAAiB,aAAa,cAAc;AAC9C,WAAK,SAAQ;;AAGf,WAAO;;;;;;;;;;;EAYD,WAAQ;;AACd,QAAI,KAAK,eAAe;AACtB;;AAEF,SAAK,gBAAgB;AACrB,SAAK,mBAAkB,UAAK,0BAAL,mBACnB,OAAO,KAAK,eAAe,eAC5B,QAAQ,MAAK;AACZ,WAAK,gBAAgB;IACvB;;;;;EAMI,aAAa,uBACnB,SAAgB;AAEhB,UAAM,+BAA+B,MAAM,QAAQ,IACjD,QAAQ,MAAM,IAAI,mBAAkB,6BAA6B,CAAC;AAEpE,WAAO;MACL,MAAM,mBAAkB,2BAA2B,QAAQ,IAAI;MAC/D,SAAS;;;;;;EAOL,aAAa,8BACnB,MAAU;AAEV,QAAI,KAAK,MAAM;AACb,aAAO;QACL,MAAM;QACN,OAAO,KAAK;;eAEL,KAAK,YAAY;AAC1B,YAAM,wBAAwB,MAAM,MAClC,QAAQ,KAAK,WAAW,QAAQ,WAAW,KAAK,WAAW,IAAI,EAAE;AAEnE,YAAM,YAAY,MAAM,sBAAsB,KAAI;AAClD,YAAM,cAAc,MAAM,kBAAkB,SAAS;AACrD,aAAO;QACL,MAAM;QACN,OAAO;;;AAGX,UAAM,IAAI,QACR,YAAY,eACZ,0DAA0D;;;;;EAOtD,OAAO,2BACb,MAAU;AAGV,WAAO,SAAS,UAAU,cAAc;;;;;;;;;;;;EAalC,MAAM,gBAAa;AACzB,QAAI,CAAC,KAAK,uBAAuB;AAC/B,YAAM,IAAI,QACR,YAAY,aACZ,sDAAsD;;AAG1D,UAAM,aAAa,MAAM,KAAK,sBAAsB,OAClD,KAAK,eAAe,aAAa;AAEnC,QAAI,KAAK,YAAY;AACnB,WAAK,WAAW,QAAO;;AAGzB,SAAK,aAAa;AAClB,WAAO;;;;;EAMD,OAAO,WAAW,MAAY;AACpC,WAAO;MACL,MAAM,aAAa;QACjB,YAAY;UACV;YACE,SAAS;cACP,OAAO,CAAC,EAAE,KAAI,CAAE;YACjB;UACF;QACF;;;;;;;EAQC,OAAO,iBAAiB,QAA8B;AAC5D,UAAM,UAAU,IAAI,YAAW;AAC/B,WAAO;MACL,MAAM,OAAO,YACX,IAAI,gBAAgB;QAClB,UAAU,OAAO,YAAU;AACzB,gBAAM,OAAO,KAAK,UAAU;YAC1B,YAAY;cACV;gBACE,SAAS;kBACP,MAAM;kBACN,OAAO,CAAC,EAAE,MAAM,MAAK,CAAE;gBACxB;cACF;YACF;UACF,CAAA;AACD,qBAAW,QAAQ,QAAQ,OAAO,SAAS,IAAI;;CAAM,CAAC;;MAEzD,CAAA,CAAC;;;;AAhVD,kBAAA,uBAAuB,CAAC,cAAc,WAAW;SAyV1C,qBACd,MACAC,SACA,QAAuB;AAGvB,MAAI,OAAOA,YAAW,eAAe,MAAM;AACzC,WAAO,IAAI,kBACRA,QAAkB,eACnB,MACA,MAAM;;AAGZ;ICnXa,kBAAS;EAMpB,YACS,KACA,SACP,cACA,kBACOC,uBAIuB;AARvB,SAAG,MAAH;AACA,SAAO,UAAP;AAGA,SAAoB,uBAApBA;AAMP,UAAM,WAAW,qDAAkB,aAAa,EAAE,UAAU,KAAI;AAChE,UAAM,OAAO,6CAAc,aAAa,EAAE,UAAU,KAAI;AACxD,SAAK,OAAO,QAAQ;AACpB,SAAK,WAAW,YAAY;AAE5B,QAAI,mBAAmB,iBAAiB;AACtC,WAAK,WAAW,QAAQ;WACnB;AACL,WAAK,WAAW;;;EAIpB,UAAO;AACL,WAAO,QAAQ,QAAO;;EAGxB,IAAI,QAAQ,cAAuB;AACjC,SAAK,WAAW;;EAGlB,IAAI,UAAO;AACT,WAAO,KAAK;;AAEf;SCjDe,QACd,WACA,EAAE,mBAAkB,GAA0B;AAE9C,MAAI,CAAC,oBAAoB;AACvB,UAAM,IAAI,QACR,YAAY,OACZ,6CAA6C;;AAIjD,QAAM,UAAU,yBAAyB,kBAAkB;AAG3D,QAAM,MAAM,UAAU,YAAY,KAAK,EAAE,aAAY;AACrD,QAAM,OAAO,UAAU,YAAY,eAAe;AAClD,QAAM,mBAAmB,UAAU,YAAY,oBAAoB;AAEnE,SAAO,IAAI,UACT,KACA,SACA,MACA,kBACA,oBAAoB;AAExB;ACtBM,SAAU,gBAAgB,IAAM;;AACpC,MAAI,GAAC,cAAG,QAAH,mBAAQ,YAAR,mBAAiB,SAAQ;AAC5B,UAAM,IAAI,QACR,YAAY,YACZ,uHAAuH;aAEhH,GAAC,cAAG,QAAH,mBAAQ,YAAR,mBAAiB,YAAW;AACtC,UAAM,IAAI,QACR,YAAY,eACZ,6HAA6H;aAEtH,GAAC,cAAG,QAAH,mBAAQ,YAAR,mBAAiB,QAAO;AAClC,UAAM,IAAI,QACR,YAAY,WACZ,qHAAqH;;AAIzH,QAAM,cAA2B;IAC/B,QAAQ,GAAG,IAAI,QAAQ;IACvB,SAAS,GAAG,IAAI,QAAQ;IACxB,OAAO,GAAG,IAAI,QAAQ;IACtB,gCAAgC,GAAG,IAAI;IACvC,UAAU,GAAG;IACb,SAAS,GAAG;;AAGd,MAAI,qBAAqB,GAAG,GAAG,KAAK,GAAG,IAAI,SAAS,eAAe;AACjE,UAAM,QAAQ,GAAG,IAAI,SAAS;AAC9B,gBAAY,mBAAmB,MAAK;AAClC,aAAO,QAAQ,QAAQ,EAAE,MAAK,CAAE;IAClC;aACU,GAAiB,UAAU;AACrC,SAAI,QAAG,YAAH,mBAAY,6BAA6B;AAC3C,kBAAY,mBAAmB,MAC5B,GAAiB,SAAU,mBAAkB;WAC3C;AACL,kBAAY,mBAAmB,MAC5B,GAAiB,SAAU,SAAQ;;;AAI1C,MAAK,GAAiB,MAAM;AAC1B,gBAAY,eAAe,MAAO,GAAiB,KAAM,SAAQ;;AAGnE,SAAO;AACT;IChDsB,gBAAA,SAAO;;;;;;;;;;;;;;;;;;EA6B3B,YAAsB,IAAQ,WAAiB;AAC7C,SAAK,eAAe,gBAAgB,EAAE;AACtC,SAAK,QAAQ,SAAQ,mBACnB,WACA,KAAK,aAAa,QAAQ,WAAW;;;;;;;;;;EAYzC,OAAO,mBACL,WACA,aAAwB;AAExB,QAAI,gBAAgB,YAAY,WAAW;AACzC,aAAO,SAAQ,2BAA2B,SAAS;WAC9C;AACL,aAAO,SAAQ,2BAA2B,SAAS;;;;;;EAO/C,OAAO,2BAA2B,WAAiB;AACzD,WAAO,UAAU,SAAS;;;;;EAMpB,OAAO,2BAA2B,WAAiB;AACzD,QAAI;AACJ,QAAI,UAAU,SAAS,GAAG,GAAG;AAC3B,UAAI,UAAU,WAAW,SAAS,GAAG;AAEnC,gBAAQ,qBAAqB,SAAS;aACjC;AAEL,gBAAQ;;WAEL;AAEL,cAAQ,4BAA4B,SAAS;;AAG/C,WAAO;;AAEV;IC9CY,mBAAU;EACrB,YACkB,QAAwD;AAAxD,SAAM,SAAN;;EAGlB,WAAQ;AACN,UAAM,MAAM,IAAI,IAAI,KAAK,OAAO;AAChC,QAAI,WAAW,KAAK;AACpB,QAAI,SAAS,KAAK,YAAY,SAAQ;AACtC,WAAO,IAAI,SAAQ;;EAGrB,IAAY,WAAQ;AAIlB,QAAI,KAAK,OAAO,YAAY;AAC1B,aAAO,GAAG,KAAK,OAAO,YAAY,QAAQ,iBACxC,KAAK,OAAO,YAAY,SACxB,KAAK,OAAO,UAAU,CACvB,IAAI,KAAK,OAAO,IAAI;WAChB;AACL,aAAO,GAAG,KAAK,OAAO,YAAY,QAAQ,cACxC,KAAK,OAAO,YAAY,SACvB,KAAK,OAAiC,KAAK,CAC7C,IAAI,KAAK,OAAO,IAAI;;;EAIzB,IAAY,UAAO;;AACjB,aAAO,UAAK,OAAO,mBAAZ,mBAA4B,YAAW,WAAW,cAAc;;EAGzE,IAAY,cAAW;AACrB,UAAM,SAAS,IAAI,gBAAe;AAClC,QAAI,KAAK,OAAO,QAAQ;AACtB,aAAO,IAAI,OAAO,KAAK;;AAGzB,WAAO;;AAEV;IAEY,qBAAY;EACvB,YAAmB,aAAwB;AAAxB,SAAW,cAAX;;EACnB,WAAQ;AACN,UAAM,MAAM,IAAI,IAAI,SAAS,cAAc,EAAE;AAC7C,QAAI,WAAW,KAAK;AAEpB,UAAM,cAAc,IAAI,gBAAe;AACvC,gBAAY,IAAI,OAAO,KAAK,YAAY,MAAM;AAC9C,QAAI,SAAS,YAAY,SAAQ;AAEjC,WAAO,IAAI,SAAQ;;EAGrB,IAAY,WAAQ;AAClB,QAAI,KAAK,YAAY,QAAQ,gBAAgB,YAAY,WAAW;AAClE,aAAO;WACF;AACL,aAAO,mFAAmF,KAAK,YAAY,QAAQ;;;AAGxH;AAKD,SAAS,mBAAgB;AACvB,QAAM,cAAc,CAAA;AACpB,cAAY,KAAK,GAAG,YAAY,IAAI,eAAe,EAAE;AACrD,cAAY,KAAK,QAAQ,eAAe,EAAE;AAC1C,SAAO,YAAY,KAAK,GAAG;AAC7B;AAEO,eAAe,WAAW,KAAe;AAC9C,QAAM,UAAU,IAAI,QAAO;AAC3B,UAAQ,OAAO,gBAAgB,kBAAkB;AACjD,UAAQ,OAAO,qBAAqB,iBAAgB,CAAE;AACtD,UAAQ,OAAO,kBAAkB,IAAI,OAAO,YAAY,MAAM;AAC9D,MAAI,IAAI,OAAO,YAAY,gCAAgC;AACzD,YAAQ,OAAO,oBAAoB,IAAI,OAAO,YAAY,KAAK;;AAEjE,MAAI,IAAI,OAAO,YAAY,kBAAkB;AAC3C,UAAM,gBAAgB,MAAM,IAAI,OAAO,YAAY,iBAAgB;AACnE,QAAI,eAAe;AACjB,cAAQ,OAAO,uBAAuB,cAAc,KAAK;AACzD,UAAI,cAAc,OAAO;AACvB,eAAO,KACL,6CAA6C,cAAc,MAAM,OAAO,EAAE;;;;AAMlF,MAAI,IAAI,OAAO,YAAY,cAAc;AACvC,UAAM,YAAY,MAAM,IAAI,OAAO,YAAY,aAAY;AAC3D,QAAI,WAAW;AACb,cAAQ,OAAO,iBAAiB,YAAY,UAAU,WAAW,EAAE;;;AAIvE,SAAO;AACT;AAEO,eAAe,YACpB,kBACA,MAAY;;AAEZ,QAAM,MAAM,IAAI,WAAW,gBAAgB;AAC3C,MAAI;AACJ,MAAI;AACJ,MAAI;AACF,UAAM,eAA4B;MAChC,QAAQ;MACR,SAAS,MAAM,WAAW,GAAG;MAC7B;;AAIF,UAAM,kBACJ,sBAAiB,mBAAjB,mBAAiC,YAAW,QAC5C,iBAAiB,eAAe,WAAW,IACvC,iBAAiB,eAAe,UAChC;AACN,UAAM,kBAAkB,IAAI,gBAAe;AAC3C,qBAAiB,WAAW,MAAM,gBAAgB,MAAK,GAAI,aAAa;AACxE,iBAAa,SAAS,gBAAgB;AAEtC,eAAW,MAAM,MAAM,IAAI,SAAQ,GAAI,YAAY;AACnD,QAAI,CAAC,SAAS,IAAI;AAChB,UAAI,UAAU;AACd,UAAI;AACJ,UAAI;AACF,cAAM,OAAO,MAAM,SAAS,KAAI;AAChC,kBAAU,KAAK,MAAM;AACrB,YAAI,KAAK,MAAM,SAAS;AACtB,qBAAW,IAAI,KAAK,UAAU,KAAK,MAAM,OAAO,CAAC;AACjD,yBAAe,KAAK,MAAM;;eAErB,GAAG;;AAGZ,UACE,SAAS,WAAW,OACpB,gBACA,aAAa,KACX,CAAC,WAAyB,OAAO,WAAW,kBAAkB,KAEhE,aAAa,KAAK,CAAC,WAAoB;;AAEnC,sBAAAC,MAAA,OAAO,UAAP,gBAAAA,IACE,OADF,mBACM,YAAY,SAClB;OACD,GAEH;AACA,cAAM,IAAI,QACR,YAAY,iBACZ,gOAGoD,IAAI,OAAO,YAAY,OAAO,uJAIlF;UACE,QAAQ,SAAS;UACjB,YAAY,SAAS;UACrB;QACD,CAAA;;AAGL,YAAM,IAAI,QACR,YAAY,aACZ,uBAAuB,GAAG,MAAM,SAAS,MAAM,IAAI,SAAS,UAAU,KAAK,OAAO,IAClF;QACE,QAAQ,SAAS;QACjB,YAAY,SAAS;QACrB;MACD,CAAA;;WAGE,GAAG;AACV,QAAI,MAAM;AACV,QACG,EAAc,SAAS,YAAY,eACnC,EAAc,SAAS,YAAY,mBACpC,aAAa,OACb;AACA,YAAM,IAAI,QACR,YAAY,OACZ,uBAAuB,IAAI,SAAQ,CAAE,KAAK,EAAE,OAAO,EAAE;AAEvD,UAAI,QAAQ,EAAE;;AAGhB,UAAM;;AAEN,QAAI,gBAAgB;AAClB,mBAAa,cAAc;;;AAG/B,SAAO;AACT;ACxOA,SAAS,mBAAmB,UAAiC;AAC3D,MAAI,SAAS,cAAc,SAAS,WAAW,SAAS,GAAG;AACzD,QAAI,SAAS,WAAW,SAAS,GAAG;AAClC,aAAO,KACL,qBAAqB,SAAS,WAAW,MAAM,6HAEqB;;AAGxE,QAAI,mBAAmB,SAAS,WAAW,CAAC,CAAC,GAAG;AAC9C,YAAM,IAAI,QACR,YAAY,gBACZ,mBAAmB,wBACjB,QAAQ,CACT,4CACD;QACE;MACD,CAAA;;AAGL,WAAO;SACF;AACL,WAAO;;AAEX;AAMM,SAAU,8BACd,UACA,kBAAmC,gBAAgB,UAAQ;AAQ3D,MAAI,SAAS,cAAc,CAAC,SAAS,WAAW,CAAC,EAAE,eAAe,OAAO,GAAG;AAC1E,aAAS,WAAW,CAAC,EAAE,QAAQ;;AAGjC,QAAM,sBAAsB,WAAW,QAAQ;AAC/C,sBAAoB,kBAAkB;AACtC,SAAO;AACT;AAMM,SAAU,WACd,UAAiC;AAEhC,WAA6C,OAAO,MAAK;AACxD,QAAI,mBAAmB,QAAQ,GAAG;AAChC,aAAO,QAAQ,UAAU,UAAQ,CAAC,KAAK,OAAO;eACrC,SAAS,gBAAgB;AAClC,YAAM,IAAI,QACR,YAAY,gBACZ,uBAAuB,wBAAwB,QAAQ,CAAC,IACxD;QACE;MACD,CAAA;;AAGL,WAAO;EACT;AACC,WAA6C,iBAAiB,MAAK;AAClE,QAAI,mBAAmB,QAAQ,GAAG;AAChC,YAAM,SAAS,QAAQ,UAAU,UAAQ,CAAC,CAAC,KAAK,OAAO;AACvD,aAAO,WAAW,KAAK,SAAY;eAC1B,SAAS,gBAAgB;AAClC,YAAM,IAAI,QACR,YAAY,gBACZ,kCAAkC,wBAAwB,QAAQ,CAAC,IACnE;QACE;MACD,CAAA;;AAGL,WAAO;EACT;AACC,WAA6C,kBAAkB,MAEhD;AACd,QAAI,mBAAmB,QAAQ,GAAG;AAChC,aAAO,mBAAmB,QAAQ;eACzB,SAAS,gBAAgB;AAClC,YAAM,IAAI,QACR,YAAY,gBACZ,uBAAuB,wBAAwB,QAAQ,CAAC,IACxD;QACE;MACD,CAAA;;AAGL,WAAO;EACT;AACC,WAA6C,gBAAgB,MAAK;AACjE,QAAI,mBAAmB,QAAQ,GAAG;AAChC,aAAO,iBAAiB,QAAQ;eACvB,SAAS,gBAAgB;AAClC,YAAM,IAAI,QACR,YAAY,gBACZ,gCAAgC,wBAAwB,QAAQ,CAAC,IACjE;QACE;MACD,CAAA;;AAGL,WAAO;EACT;AACA,SAAO;AACT;AASgB,SAAA,QACd,UACA,YAAmC;;AAEnC,QAAM,cAAc,CAAA;AACpB,OAAI,oBAAS,eAAT,mBAAsB,GAAG,YAAzB,mBAAkC,OAAO;AAC3C,eAAW,SAAQ,oBAAS,eAAT,mBAAsB,GAAG,YAAzB,mBAAkC,OAAO;AAC1D,UAAI,KAAK,QAAQ,WAAW,IAAI,GAAG;AACjC,oBAAY,KAAK,KAAK,IAAI;;;;AAIhC,MAAI,YAAY,SAAS,GAAG;AAC1B,WAAO,YAAY,KAAK,EAAE;SACrB;AACL,WAAO;;AAEX;AAKM,SAAU,iBACd,UAAiC;;AAEjC,QAAM,gBAAgC,CAAA;AACtC,OAAI,oBAAS,eAAT,mBAAsB,GAAG,YAAzB,mBAAkC,OAAO;AAC3C,eAAW,SAAQ,oBAAS,eAAT,mBAAsB,GAAG,YAAzB,mBAAkC,OAAO;AAC1D,UAAI,KAAK,cAAc;AACrB,sBAAc,KAAK,KAAK,YAAY;;;;AAI1C,MAAI,cAAc,SAAS,GAAG;AAC5B,WAAO;SACF;AACL,WAAO;;AAEX;AAOM,SAAU,mBACd,UAAiC;;AAEjC,QAAM,OAAyB,CAAA;AAE/B,OAAI,oBAAS,eAAT,mBAAsB,GAAG,YAAzB,mBAAkC,OAAO;AAC3C,eAAW,SAAQ,oBAAS,eAAT,mBAAsB,GAAG,YAAzB,mBAAkC,OAAO;AAC1D,UAAI,KAAK,YAAY;AACnB,aAAK,KAAK,IAAI;;;;AAKpB,MAAI,KAAK,SAAS,GAAG;AACnB,WAAO;SACF;AACL,WAAO;;AAEX;AAEA,IAAM,mBAAmB,CAAC,aAAa,YAAY,aAAa,MAAM;AAEtE,SAAS,mBAAmB,WAAmC;AAC7D,SACE,CAAC,CAAC,UAAU,gBACZ,iBAAiB,KAAK,YAAU,WAAW,UAAU,YAAY;AAErE;AAEM,SAAU,wBACd,UAAiC;;AAEjC,MAAI,UAAU;AACd,OACG,CAAC,SAAS,cAAc,SAAS,WAAW,WAAW,MACxD,SAAS,gBACT;AACA,eAAW;AACX,SAAI,cAAS,mBAAT,mBAAyB,aAAa;AACxC,iBAAW,WAAW,SAAS,eAAe,WAAW;;AAE3D,SAAI,cAAS,mBAAT,mBAAyB,oBAAoB;AAC/C,iBAAW,KAAK,SAAS,eAAe,kBAAkB;;cAEnD,cAAS,eAAT,mBAAsB,IAAI;AACnC,UAAM,iBAAiB,SAAS,WAAW,CAAC;AAC5C,QAAI,mBAAmB,cAAc,GAAG;AACtC,iBAAW,gCAAgC,eAAe,YAAY;AACtE,UAAI,eAAe,eAAe;AAChC,mBAAW,KAAK,eAAe,aAAa;;;;AAIlD,SAAO;AACT;AASO,eAAe,sBAEpB,UAAkB;;AAClB,QAAM,eAAuC,MAAM,SAAS,KAAI;AAEhE,QAAM,SAAc,CAAA;AACpB,MAAI,iBAAqC;AAGzC,MAAI,CAAC,aAAa,iBAAe,kBAAa,gBAAb,mBAA0B,YAAW,GAAG;AACvE,UAAM,IAAI,QACR,YAAY,gBACZ,wKAAwK;;AAI5K,aAAW,cAAc,aAAa,aAAa;AACjD,QAAI,WAAW,mBAAmB;AAChC,uBAAiB,WAAW;eACnB,WAAW,YAAY,WAAW,oBAAoB;AAC/D,aAAO,KAAK;QACV,UAAU,WAAW;QACrB,oBAAoB,WAAW;MAC3B,CAAA;eACG,WAAW,YAAY,WAAW,QAAQ;AACnD,aAAO,KAAK;QACV,UAAU,WAAW;QACrB,QAAQ,WAAW;MACf,CAAA;eACG,WAAW,iBAAkB;SAEjC;AACL,YAAM,IAAI,QACR,YAAY,gBACZ,2DAA2D,KAAK,UAC9D,UAAU,CACX,GAAG;;;AAKV,SAAO,EAAE,QAAQ,eAAc;AACjC;AC9PM,SAAU,0BACd,wBAA8C;;AAE9C,+BAAuB,mBAAvB,mBAAuC,QAAQ,mBAAgB;AAC7D,QAAI,cAAc,QAAQ;AACxB,YAAM,IAAI,QACR,YAAY,aACZ,qGAAqG;;EAG3G;AAEA,OAAI,4BAAuB,qBAAvB,mBAAyC,MAAM;AACjD,UAAM,cAAc,KAAK,MACvB,uBAAuB,iBAAiB,IAAI;AAG9C,QAAI,gBAAgB,uBAAuB,iBAAiB,MAAM;AAChE,aAAO,KACL,gIAAgI;AAElI,6BAAuB,iBAAiB,OAAO;;;AAInD,SAAO;AACT;AAWM,SAAU,2BACd,kBAAiD;AAEjD,QAAM,0BAA0B;IAC9B,YAAY,iBAAiB,aACzB,6BAA6B,iBAAiB,UAAU,IACxD;IACJ,QAAQ,iBAAiB,iBACrB,kBAAkB,iBAAiB,cAAc,IACjD;IACJ,eAAe,iBAAiB;;AAGlC,SAAO;AACT;AAWgB,SAAA,sBACd,oBACA,OAAa;AAEb,QAAM,2BAAuD;IAC3D,wBAAwB;MACtB;MACA,GAAG;IACJ;;AAGH,SAAO;AACT;AAaM,SAAU,6BACd,YAA8C;AAE9C,QAAM,mBAA+C,CAAA;AACrD,MAAI;AACJ,MAAI,kBAAkB;AACpB,eAAW,QAAQ,eAAY;;AAE7B,UAAI;AACJ,UAAI,UAAU,kBAAkB;AAC9B,2BAAmB;UACjB,WAAW,UAAU,iBAAiB;;;AAK1C,UAAI,UAAU,eAAe;AAC3B,8BAAsB,UAAU,cAAc,IAAI,kBAAe;AAC/D,iBAAO;YACL,GAAG;YACH,UACE,aAAa,YAAY,aAAa;YACxC,kBAAkB,aAAa,oBAAoB;YACnD,eAAe,aAAa,iBAAiB;;QAEjD,CAAC;;AAMH,WACE,qBAAU,YAAV,mBAAmB,UAAnB,mBAA0B,KACxB,UAAS,6BAAyB,gBAEpC;AACA,cAAM,IAAI,QACR,YAAY,aACZ,+FAA+F;;AAInG,YAAM,kBAAkB;QACtB,OAAO,UAAU;QACjB,SAAS,UAAU;QACnB,cAAc,UAAU;QACxB,eAAe,UAAU;QACzB,eAAe;QACf;QACA,mBAAmB,UAAU;QAC7B,oBAAoB,UAAU;;AAEhC,uBAAiB,KAAK,eAAe;IACvC,CAAC;;AAGH,SAAO;AACT;AAEM,SAAU,kBACd,gBAA8B;AAG9B,QAAM,sBAAsC,CAAA;AAC5C,iBAAe,cAAc,QAAQ,kBAAe;AAClD,wBAAoB,KAAK;MACvB,UAAU,aAAa;MACvB,aAAa,aAAa;MAC1B,UAAU,aAAa,YAAY,aAAa;MAChD,kBAAkB,aAAa,oBAAoB;MACnD,eAAe,aAAa,iBAAiB;MAC7C,SAAS,aAAa;IACvB,CAAA;EACH,CAAC;AAED,QAAM,uBAAuC;IAC3C,aAAa,eAAe;IAC5B,eAAe;IACf,oBAAoB,eAAe;;AAErC,SAAO;AACT;AC/LA,IAAM,iBAAiB;SAUP,cACd,UACA,aACA,iBAAiC;AAEjC,QAAM,cAAc,SAAS,KAAM,YACjC,IAAI,kBAAkB,QAAQ,EAAE,OAAO,KAAI,CAAE,CAAC;AAEhD,QAAM,iBACJ,kBAA2C,WAAW;AACxD,QAAM,CAAC,SAAS,OAAO,IAAI,eAAe,IAAG;AAC7C,SAAO;IACL,QAAQ,yBAAyB,SAAS,aAAa,eAAe;IACtE,UAAU,mBAAmB,SAAS,aAAa,eAAe;;AAEtE;AAEA,eAAe,mBACb,QACA,aACA,iBAAiC;AAEjC,QAAM,eAA0C,CAAA;AAChD,QAAM,SAAS,OAAO,UAAS;AAC/B,SAAO,MAAM;AACX,UAAM,EAAE,MAAM,MAAK,IAAK,MAAM,OAAO,KAAI;AACzC,QAAI,MAAM;AACR,UAAI,0BAA0B,mBAAmB,YAAY;AAC7D,UAAI,YAAY,QAAQ,gBAAgB,YAAY,WAAW;AAC7D,kCAA0BC,2BACxB,uBAA0D;;AAG9D,aAAO,8BACL,yBACA,eAAe;;AAInB,iBAAa,KAAK,KAAK;;AAE3B;AAEA,gBAAgB,yBACd,QACA,aACA,iBAAiC;;AAEjC,QAAM,SAAS,OAAO,UAAS;AAC/B,SAAO,MAAM;AACX,UAAM,EAAE,OAAO,KAAI,IAAK,MAAM,OAAO,KAAI;AACzC,QAAI,MAAM;AACR;;AAGF,QAAI;AACJ,QAAI,YAAY,QAAQ,gBAAgB,YAAY,WAAW;AAC7D,yBAAmB,8BACjBA,2BACE,KAAwC,GAE1C,eAAe;WAEZ;AACL,yBAAmB,8BAA8B,OAAO,eAAe;;AAGzE,UAAM,kBAAiB,sBAAiB,eAAjB,mBAA8B;AAErD,QACE,GAAC,sDAAgB,YAAhB,mBAAyB,UAC1B,EAAC,iDAAgB,iBACjB,EAAC,iDAAgB,qBACjB,EAAC,iDAAgB,qBACjB;AACA;;AAGF,UAAM;;AAEV;AAOM,SAAU,kBACd,aAAmC;AAEnC,QAAM,SAAS,YAAY,UAAS;AACpC,QAAM,SAAS,IAAI,eAAkB;IACnC,MAAM,YAAU;AACd,UAAI,cAAc;AAClB,aAAO,KAAI;AACX,eAAS,OAAI;AACX,eAAO,OAAO,KAAI,EAAG,KAAK,CAAC,EAAE,OAAO,KAAI,MAAM;AAC5C,cAAI,MAAM;AACR,gBAAI,YAAY,KAAI,GAAI;AACtB,yBAAW,MACT,IAAI,QAAQ,YAAY,cAAc,wBAAwB,CAAC;AAEjE;;AAEF,uBAAW,MAAK;AAChB;;AAGF,yBAAe;AACf,cAAI,QAAQ,YAAY,MAAM,cAAc;AAC5C,cAAI;AACJ,iBAAO,OAAO;AACZ,gBAAI;AACF,+BAAiB,KAAK,MAAM,MAAM,CAAC,CAAC;qBAC7B,GAAG;AACV,yBAAW,MACT,IAAI,QACF,YAAY,cACZ,iCAAiC,MAAM,CAAC,CAAC,EAAE,CAC5C;AAEH;;AAEF,uBAAW,QAAQ,cAAc;AACjC,0BAAc,YAAY,UAAU,MAAM,CAAC,EAAE,MAAM;AACnD,oBAAQ,YAAY,MAAM,cAAc;;AAE1C,iBAAO,KAAI;QACb,CAAC;;;EAGN,CAAA;AACD,SAAO;AACT;AAMM,SAAU,mBACd,WAAoC;AAEpC,QAAM,eAAe,UAAU,UAAU,SAAS,CAAC;AACnD,QAAM,qBAA8C;IAClD,gBAAgB,6CAAc;;AAEhC,aAAW,YAAY,WAAW;AAChC,QAAI,SAAS,YAAY;AACvB,iBAAW,aAAa,SAAS,YAAY;AAG3C,cAAM,IAAI,UAAU,SAAS;AAC7B,YAAI,CAAC,mBAAmB,YAAY;AAClC,6BAAmB,aAAa,CAAA;;AAElC,YAAI,CAAC,mBAAmB,WAAW,CAAC,GAAG;AACrC,6BAAmB,WAAW,CAAC,IAAI;YACjC,OAAO,UAAU;;;AAIrB,2BAAmB,WAAW,CAAC,EAAE,mBAC/B,UAAU;AACZ,2BAAmB,WAAW,CAAC,EAAE,eAAe,UAAU;AAC1D,2BAAmB,WAAW,CAAC,EAAE,gBAC/B,UAAU;AACZ,2BAAmB,WAAW,CAAC,EAAE,gBAC/B,UAAU;AACZ,2BAAmB,WAAW,CAAC,EAAE,oBAC/B,UAAU;AAMZ,cAAM,qBAAqB,UAAU;AACrC,YACE,OAAO,uBAAuB,YAC9B,uBAAuB,QACvB,OAAO,KAAK,kBAAkB,EAAE,SAAS,GACzC;AACA,6BAAmB,WAAW,CAAC,EAAE,qBAC/B;;AAOJ,YAAI,UAAU,SAAS;AAErB,cAAI,CAAC,UAAU,QAAQ,OAAO;AAC5B;;AAEF,cAAI,CAAC,mBAAmB,WAAW,CAAC,EAAE,SAAS;AAC7C,+BAAmB,WAAW,CAAC,EAAE,UAAU;cACzC,MAAM,UAAU,QAAQ,QAAQ;cAChC,OAAO,CAAA;;;AAGX,qBAAW,QAAQ,UAAU,QAAQ,OAAO;AAC1C,kBAAM,UAAgB,EAAE,GAAG,KAAI;AAI/B,gBAAI,KAAK,SAAS,IAAI;AACpB;;AAEF,gBAAI,OAAO,KAAK,OAAO,EAAE,SAAS,GAAG;AACnC,iCAAmB,WAAW,CAAC,EAAE,QAAQ,MAAM,KAC7C,OAAe;;;;;;;AAQ7B,SAAO;AACT;AC/OA,IAAM,wBAAuC;;EAE3C,YAAY;;EAEZ,YAAY;;EAEZ,YAAY;;AAkBP,eAAe,kBACpB,SACA,eACA,cACA,aAAoC;AAEpC,MAAI,CAAC,eAAe;AAClB,WAAO;MACL,UAAU,MAAM,YAAW;MAC3B,iBAAiB,gBAAgB;;;AAGrC,UAAQ,cAAc,MAAI;IACxB,KAAK,cAAc;AACjB,UAAI,MAAM,cAAc,YAAY,OAAO,GAAG;AAC5C,eAAO;UACL,UAAU,MAAM,aAAY;UAC5B,iBAAiB,gBAAgB;;;AAGrC,YAAM,IAAI,QACR,YAAY,aACZ,4EAA4E;IAEhF,KAAK,cAAc;AACjB,aAAO;QACL,UAAU,MAAM,YAAW;QAC3B,iBAAiB,gBAAgB;;IAErC,KAAK,cAAc;AACjB,UAAI;AACF,eAAO;UACL,UAAU,MAAM,YAAW;UAC3B,iBAAiB,gBAAgB;;eAE5B,GAAG;AACV,YAAI,aAAa,WAAW,sBAAsB,SAAS,EAAE,IAAI,GAAG;AAClE,iBAAO;YACL,UAAU,MAAM,aAAY;YAC5B,iBAAiB,gBAAgB;;;AAGrC,cAAM;;IAEV,KAAK,cAAc;AACjB,UAAI,MAAM,cAAc,YAAY,OAAO,GAAG;AAC5C,eAAO;UACL,UAAU,MAAM,aAAY;UAC5B,iBAAiB,gBAAgB;;;AAGrC,aAAO;QACL,UAAU,MAAM,YAAW;QAC3B,iBAAiB,gBAAgB;;IAErC;AACE,YAAM,IAAI,QACR,YAAY,OACZ,gCAAgC,cAAc,IAAI,EAAE;;AAG5D;AC1EA,eAAe,6BACb,aACA,OACA,QACA,gBAA+B;AAE/B,MAAI,YAAY,QAAQ,gBAAgB,YAAY,WAAW;AAC7D,aAASC,0BAAyC,MAAM;;AAE1D,SAAO,YACL;IACE,MAAkC;IAClC;IACA;IACA,QAAQ;IACR;EACD,GACD,KAAK,UAAU,MAAM,CAAC;AAE1B;AAEO,eAAe,sBACpB,aACA,OACA,QACA,eACA,gBAA+B;AAE/B,QAAM,aAAa,MAAM,kBACvB,QACA,eACA,MAAM,cAAe,sBAAsB,MAAM,GACjD,MACE,6BAA6B,aAAa,OAAO,QAAQ,cAAc,CAAC;AAE5E,SAAO,cAAc,WAAW,UAAU,WAAW;AACvD;AAEA,eAAe,uBACb,aACA,OACA,QACA,gBAA+B;AAE/B,MAAI,YAAY,QAAQ,gBAAgB,YAAY,WAAW;AAC7D,aAASA,0BAAyC,MAAM;;AAE1D,SAAO,YACL;IACE;IACA,MAA2B;IAC3B;IACA,QAAQ;IACR;EACD,GACD,KAAK,UAAU,MAAM,CAAC;AAE1B;AAEO,eAAe,wBACpB,aACA,YACA,gBACA,gBAA+B;AAE/B,QAAM,WAAW,MAAM,YACrB;IACE,MAAwD;IACxD;IACA;IACA,QAAQ;IACR;EACD,GACD,KAAK,UAAU,cAAc,CAAC;AAEhC,QAAM,0BAA0B,MAAM,+BACpC,UACA,WAAW;AAEb,QAAM,mBAAmB,8BACvB,uBAAuB;AAEzB,SAAO;IACL,UAAU;;AAEd;AAEO,eAAe,8BACpB,aACA,YACA,gBACA,gBAA+B;AAE/B,QAAM,WAAW,MAAM,YACrB;IACE,MAA+D;IAC/D;IACA;IACA,QAAQ;IACR;EACD,GACD,KAAK,UAAU,cAAc,CAAC;AAEhC,SAAO,cAAc,UAAU,WAAW;AAC5C;AAEO,eAAe,gBACpB,aACA,OACA,QACA,eACA,gBAA+B;AAE/B,QAAM,aAAa,MAAM,kBACvB,QACA,eACA,MAAM,cAAe,gBAAgB,MAAM,GAC3C,MAAM,uBAAuB,aAAa,OAAO,QAAQ,cAAc,CAAC;AAE1E,QAAM,0BAA0B,MAAM,+BACpC,WAAW,UACX,WAAW;AAEb,QAAM,mBAAmB,8BACvB,yBACA,WAAW,eAAe;AAE5B,SAAO;IACL,UAAU;;AAEd;AAEA,eAAe,+BACb,UACA,aAAwB;AAExB,QAAM,eAAe,MAAM,SAAS,KAAI;AACxC,MAAI,YAAY,QAAQ,gBAAgB,YAAY,WAAW;AAC7D,WAAOD,2BAA0C,YAAY;SACxD;AACL,WAAO;;AAEX;AC9JM,SAAU,wBACd,OAA+B;AAG/B,MAAI,SAAS,MAAM;AACjB,WAAO;aACE,OAAO,UAAU,UAAU;AACpC,WAAO,EAAE,MAAM,UAAU,OAAO,CAAC,EAAE,MAAM,MAAK,CAAE,EAAC;aACvC,MAAe,MAAM;AAC/B,WAAO,EAAE,MAAM,UAAU,OAAO,CAAC,KAAa,EAAC;aACrC,MAAkB,OAAO;AACnC,QAAI,CAAE,MAAkB,MAAM;AAC5B,aAAO,EAAE,MAAM,UAAU,OAAQ,MAAkB,MAAK;WACnD;AACL,aAAO;;;AAGb;AAEM,SAAU,iBACd,SAAsC;AAEtC,MAAI,WAAmB,CAAA;AACvB,MAAI,OAAO,YAAY,UAAU;AAC/B,eAAW,CAAC,EAAE,MAAM,QAAO,CAAE;SACxB;AACL,eAAW,gBAAgB,SAAS;AAClC,UAAI,OAAO,iBAAiB,UAAU;AACpC,iBAAS,KAAK,EAAE,MAAM,aAAY,CAAE;aAC/B;AACL,iBAAS,KAAK,YAAY;;;;AAIhC,SAAO,+CAA+C,QAAQ;AAChE;AAUA,SAAS,+CACP,OAAa;AAEb,QAAM,cAAuB,EAAE,MAAM,QAAQ,OAAO,CAAA,EAAE;AACtD,QAAM,kBAA2B,EAAE,MAAM,YAAY,OAAO,CAAA,EAAE;AAC9D,MAAI,iBAAiB;AACrB,MAAI,qBAAqB;AACzB,aAAW,QAAQ,OAAO;AACxB,QAAI,sBAAsB,MAAM;AAC9B,sBAAgB,MAAM,KAAK,IAAI;AAC/B,2BAAqB;WAChB;AACL,kBAAY,MAAM,KAAK,IAAI;AAC3B,uBAAiB;;;AAIrB,MAAI,kBAAkB,oBAAoB;AACxC,UAAM,IAAI,QACR,YAAY,iBACZ,4HAA4H;;AAIhI,MAAI,CAAC,kBAAkB,CAAC,oBAAoB;AAC1C,UAAM,IAAI,QACR,YAAY,iBACZ,kDAAkD;;AAItD,MAAI,gBAAgB;AAClB,WAAO;;AAGT,SAAO;AACT;AAEM,SAAU,2BACd,QAA8D;AAE9D,MAAI;AACJ,MAAK,OAAkC,UAAU;AAC/C,uBAAmB;SACd;AAEL,UAAM,UAAU,iBAAiB,MAAuC;AACxE,uBAAmB,EAAE,UAAU,CAAC,OAAO,EAAC;;AAE1C,MAAK,OAAkC,mBAAmB;AACxD,qBAAiB,oBAAoB,wBAClC,OAAkC,iBAAiB;;AAGxD,SAAO;AACT;AAQM,SAAU,yBACd,QACA,EACE,QACA,aACA,cACA,iBAAiB,GACjB,gBACA,aACA,mBACA,kBAAiB,GACM;AAGzB,QAAM,OAA2B;IAC/B,WAAW;MACT;QACE;MACD;IACF;IACD,YAAY;MACV,YAAY;MACZ;MACA,aAAa;MACb;MACA,eAAe;MACf;MACA;MACA,kBAAkB;MAClB,kBAAkB;MAClB,yBAAyB;IAC1B;;AAEH,SAAO;AACT;AC7IA,IAAM,oBAAuC;EAC3C;EACA;EACA;EACA;EACA;EACA;;AAGF,IAAM,uBAA6D;EACjE,MAAM,CAAC,QAAQ,YAAY;EAC3B,UAAU,CAAC,kBAAkB;EAC7B,OAAO,CAAC,QAAQ,gBAAgB,WAAW,kBAAkB;;EAE7D,QAAQ,CAAC,MAAM;;AAGjB,IAAM,+BAA0D;EAC9D,MAAM,CAAC,OAAO;EACd,UAAU,CAAC,OAAO;EAClB,OAAO,CAAC,QAAQ,UAAU;;EAE1B,QAAQ,CAAA;;AAGJ,SAAU,oBAAoB,SAAkB;AACpD,MAAI,cAA8B;AAClC,aAAW,eAAe,SAAS;AACjC,UAAM,EAAE,MAAM,MAAK,IAAK;AACxB,QAAI,CAAC,eAAe,SAAS,QAAQ;AACnC,YAAM,IAAI,QACR,YAAY,iBACZ,iDAAiD,IAAI,EAAE;;AAG3D,QAAI,CAAC,eAAe,SAAS,IAAI,GAAG;AAClC,YAAM,IAAI,QACR,YAAY,iBACZ,4CAA4C,IAAI,yBAAyB,KAAK,UAC5E,cAAc,CACf,EAAE;;AAIP,QAAI,CAAC,MAAM,QAAQ,KAAK,GAAG;AACzB,YAAM,IAAI,QACR,YAAY,iBACZ,6DAA6D;;AAIjE,QAAI,MAAM,WAAW,GAAG;AACtB,YAAM,IAAI,QACR,YAAY,iBACZ,4CAA4C;;AAIhD,UAAM,cAA0C;MAC9C,MAAM;MACN,YAAY;MACZ,cAAc;MACd,kBAAkB;MAClB,SAAS;MACT,kBAAkB;MAClB,gBAAgB;MAChB,qBAAqB;;AAGvB,eAAW,QAAQ,OAAO;AACxB,iBAAW,OAAO,mBAAmB;AACnC,YAAI,OAAO,MAAM;AACf,sBAAY,GAAG,KAAK;;;;AAI1B,UAAM,aAAa,qBAAqB,IAAI;AAC5C,eAAW,OAAO,mBAAmB;AACnC,UAAI,CAAC,WAAW,SAAS,GAAG,KAAK,YAAY,GAAG,IAAI,GAAG;AACrD,cAAM,IAAI,QACR,YAAY,iBACZ,sBAAsB,IAAI,oBAAoB,GAAG,QAAQ;;;AAK/D,QAAI,aAAa;AACf,YAAM,4BAA4B,6BAA6B,IAAI;AACnE,UAAI,CAAC,0BAA0B,SAAS,YAAY,IAAI,GAAG;AACzD,cAAM,IAAI,QACR,YAAY,iBACZ,sBAAsB,IAAI,mBACxB,YAAY,IACd,4BAA4B,KAAK,UAC/B,4BAA4B,CAC7B,EAAE;;;AAIT,kBAAc;;AAElB;ACtFA,IAAM,eAAe;IAQR,oBAAW;EAKtB,YACE,aACO,OACC,eACD,QACA,gBAA+B;AAH/B,SAAK,QAAL;AACC,SAAa,gBAAb;AACD,SAAM,SAAN;AACA,SAAc,iBAAd;AARD,SAAQ,WAAc,CAAA;AACtB,SAAA,eAA8B,QAAQ,QAAO;AASnD,SAAK,eAAe;AACpB,QAAI,iCAAQ,SAAS;AACnB,0BAAoB,OAAO,OAAO;AAClC,WAAK,WAAW,OAAO;;;;;;;;EAS3B,MAAM,aAAU;AACd,UAAM,KAAK;AACX,WAAO,KAAK;;;;;;EAOd,MAAM,YACJ,SAAsC;;AAEtC,UAAM,KAAK;AACX,UAAM,aAAa,iBAAiB,OAAO;AAC3C,UAAM,yBAAiD;MACrD,iBAAgB,UAAK,WAAL,mBAAa;MAC7B,mBAAkB,UAAK,WAAL,mBAAa;MAC/B,QAAO,UAAK,WAAL,mBAAa;MACpB,aAAY,UAAK,WAAL,mBAAa;MACzB,oBAAmB,UAAK,WAAL,mBAAa;MAChC,UAAU,CAAC,GAAG,KAAK,UAAU,UAAU;;AAEzC,QAAI,cAAc,CAAA;AAElB,SAAK,eAAe,KAAK,aACtB,KAAK,MACJ,gBACE,KAAK,cACL,KAAK,OACL,wBACA,KAAK,eACL,KAAK,cAAc,CACpB,EAEF,KAAK,YAAS;;AACb,UACE,OAAO,SAAS,cAChB,OAAO,SAAS,WAAW,SAAS,GACpC;AACA,aAAK,SAAS,KAAK,UAAU;AAC7B,cAAM,kBAA2B;UAC/B,SAAOD,MAAA,OAAO,SAAS,eAAhB,gBAAAA,IAA6B,GAAG,QAAQ,UAAS,CAAA;;UAExD,QAAMG,MAAA,OAAO,SAAS,eAAhB,gBAAAA,IAA6B,GAAG,QAAQ,SAAQ;;AAExD,aAAK,SAAS,KAAK,eAAe;aAC7B;AACL,cAAM,oBAAoB,wBAAwB,OAAO,QAAQ;AACjE,YAAI,mBAAmB;AACrB,iBAAO,KACL,mCAAmC,iBAAiB,wCAAwC;;;AAIlG,oBAAc;IAChB,CAAC;AACH,UAAM,KAAK;AACX,WAAO;;;;;;;EAQT,MAAM,kBACJ,SAAsC;;AAEtC,UAAM,KAAK;AACX,UAAM,aAAa,iBAAiB,OAAO;AAC3C,UAAM,yBAAiD;MACrD,iBAAgB,UAAK,WAAL,mBAAa;MAC7B,mBAAkB,UAAK,WAAL,mBAAa;MAC/B,QAAO,UAAK,WAAL,mBAAa;MACpB,aAAY,UAAK,WAAL,mBAAa;MACzB,oBAAmB,UAAK,WAAL,mBAAa;MAChC,UAAU,CAAC,GAAG,KAAK,UAAU,UAAU;;AAEzC,UAAM,gBAAgB,sBACpB,KAAK,cACL,KAAK,OACL,wBACA,KAAK,eACL,KAAK,cAAc;AAIrB,SAAK,eAAe,KAAK,aACtB,KAAK,MAAM,aAAa,EAGxB,MAAM,cAAW;AAChB,YAAM,IAAI,MAAM,YAAY;IAC9B,CAAC,EACA,KAAK,kBAAgB,aAAa,QAAQ,EAC1C,KAAK,cAAW;AACf,UAAI,SAAS,cAAc,SAAS,WAAW,SAAS,GAAG;AACzD,aAAK,SAAS,KAAK,UAAU;AAC7B,cAAM,kBAAkB,EAAE,GAAG,SAAS,WAAW,CAAC,EAAE,QAAO;AAE3D,YAAI,CAAC,gBAAgB,MAAM;AACzB,0BAAgB,OAAO;;AAEzB,aAAK,SAAS,KAAK,eAAe;aAC7B;AACL,cAAM,oBAAoB,wBAAwB,QAAQ;AAC1D,YAAI,mBAAmB;AACrB,iBAAO,KACL,yCAAyC,iBAAiB,wCAAwC;;;IAI1G,CAAC,EACA,MAAM,OAAI;AAIT,UAAI,EAAE,YAAY,cAAc;AAG9B,eAAO,MAAM,CAAC;;IAElB,CAAC;AACH,WAAO;;AAEV;ACnKM,eAAe,mBACpB,aACA,OACA,QACA,gBAA+B;AAE/B,MAAI,OAAe;AACnB,MAAI,YAAY,QAAQ,gBAAgB,YAAY,WAAW;AAC7D,UAAM,eAAeC,sBAAqC,QAAQ,KAAK;AACvE,WAAO,KAAK,UAAU,YAAY;SAC7B;AACL,WAAO,KAAK,UAAU,MAAM;;AAE9B,QAAM,WAAW,MAAM,YACrB;IACE;IACA,MAAuB;IACvB;IACA,QAAQ;IACR;KAEF,IAAI;AAEN,SAAO,SAAS,KAAI;AACtB;AAEO,eAAe,YACpB,aACA,OACA,QACA,eACA,gBAA+B;AAE/B,OAAI,+CAAe,UAAS,cAAc,gBAAgB;AACxD,UAAM,IAAI,QACR,YAAY,aACZ,sDAAsD;;AAG1D,SAAO,mBAAmB,aAAa,OAAO,QAAQ,cAAc;AACtE;ACpBM,IAAO,kBAAP,cAA+B,QAAO;EAQ1C,YACE,IACA,aACA,gBACQ,eAA6B;AAErC,UAAM,IAAI,YAAY,KAAK;AAFnB,SAAa,gBAAb;AAGR,SAAK,mBAAmB,YAAY,oBAAoB,CAAA;AACxD,SAAK,iBAAiB,YAAY,kBAAkB,CAAA;AACpD,SAAK,QAAQ,YAAY;AACzB,SAAK,aAAa,YAAY;AAC9B,SAAK,oBAAoB,wBACvB,YAAY,iBAAiB;AAE/B,SAAK,iBAAiB,kBAAkB,CAAA;;;;;;EAO1C,MAAM,gBACJ,SAA+D;AAE/D,UAAM,kBAAkB,2BAA2B,OAAO;AAC1D,WAAO,gBACL,KAAK,cACL,KAAK,OACL;MACE,kBAAkB,KAAK;MACvB,gBAAgB,KAAK;MACrB,OAAO,KAAK;MACZ,YAAY,KAAK;MACjB,mBAAmB,KAAK;MACxB,GAAG;OAEL,KAAK,eACL,KAAK,cAAc;;;;;;;;EAUvB,MAAM,sBACJ,SAA+D;AAE/D,UAAM,kBAAkB,2BAA2B,OAAO;AAC1D,WAAO,sBACL,KAAK,cACL,KAAK,OACL;MACE,kBAAkB,KAAK;MACvB,gBAAgB,KAAK;MACrB,OAAO,KAAK;MACZ,YAAY,KAAK;MACjB,mBAAmB,KAAK;MACxB,GAAG;OAEL,KAAK,eACL,KAAK,cAAc;;;;;;EAQvB,UAAU,iBAAiC;AACzC,WAAO,IAAI,YACT,KAAK,cACL,KAAK,OACL,KAAK,eACL;MACE,OAAO,KAAK;MACZ,YAAY,KAAK;MACjB,mBAAmB,KAAK;MACxB,kBAAkB,KAAK;MACvB,gBAAgB,KAAK;;;;;;MAMrB,GAAG;IACJ,GACD,KAAK,cAAc;;;;;EAOvB,MAAM,YACJ,SAA2D;AAE3D,UAAM,kBAAkB,2BAA2B,OAAO;AAC1D,WAAO,YACL,KAAK,cACL,KAAK,OACL,iBACA,KAAK,aAAa;;AAGvB;IC1HY,oBAAW;;;;EAiBtB,YACU,kBACA,gBAAuC;AADvC,SAAgB,mBAAhB;AACA,SAAc,iBAAd;AAbV,SAAQ,WAAG;AAMX,SAAc,iBAAG;;;;;;;;;;;EAmBjB,MAAM,KACJ,SACA,eAAe,MAAI;AAEnB,QAAI,KAAK,UAAU;AACjB,YAAM,IAAI,QACR,YAAY,eACZ,sDAAsD;;AAI1D,UAAM,aAAa,iBAAiB,OAAO;AAE3C,UAAM,UAA8B;MAClC,eAAe;QACb,OAAO,CAAC,UAAU;QAClB;MACD;;AAEH,SAAK,iBAAiB,KAAK,KAAK,UAAU,OAAO,CAAC;;;;;;;;;;;;;;;EAgBpD,MAAM,iBAAiB,MAAY;AACjC,QAAI,KAAK,UAAU;AACjB,YAAM,IAAI,QACR,YAAY,eACZ,sDAAsD;;AAI1D,UAAM,UAAoC;MACxC,eAAe;QACb;MACD;;AAEH,SAAK,iBAAiB,KAAK,KAAK,UAAU,OAAO,CAAC;;;;;;;;;;;;;;;;;;;;EAqBpD,MAAM,kBAAkB,MAA2B;AACjD,QAAI,KAAK,UAAU;AACjB,YAAM,IAAI,QACR,YAAY,eACZ,sDAAsD;;AAI1D,UAAM,UAAoC;MACxC,eAAe;QACb,OAAO;MACR;;AAEH,SAAK,iBAAiB,KAAK,KAAK,UAAU,OAAO,CAAC;;;;;;;;;;;;;;;;;;;EAoBpD,MAAM,kBAAkB,MAA2B;AACjD,QAAI,KAAK,UAAU;AACjB,YAAM,IAAI,QACR,YAAY,eACZ,sDAAsD;;AAI1D,UAAM,UAAoC;MACxC,eAAe;QACb,OAAO;MACR;;AAEH,SAAK,iBAAiB,KAAK,KAAK,UAAU,OAAO,CAAC;;;;;;;;;;EAWpD,MAAM,sBACJ,mBAAqC;AAErC,QAAI,KAAK,UAAU;AACjB,YAAM,IAAI,QACR,YAAY,eACZ,sDAAsD;;AAI1D,UAAM,UAAmC;MACvC,cAAc;QACZ;MACD;;AAEH,SAAK,iBAAiB,KAAK,KAAK,UAAU,OAAO,CAAC;;;;;;;;;;;EAYpD,OAAO,UAAO;AAGZ,QAAI,KAAK,UAAU;AACjB,YAAM,IAAI,QACR,YAAY,gBACZ,kFAAkF;;AAGtF,qBAAiB,WAAW,KAAK,gBAAgB;AAC/C,UAAI,WAAW,OAAO,YAAY,UAAU;AAC1C,YAAI,iBAAiB,kBAAkB,SAAS;AAC9C,gBAAM;YACJ,MAAM;YACN,GAAI,QACD;;mBAEI,iBAAiB,aAAa,SAAS;AAChD,gBAAM;YACJ,MAAM;YACN,GAAI,QACD;;mBAEI,iBAAiB,0BAA0B,SAAS;AAC7D,gBAAM;YACJ,MAAM;YACN,GACE,QAMA;;eAEC;AACL,iBAAO,KACL,qDAAqD,KAAK,UACxD,OAAO,CACR,EAAE;;aAGF;AACL,eAAO,KACL,gDAAgD,KAAK,UACnD,OAAO,CACR,EAAE;;;;;;;;;;EAYX,MAAM,QAAK;AACT,QAAI,CAAC,KAAK,UAAU;AAClB,WAAK,WAAW;AAChB,YAAM,KAAK,iBAAiB,MAAM,KAAM,wBAAwB;;;;;;;;;;;;;EAcpE,MAAM,gBAAgB,aAAoC;AACxD,QAAI,KAAK,UAAU;AACjB,YAAM,IAAI,QACR,YAAY,eACZ,sDAAsD;;AAM1D,gBAAY,QAAQ,gBAAa;AAC/B,YAAM,UAAoC;QACxC,eAAe,EAAE,aAAa,CAAC,UAAU,EAAC;;AAE5C,WAAK,iBAAiB,KAAK,KAAK,UAAU,OAAO,CAAC;IACpD,CAAC;;;;;;;;;;;;EAaH,MAAM,gBACJ,kBAAuD;AAEvD,QAAI,KAAK,UAAU;AACjB,YAAM,IAAI,QACR,YAAY,eACZ,sDAAsD;;AAI1D,UAAM,SAAS,iBAAiB,UAAS;AACzC,WAAO,MAAM;AACX,UAAI;AACF,cAAM,EAAE,MAAM,MAAK,IAAK,MAAM,OAAO,KAAI;AAEzC,YAAI,MAAM;AACR;mBACS,CAAC,OAAO;AACjB,gBAAM,IAAI,MAAM,kDAAkD;;AAGpE,cAAM,KAAK,gBAAgB,CAAC,KAAK,CAAC;eAC3B,GAAG;AAEV,cAAM,UACJ,aAAa,QAAQ,EAAE,UAAU;AACnC,cAAM,IAAI,QAAQ,YAAY,eAAe,OAAO;;;;AAI3D;AC9TK,IAAO,sBAAP,cAAmC,QAAO;;;;EAS9C,YACE,IACA,aAIQ,mBAAmC;AAE3C,UAAM,IAAI,YAAY,KAAK;AAFnB,SAAiB,oBAAjB;AAGR,SAAK,mBAAmB,YAAY,oBAAoB,CAAA;AACxD,SAAK,QAAQ,YAAY;AACzB,SAAK,aAAa,YAAY;AAC9B,SAAK,oBAAoB,wBACvB,YAAY,iBAAiB;;;;;;;;;;EAYjC,MAAM,UAAO;AACX,UAAM,MAAM,IAAI,aAAa,KAAK,YAAY;AAC9C,UAAM,KAAK,kBAAkB,QAAQ,IAAI,SAAQ,CAAE;AAEnD,QAAI;AACJ,QAAI,KAAK,aAAa,QAAQ,gBAAgB,YAAY,WAAW;AACnE,sBAAgB,YAAY,KAAK,aAAa,OAAO,IAAI,KAAK,KAAK;WAC9D;AACL,sBAAgB,YAAY,KAAK,aAAa,OAAO,cAAc,KAAK,aAAa,QAAQ,IAAI,KAAK,KAAK;;AAK7G,UAAM,EACJ,yBACA,0BACA,GAAG,iBAAgB,IACjB,KAAK;AAET,UAAM,eAAiC;MACrC,OAAO;QACL,OAAO;QACP;QACA,OAAO,KAAK;QACZ,YAAY,KAAK;QACjB,mBAAmB,KAAK;QACxB;QACA;MACD;;AAGH,QAAI;AAEF,YAAM,iBAAiB,KAAK,kBAAkB,OAAM;AACpD,WAAK,kBAAkB,KAAK,KAAK,UAAU,YAAY,CAAC;AAGxD,YAAM,gBAAgB,MAAM,eAAe,KAAI,GAAI;AACnD,UACE,CAAC,gBACD,EAAE,OAAO,iBAAiB,aAC1B,EAAE,mBAAmB,eACrB;AACA,cAAM,KAAK,kBAAkB,MAAM,MAAM,mBAAmB;AAC5D,cAAM,IAAI,QACR,YAAY,gBACZ,8FAA8F;;AAIlG,aAAO,IAAI,YAAY,KAAK,mBAAmB,cAAc;aACtD,GAAG;AAEV,YAAM,KAAK,kBAAkB,MAAK;AAClC,YAAM;;;AAGX;AChFK,IAAO,cAAP,cAA2B,QAAO;;;;;;;;;;;EAoBtC,YACE,IACA,aACO,gBAA+B;AAEtC,UAAM,EAAE,OAAO,kBAAkB,eAAc,IAAK;AACpD,UAAM,IAAI,KAAK;AAHR,SAAc,iBAAd;AAIP,SAAK,mBAAmB;AACxB,SAAK,iBAAiB;;;;;;;;;;;;;;;;;;;;EAqBxB,MAAM,eACJ,QAAc;AAEd,UAAM,OAAO,yBAAyB,QAAQ;MAC5C,GAAG,KAAK;MACR,GAAG,KAAK;IACT,CAAA;AACD,UAAM,WAAW,MAAM,YACrB;MACE,MAAkB;MAClB,OAAO,KAAK;MACZ,aAAa,KAAK;MAClB,QAAQ;MACR,gBAAgB,KAAK;IACtB,GACD,KAAK,UAAU,IAAI,CAAC;AAEtB,WAAO,sBAAyC,QAAQ;;;;;;;;;;;;;;;;;;;;;EAsB1D,MAAM,kBACJ,QACA,QAAc;AAEd,UAAM,OAAO,yBAAyB,QAAQ;MAC5C;MACA,GAAG,KAAK;MACR,GAAG,KAAK;IACT,CAAA;AACD,UAAM,WAAW,MAAM,YACrB;MACE,MAAkB;MAClB,OAAO,KAAK;MACZ,aAAa,KAAK;MAClB,QAAQ;MACR,gBAAgB,KAAK;IACtB,GACD,KAAK,UAAU,IAAI,CAAC;AAEtB,WAAO,sBAAsC,QAAQ;;AAExD;IC9FY,6BAAoB;EAG/B,cAAA;AACE,QAAI,OAAO,cAAc,aAAa;AACpC,YAAM,IAAI,QACR,YAAY,aACZ,kMAE+E;;;EAKrF,QAAQ,KAAW;AACjB,WAAO,IAAI,QAAQ,CAAC,SAAS,WAAU;AACrC,WAAK,KAAK,IAAI,UAAU,GAAG;AAC3B,WAAK,GAAG,aAAa;AACrB,WAAK,GAAG,iBAAiB,QAAQ,MAAM,QAAO,GAAI,EAAE,MAAM,KAAI,CAAE;AAChE,WAAK,GAAG,iBACN,SACA,MACE,OACE,IAAI,QACF,YAAY,aACZ,iCAAiC,CAClC,GAEL,EAAE,MAAM,KAAI,CAAE;AAEhB,WAAK,GAAI,iBAAiB,SAAS,CAAC,eAA0B;AAC5D,YAAI,WAAW,QAAQ;AACrB,iBAAO,KACL,mDAAmD,WAAW,MAAM,GAAG;;MAG7E,CAAC;IACH,CAAC;;EAGH,KAAK,MAA0B;AAC7B,QAAI,CAAC,KAAK,MAAM,KAAK,GAAG,eAAe,UAAU,MAAM;AACrD,YAAM,IAAI,QAAQ,YAAY,eAAe,wBAAwB;;AAEvE,SAAK,GAAG,KAAK,IAAI;;EAGnB,OAAO,SAAM;AACX,QAAI,CAAC,KAAK,IAAI;AACZ,YAAM,IAAI,QACR,YAAY,eACZ,6BAA6B;;AAIjC,UAAM,eAA0B,CAAA;AAChC,UAAM,aAAsB,CAAA;AAC5B,QAAI,iBAAsC;AAC1C,QAAI,WAAW;AAEf,UAAM,kBAAkB,OAAO,UAAsC;AACnE,UAAI;AACJ,UAAI,MAAM,gBAAgB,MAAM;AAC9B,eAAO,MAAM,MAAM,KAAK,KAAI;iBACnB,OAAO,MAAM,SAAS,UAAU;AACzC,eAAO,MAAM;aACR;AACL,mBAAW,KACT,IAAI,QACF,YAAY,cACZ,qFAAqF,OAAO,MAAM,IAAI,GAAG,CAC1G;AAEH,YAAI,gBAAgB;AAClB,yBAAc;AACd,2BAAiB;;AAEnB;;AAGF,UAAI;AACF,cAAM,MAAM,KAAK,MAAM,IAAI;AAC3B,qBAAa,KAAK,GAAG;eACd,GAAG;AACV,cAAM,MAAM;AACZ,mBAAW,KACT,IAAI,QACF,YAAY,cACZ,4CAA4C,IAAI,OAAO,EAAE,CAC1D;;AAIL,UAAI,gBAAgB;AAClB,uBAAc;AACd,yBAAiB;;IAErB;AAEA,UAAM,gBAAgB,MAAW;AAC/B,iBAAW,KACT,IAAI,QAAQ,YAAY,aAAa,6BAA6B,CAAC;AAErE,UAAI,gBAAgB;AAClB,uBAAc;AACd,yBAAiB;;IAErB;AAEA,UAAM,gBAAgB,CAAC,UAA2B;;AAChD,UAAI,MAAM,QAAQ;AAChB,eAAO,KACL,0DAA0D,MAAM,MAAM,EAAE;;AAG5E,iBAAW;AACX,UAAI,gBAAgB;AAClB,uBAAc;AACd,yBAAiB;;AAGnB,iBAAK,OAAL,mBAAS,oBAAoB,WAAW;AACxC,iBAAK,OAAL,mBAAS,oBAAoB,SAAS;AACtC,iBAAK,OAAL,mBAAS,oBAAoB,SAAS;IACxC;AAEA,SAAK,GAAG,iBAAiB,WAAW,eAAe;AACnD,SAAK,GAAG,iBAAiB,SAAS,aAAa;AAC/C,SAAK,GAAG,iBAAiB,SAAS,aAAa;AAE/C,WAAO,CAAC,UAAU;AAChB,UAAI,WAAW,SAAS,GAAG;AACzB,cAAM,QAAQ,WAAW,MAAK;AAC9B,cAAM;;AAER,UAAI,aAAa,SAAS,GAAG;AAC3B,cAAM,aAAa,MAAK;aACnB;AACL,cAAM,IAAI,QAAc,aAAU;AAChC,2BAAiB;QACnB,CAAC;;;AAKL,QAAI,WAAW,SAAS,GAAG;AACzB,YAAM,QAAQ,WAAW,MAAK;AAC9B,YAAM;;;EAIV,MAAM,MAAe,QAAe;AAClC,WAAO,IAAI,QAAQ,aAAU;AAC3B,UAAI,CAAC,KAAK,IAAI;AACZ,eAAO,QAAO;;AAGhB,WAAK,GAAG,iBAAiB,SAAS,MAAM,QAAO,GAAI,EAAE,MAAM,KAAI,CAAE;AAEjE,UACE,KAAK,GAAG,eAAe,UAAU,UACjC,KAAK,GAAG,eAAe,UAAU,YACjC;AACA,eAAO,QAAO;;AAGhB,UAAI,KAAK,GAAG,eAAe,UAAU,SAAS;AAC5C,aAAK,GAAG,MAAM,MAAM,MAAM;;IAE9B,CAAC;;AAEJ;IC/MY,gCAAuB;;;;EAclC,YAAY,IAAQ,gBAA+B;AACjD,SAAK,iBAAiB,kBAAkB,CAAA;AACxC,SAAK,eAAe,gBAAgB,EAAE;;;;;;;;;;;;EAaxC,MAAM,gBACJ,YACA;AAEA,WAAO,wBACL,KAAK,cACL,YACA,EAAE,QAAQ,kBAAiB,GAC3B,KAAK,cAAc;;;;;;;;;;;;;;EAgBvB,MAAM,sBACJ,YACA,mBAAyB;AAEzB,WAAO,8BACL,KAAK,cACL,YACA,EAAE,QAAQ,kBAAiB,GAC3B,KAAK,cAAc;;AAGxB;IC9DY,4BAAmB;;;;EAc9B,YAAY,IAAQ,gBAA+B;AACjD,SAAK,iBAAiB,kBAAkB,CAAA;AACxC,SAAK,eAAe,gBAAgB,EAAE;;;;;;;;;;;;EAaxC,MAAM,eACJ,YACA,mBAAyB;AAEzB,UAAM,WAAW,MAAM,YACrB;MACE,MAA+C;MAC/C;MACA,aAAa,KAAK;MAClB,QAAQ;MACR,gBAAgB,KAAK;OAEvB,KAAK,UAAU,EAAE,QAAQ,kBAAiB,CAAE,CAAC;AAE/C,WAAO,sBAAyC,QAAQ;;AAE3D;IC/CqB,eAAM;EAkC1B,YAAY,cAA6B;AAEvC,QAAI,CAAC,aAAa,QAAQ,CAAC,aAAa,OAAO;AAC7C,YAAM,IAAI,QACR,YAAY,gBACZ,wEAAwE;;AAI5E,eAAW,YAAY,cAAc;AACnC,WAAK,QAAQ,IAAI,aAAa,QAAQ;;AAGxC,SAAK,OAAO,aAAa;AACzB,SAAK,SAAS,aAAa,eAAe,QAAQ,IAC9C,aAAa,SACb;AACJ,SAAK,WAAW,aAAa,eAAe,UAAU,IAClD,CAAC,CAAC,aAAa,WACf;;;;;;;EAQN,SAAM;AACJ,UAAM,MAAqD;MACzD,MAAM,KAAK;;AAEb,eAAW,QAAQ,MAAM;AACvB,UAAI,KAAK,eAAe,IAAI,KAAK,KAAK,IAAI,MAAM,QAAW;AACzD,YAAI,SAAS,cAAc,KAAK,SAAS,WAAW,QAAQ;AAC1D,cAAI,IAAI,IAAI,KAAK,IAAI;;;;AAI3B,WAAO;;EAGT,OAAO,MAAM,aAA6C;AACxD,WAAO,IAAI,YAAY,aAAa,YAAY,KAAK;;EAGvD,OAAO,OACL,cAKC;AAED,WAAO,IAAI,aACT,cACA,aAAa,YACb,aAAa,kBAAkB;;;EAKnC,OAAO,OAAO,cAA2B;AACvC,WAAO,IAAI,aAAa,YAAY;;EAGtC,OAAO,WACL,cAA+C;AAE/C,WAAO,IAAI,aAAa,cAAc,aAAa,IAAI;;EAGzD,OAAO,QAAQ,eAA4B;AACzC,WAAO,IAAI,cAAc,aAAa;;;EAIxC,OAAO,OAAO,cAA2B;AACvC,WAAO,IAAI,aAAa,YAAY;;;EAItC,OAAO,QAAQ,eAA4B;AACzC,WAAO,IAAI,cAAc,aAAa;;EAGxC,OAAO,MACL,aAAoD;AAEpD,WAAO,IAAI,YAAY,WAAW;;AAErC;AAmBK,IAAO,gBAAP,cAA6B,OAAM;EACvC,YAAY,cAA2B;AACrC,UAAM;MACJ,MAAM,WAAW;MACjB,GAAG;IACJ,CAAA;;AAEJ;AAMK,IAAO,eAAP,cAA4B,OAAM;EACtC,YAAY,cAA2B;AACrC,UAAM;MACJ,MAAM,WAAW;MACjB,GAAG;IACJ,CAAA;;AAEJ;AAMK,IAAO,gBAAP,cAA6B,OAAM;EACvC,YAAY,cAA2B;AACrC,UAAM;MACJ,MAAM,WAAW;MACjB,GAAG;IACJ,CAAA;;AAEJ;AAOK,IAAO,eAAP,cAA4B,OAAM;EAEtC,YAAY,cAA6B,YAAqB;AAC5D,UAAM;MACJ,MAAM,WAAW;MACjB,GAAG;IACJ,CAAA;AACD,SAAK,OAAO;;;;;EAMd,SAAM;AACJ,UAAM,MAAM,MAAM,OAAM;AACxB,QAAI,KAAK,MAAM;AACb,UAAI,MAAM,IAAI,KAAK;;AAErB,WAAO;;AAEV;AAQK,IAAO,cAAP,cAA2B,OAAM;EACrC,YAAY,cAAmC,OAAkB;AAC/D,UAAM;MACJ,MAAM,WAAW;MACjB,GAAG;IACJ,CAAA;AAJ4C,SAAK,QAAL;;;;;EAU/C,SAAM;AACJ,UAAM,MAAM,MAAM,OAAM;AACxB,QAAI,QAAQ,KAAK,MAAM,OAAM;AAC7B,WAAO;;AAEV;AAOK,IAAO,eAAP,cAA4B,OAAM;EACtC,YACE,cACO,YAGA,qBAA+B,CAAA,GAAE;AAExC,UAAM;MACJ,MAAM,WAAW;MACjB,GAAG;IACJ,CAAA;AARM,SAAU,aAAV;AAGA,SAAkB,qBAAlB;;;;;EAWT,SAAM;AACJ,UAAM,MAAM,MAAM,OAAM;AACxB,QAAI,aAAa,EAAE,GAAG,KAAK,WAAU;AACrC,UAAM,WAAW,CAAA;AACjB,QAAI,KAAK,oBAAoB;AAC3B,iBAAW,eAAe,KAAK,oBAAoB;AACjD,YAAI,CAAC,KAAK,WAAW,eAAe,WAAW,GAAG;AAChD,gBAAM,IAAI,QACR,YAAY,gBACZ,aAAa,WAAW,qDAAqD;;;;AAKrF,eAAW,eAAe,KAAK,YAAY;AACzC,UAAI,KAAK,WAAW,eAAe,WAAW,GAAG;AAC/C,YAAI,WAAW,WAAW,IAAI,KAAK,WACjC,WAAW,EACX,OAAM;AACR,YAAI,CAAC,KAAK,mBAAmB,SAAS,WAAW,GAAG;AAClD,mBAAS,KAAK,WAAW;;;;AAI/B,QAAI,SAAS,SAAS,GAAG;AACvB,UAAI,WAAW;;AAEjB,WAAO,IAAI;AACX,WAAO;;AAEV;AAOK,IAAO,cAAP,cAA2B,OAAM;EAErC,YAAY,cAAqD;AAC/D,QAAI,aAAa,MAAM,WAAW,GAAG;AACnC,YAAM,IAAI,QACR,YAAY,gBACZ,sCAAsC;;AAG1C,UAAM;MACJ,GAAG;MACH,MAAM;;IACP,CAAA;AACD,SAAK,QAAQ,aAAa;;;;;EAM5B,SAAM;AACJ,UAAM,MAAM,MAAM,OAAM;AAExB,QAAI,KAAK,SAAS,MAAM,QAAQ,KAAK,KAAK,GAAG;AAC3C,UAAI,QAAS,KAAK,MAAwB,IAAI,OAAK,EAAE,OAAM,CAAE;;AAE/D,WAAO;;AAEV;ICxTY,0BAAiB;EAU5B,cAAA;AACE,SAAK,WAAW;;;;;;;;;;EAWlB,OAAO,KAAK,oBAA2B;AACrC,QACE,uBACC,qBAAqB,KAAK,qBAAqB,MAChD;AACA,aAAO,KACL,uCAAuC,kBAAkB,8CAA8C;;AAG3G,WAAO,EAAE,UAAU,cAAc,mBAAkB;;;;;;;;;EAUrD,OAAO,MAAG;AACR,WAAO,EAAE,UAAU,YAAW;;AAEjC;ACnDD,IAAM,2BAA2B;AACjC,IAAM,4BAA4B;AAElC,IAAM,uBAAuB;AAY7B,IAAM,8BAA8B;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;uBA6Cb,oBAAoB;;IAiD9B,gCAAuB;EAiBlC,YACmB,aACA,SACA,MAAwB;AAFxB,SAAW,cAAX;AACA,SAAO,UAAP;AACA,SAAI,OAAJ;AAlBX,SAAS,YAAG;AAEH,SAAA,eAAe,IAAI,SAAQ;AAK3B,SAAa,gBAAkB,CAAA;AAExC,SAAgB,mBAA4B,CAAA;AAE5C,SAAa,gBAAG;AAEhB,SAAqB,wBAAG;AAO9B,SAAK,YAAY,iBAAiB;AAGlC,SAAK,qBAAqB,KAAK,eAAc,EAAG,QAAQ,MACtD,KAAK,QAAO,CAAE;AAKhB,SAAK,KAAK,YAAY,KAAK,YAAY,WAAQ;AAC7C,UAAI,KAAK,WAAW;AAClB;;AAGF,YAAM,QAAQ,MAAM;AACpB,YAAM,SAAS,KACb,OAAO,aAAa,MAClB,MACA,MAAM,KAAK,IAAI,WAAW,MAAM,MAAM,CAAC,CAAC,CACzC;AAGH,YAAM,QAA+B;QACnC,UAAU;QACV,MAAM;;AAER,WAAK,KAAK,YAAY,kBAAkB,KAAK;IAC/C;;;;;EAMF,MAAM,OAAI;AACR,QAAI,KAAK,WAAW;AAClB;;AAEF,SAAK,YAAY;AACjB,SAAK,aAAa,QAAO;AACzB,UAAM,KAAK;;;;;;EAOL,UAAO;AACb,SAAK,kBAAiB;AACtB,SAAK,KAAK,YAAY,KAAK,YAAY;AACvC,SAAK,KAAK,YAAY,WAAU;AAChC,SAAK,KAAK,WAAW,WAAU;AAC/B,SAAK,KAAK,YAAY,UAAS,EAAG,QAAQ,WAAS,MAAM,KAAI,CAAE;AAC/D,QAAI,KAAK,KAAK,aAAa,UAAU,UAAU;AAC7C,WAAK,KAAK,KAAK,aAAa,MAAK;;AAEnC,SAAK,YAAY,iBAAiB;;;;;EAM5B,eAAe,WAAsB;AAC3C,SAAK,cAAc,KAAK,SAAS;AAEjC,SAAK,KAAK,qBAAoB;;;;;;;EAQxB,oBAAiB;AAGvB,KAAC,GAAG,KAAK,gBAAgB,EAAE,QAAQ,YAAU,OAAO,KAAK,CAAC,CAAC;AAG3D,SAAK,cAAc,SAAS;AAG5B,SAAK,gBAAgB,KAAK,KAAK,aAAa;;;;;EAMtC,MAAM,uBAAoB;AAChC,QAAI,KAAK,uBAAuB;AAC9B;;AAEF,SAAK,wBAAwB;AAE7B,WAAO,KAAK,cAAc,SAAS,KAAK,CAAC,KAAK,WAAW;AACvD,YAAM,eAAe,KAAK,cAAc,MAAK;AAC7C,UAAI;AACF,cAAM,QAAQ,IAAI,WAAW,YAAY;AACzC,cAAM,aAAa,MAAM;AAEzB,cAAM,cAAc,KAAK,KAAK,aAAa,aACzC,GACA,YACA,yBAAyB;AAI3B,cAAM,cAAc,YAAY,eAAe,CAAC;AAChD,iBAAS,IAAI,GAAG,IAAI,YAAY,KAAK;AACnC,sBAAY,CAAC,IAAI,MAAM,CAAC,IAAI;;AAG9B,cAAM,SAAS,KAAK,KAAK,aAAa,mBAAkB;AACxD,eAAO,SAAS;AAChB,eAAO,QAAQ,KAAK,KAAK,aAAa,WAAW;AAGjD,aAAK,iBAAiB,KAAK,MAAM;AACjC,eAAO,UAAU,MAAK;AACpB,eAAK,mBAAmB,KAAK,iBAAiB,OAC5C,OAAK,MAAM,MAAM;QAErB;AAIA,aAAK,gBAAgB,KAAK,IACxB,KAAK,KAAK,aAAa,aACvB,KAAK,aAAa;AAEpB,eAAO,MAAM,KAAK,aAAa;AAG/B,aAAK,iBAAiB,YAAY;eAC3B,GAAG;AACV,eAAO,MAAM,wBAAwB,CAAC;;;AAI1C,SAAK,wBAAwB;;;;;EAMvB,MAAM,iBAAc;;AAC1B,UAAM,mBAAmB,KAAK,YAAY,QAAO;AACjD,WAAO,CAAC,KAAK,WAAW;AACtB,YAAM,SAAS,MAAM,QAAQ,KAAK;QAChC,iBAAiB,KAAI;QACrB,KAAK,aAAa;MACnB,CAAA;AAED,UAAI,KAAK,aAAa,CAAC,UAAU,OAAO,MAAM;AAC5C;;AAGF,YAAM,UAAU,OAAO;AACvB,UAAI,QAAQ,SAAS,iBAAiB;AACpC,cAAM,gBAAgB;AACtB,YAAI,cAAc,aAAa;AAC7B,eAAK,kBAAiB;;AAGxB,cAAM,aAAY,mBAAc,cAAd,mBAAyB,MAAM,KAAK,UAAI;;AACxD,kBAAAJ,MAAA,KAAK,eAAL,gBAAAA,IAAiB,SAAS,WAAW;;AAEvC,YAAI,uCAAW,YAAY;AACzB,gBAAM,YAAY,WAAW,KAC3B,KAAK,UAAU,WAAW,IAAI,GAC9B,OAAK,EAAE,WAAW,CAAC,CAAC,EACpB;AACF,eAAK,eAAe,SAAS;;iBAEtB,QAAQ,SAAS,YAAY;AACtC,YAAI,CAAC,KAAK,QAAQ,wBAAwB;AACxC,iBAAO,KACL,wHAAwH;eAErH;AACL,cAAI;AACF,kBAAM,mBAAmB,MAAM,KAAK,QAAQ,uBAC1C,QAAQ,aAAa;AAEvB,gBAAI,CAAC,KAAK,WAAW;AACnB,mBAAK,KAAK,YAAY,sBAAsB,CAAC,gBAAgB,CAAC;;mBAEzD,GAAG;AACV,kBAAM,IAAI,QACR,YAAY,OACZ,oCAAqC,EAAY,OAAO,EAAE;;;;;;AAOvE;AAgDM,eAAe,uBACpB,aACA,UAAyC,CAAA,GAAE;AAE3C,MAAI,YAAY,UAAU;AACxB,UAAM,IAAI,QACR,YAAY,gBACZ,0DAA0D;;AAI9D,MAAI,YAAY,gBAAgB;AAC9B,UAAM,IAAI,QACR,YAAY,eACZ,gEAAgE;;AAKpE,MACE,OAAO,qBAAqB,eAC5B,OAAO,iBAAiB,eACxB,OAAO,cAAc,eACrB,CAAC,UAAU,cACX;AACA,UAAM,IAAI,QACR,YAAY,aACZ,kHAAkH;;AAItH,MAAI;AACJ,MAAI;AAGF,mBAAe,IAAI,aAAY;AAC/B,QAAI,aAAa,UAAU,aAAa;AACtC,YAAM,aAAa,OAAM;;AAK3B,UAAM,cAAc,MAAM,UAAU,aAAa,aAAa;MAC5D,OAAO;IACR,CAAA;AAID,UAAM,cAAc,IAAI,KAAK,CAAC,2BAA2B,GAAG;MAC1D,MAAM;IACP,CAAA;AACD,UAAM,aAAa,IAAI,gBAAgB,WAAW;AAClD,UAAM,aAAa,aAAa,UAAU,UAAU;AAGpD,UAAM,aAAa,aAAa,wBAAwB,WAAW;AACnE,UAAM,cAAc,IAAI,iBACtB,cACA,sBACA;MACE,kBAAkB,EAAE,kBAAkB,yBAAwB;IAC/D,CAAA;AAEH,eAAW,QAAQ,WAAW;AAG9B,UAAM,SAAS,IAAI,wBAAwB,aAAa,SAAS;MAC/D;MACA;MACA;MACA;IACD,CAAA;AAED,WAAO,EAAE,MAAM,MAAM,OAAO,KAAI,EAAE;WAC3B,GAAG;AAEV,QAAI,gBAAgB,aAAa,UAAU,UAAU;AACnD,WAAK,aAAa,MAAK;;AAKzB,QAAI,aAAa,WAAW,aAAa,cAAc;AACrD,YAAM;;AAIR,UAAM,IAAI,QACR,YAAY,OACZ,yCAA0C,EAAY,OAAO,EAAE;;AAGrE;SC9YgB,MAAM,MAAmB,OAAM,GAAI,SAAmB;AACpE,QAAM,mBAAmB,GAAG;AAE5B,QAAM,aAA6B,aAAa,KAAK,OAAO;AAE5D,QAAM,WAAU,mCAAS,YAAW,IAAI,gBAAe;AAEvD,QAAM,eAA2C;IAC/C,8BAA6B,mCAAS,gCAA+B;;AAGvE,QAAM,aAAa,yBAAyB,OAAO;AACnD,QAAM,aAAa,WAAW,aAAa;IACzC;EACD,CAAA;AAED,aAAW,UAAU;AAErB,SAAO;AACT;SAQgB,mBACd,IACA,aACA,gBAA+B;;AAG/B,QAAM,eAAe;AACrB,MAAI;AACJ,MAAI,aAAa,MAAM;AACrB,oBAAgB,aAAa,iBAAiB;MAC5C,OAAO;;SAEJ;AACL,oBAAgB;;AAGlB,MAAI,CAAC,cAAc,OAAO;AACxB,UAAM,IAAI,QACR,YAAY,UACZ,oFAAoF;;AAQxF,QAAM,iBAAiB,QAAiB,yBAAjB,4BACrB,aAAa,MACb,OAAO,WAAW,cAAc,SAAY,QAC5C,aAAa;AAGf,SAAO,IAAI,gBAAgB,IAAI,eAAe,gBAAgB,aAAa;AAC7E;SAgBgB,eACd,IACA,aACA,gBAA+B;AAE/B,MAAI,CAAC,YAAY,OAAO;AACtB,UAAM,IAAI,QACR,YAAY,UACZ,gFAAgF;;AAGpF,SAAO,IAAI,YAAY,IAAI,aAAa,cAAc;AACxD;AAcgB,SAAA,uBACd,IACA,aAA4B;AAE5B,MAAI,CAAC,YAAY,OAAO;AACtB,UAAM,IAAI,QACR,YAAY,UACZ,uHAAuH;;AAG3H,QAAM,mBAAmB,IAAI,qBAAoB;AACjD,SAAO,IAAI,oBAAoB,IAAI,aAAa,gBAAgB;AAClE;AAWgB,SAAA,2BACd,IACA,gBAA+B;AAE/B,SAAO,IAAI,wBAAwB,IAAI,cAAc;AACvD;AAWgB,SAAA,uBACd,IACA,gBAA+B;AAE/B,SAAO,IAAI,oBAAoB,IAAI,cAAc;AACnD;ACjNA,SAAS,aAAU;AACjB,qBACE,IAAI;IAAU;IAAS;IAA8B;;EAAA,EAAC,qBACpD,IAAI,CACL;AAGH,kBAAgB,MAAM,OAAO;AAE7B,kBAAgB,MAAM,SAAS,SAAkB;AACnD;AAEA,WAAU;",
  "names": ["Availability", "window", "chromeAdapterFactory", "_a", "GoogleAIMapper.mapGenerateContentResponse", "GoogleAIMapper.mapGenerateContentRequest", "_b", "GoogleAIMapper.mapCountTokensRequest"]
}
